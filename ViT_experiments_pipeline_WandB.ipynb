{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "LYSEhsPs0Ulr",
        "outputId": "e0285043-1aa0-41a9-a1df-520a1e2c86e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pip in ./.venv/lib/python3.11/site-packages (25.0.1)\n",
            "Requirement already satisfied: tokenizers in ./.venv/lib/python3.11/site-packages (0.21.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in ./.venv/lib/python3.11/site-packages (from tokenizers) (0.30.2)\n",
            "Requirement already satisfied: filelock in ./.venv/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in ./.venv/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (2024.12.0)\n",
            "Requirement already satisfied: packaging>=20.9 in ./.venv/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in ./.venv/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (6.0.2)\n",
            "Requirement already satisfied: requests in ./.venv/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in ./.venv/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.venv/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.11/site-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.11/site-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.11/site-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.11/site-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers) (2025.1.31)\n",
            "Requirement already satisfied: datasets in ./.venv/lib/python3.11/site-packages (3.5.0)\n",
            "Requirement already satisfied: evaluate in ./.venv/lib/python3.11/site-packages (0.4.3)\n",
            "Requirement already satisfied: filelock in ./.venv/lib/python3.11/site-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in ./.venv/lib/python3.11/site-packages (from datasets) (2.2.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in ./.venv/lib/python3.11/site-packages (from datasets) (19.0.1)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in ./.venv/lib/python3.11/site-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in ./.venv/lib/python3.11/site-packages (from datasets) (2.2.3)\n",
            "Requirement already satisfied: requests>=2.32.2 in ./.venv/lib/python3.11/site-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in ./.venv/lib/python3.11/site-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in ./.venv/lib/python3.11/site-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in ./.venv/lib/python3.11/site-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in ./.venv/lib/python3.11/site-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.12.0)\n",
            "Requirement already satisfied: aiohttp in ./.venv/lib/python3.11/site-packages (from datasets) (3.11.16)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in ./.venv/lib/python3.11/site-packages (from datasets) (0.30.2)\n",
            "Requirement already satisfied: packaging in ./.venv/lib/python3.11/site-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in ./.venv/lib/python3.11/site-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in ./.venv/lib/python3.11/site-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in ./.venv/lib/python3.11/site-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in ./.venv/lib/python3.11/site-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in ./.venv/lib/python3.11/site-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in ./.venv/lib/python3.11/site-packages (from aiohttp->datasets) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in ./.venv/lib/python3.11/site-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./.venv/lib/python3.11/site-packages (from aiohttp->datasets) (1.20.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.venv/lib/python3.11/site-packages (from huggingface-hub>=0.24.0->datasets) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.11/site-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.11/site-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.11/site-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Requirement already satisfied: transformers in ./.venv/lib/python3.11/site-packages (4.51.3)\n",
            "Requirement already satisfied: filelock in ./.venv/lib/python3.11/site-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in ./.venv/lib/python3.11/site-packages (from transformers) (0.30.2)\n",
            "Requirement already satisfied: numpy>=1.17 in ./.venv/lib/python3.11/site-packages (from transformers) (2.2.4)\n",
            "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.11/site-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in ./.venv/lib/python3.11/site-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in ./.venv/lib/python3.11/site-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in ./.venv/lib/python3.11/site-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in ./.venv/lib/python3.11/site-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in ./.venv/lib/python3.11/site-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in ./.venv/lib/python3.11/site-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in ./.venv/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2024.12.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.venv/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.11/site-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.11/site-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.11/site-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.11/site-packages (from requests->transformers) (2025.1.31)\n",
            "Requirement already satisfied: numpy in ./.venv/lib/python3.11/site-packages (2.2.4)\n",
            "Requirement already satisfied: torch in ./.venv/lib/python3.11/site-packages (2.6.0)\n",
            "Requirement already satisfied: matplotlib in ./.venv/lib/python3.11/site-packages (3.10.1)\n",
            "Requirement already satisfied: pandas in ./.venv/lib/python3.11/site-packages (2.2.3)\n",
            "Requirement already satisfied: scikit-learn in ./.venv/lib/python3.11/site-packages (1.6.1)\n",
            "Requirement already satisfied: tqdm in ./.venv/lib/python3.11/site-packages (4.67.1)\n",
            "Requirement already satisfied: pillow in ./.venv/lib/python3.11/site-packages (11.2.1)\n",
            "Requirement already satisfied: filelock in ./.venv/lib/python3.11/site-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in ./.venv/lib/python3.11/site-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: networkx in ./.venv/lib/python3.11/site-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in ./.venv/lib/python3.11/site-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in ./.venv/lib/python3.11/site-packages (from torch) (2024.12.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in ./.venv/lib/python3.11/site-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.11/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in ./.venv/lib/python3.11/site-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in ./.venv/lib/python3.11/site-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in ./.venv/lib/python3.11/site-packages (from matplotlib) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in ./.venv/lib/python3.11/site-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.11/site-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in ./.venv/lib/python3.11/site-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in ./.venv/lib/python3.11/site-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.11/site-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.11/site-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in ./.venv/lib/python3.11/site-packages (from scikit-learn) (1.15.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in ./.venv/lib/python3.11/site-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in ./.venv/lib/python3.11/site-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.11/site-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: datasets in ./.venv/lib/python3.11/site-packages (3.5.0)\n",
            "Requirement already satisfied: evaluate in ./.venv/lib/python3.11/site-packages (0.4.3)\n",
            "Requirement already satisfied: transformers in ./.venv/lib/python3.11/site-packages (4.51.3)\n",
            "Requirement already satisfied: filelock in ./.venv/lib/python3.11/site-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in ./.venv/lib/python3.11/site-packages (from datasets) (2.2.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in ./.venv/lib/python3.11/site-packages (from datasets) (19.0.1)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in ./.venv/lib/python3.11/site-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in ./.venv/lib/python3.11/site-packages (from datasets) (2.2.3)\n",
            "Requirement already satisfied: requests>=2.32.2 in ./.venv/lib/python3.11/site-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in ./.venv/lib/python3.11/site-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in ./.venv/lib/python3.11/site-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in ./.venv/lib/python3.11/site-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in ./.venv/lib/python3.11/site-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.12.0)\n",
            "Requirement already satisfied: aiohttp in ./.venv/lib/python3.11/site-packages (from datasets) (3.11.16)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in ./.venv/lib/python3.11/site-packages (from datasets) (0.30.2)\n",
            "Requirement already satisfied: packaging in ./.venv/lib/python3.11/site-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in ./.venv/lib/python3.11/site-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in ./.venv/lib/python3.11/site-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in ./.venv/lib/python3.11/site-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in ./.venv/lib/python3.11/site-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in ./.venv/lib/python3.11/site-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in ./.venv/lib/python3.11/site-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in ./.venv/lib/python3.11/site-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in ./.venv/lib/python3.11/site-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in ./.venv/lib/python3.11/site-packages (from aiohttp->datasets) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in ./.venv/lib/python3.11/site-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./.venv/lib/python3.11/site-packages (from aiohttp->datasets) (1.20.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.venv/lib/python3.11/site-packages (from huggingface-hub>=0.24.0->datasets) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.11/site-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.11/site-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.11/site-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Requirement already satisfied: torchvision in ./.venv/lib/python3.11/site-packages (0.21.0)\n",
            "Requirement already satisfied: numpy in ./.venv/lib/python3.11/site-packages (from torchvision) (2.2.4)\n",
            "Requirement already satisfied: torch==2.6.0 in ./.venv/lib/python3.11/site-packages (from torchvision) (2.6.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in ./.venv/lib/python3.11/site-packages (from torchvision) (11.2.1)\n",
            "Requirement already satisfied: filelock in ./.venv/lib/python3.11/site-packages (from torch==2.6.0->torchvision) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in ./.venv/lib/python3.11/site-packages (from torch==2.6.0->torchvision) (4.13.2)\n",
            "Requirement already satisfied: networkx in ./.venv/lib/python3.11/site-packages (from torch==2.6.0->torchvision) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in ./.venv/lib/python3.11/site-packages (from torch==2.6.0->torchvision) (3.1.6)\n",
            "Requirement already satisfied: fsspec in ./.venv/lib/python3.11/site-packages (from torch==2.6.0->torchvision) (2024.12.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in ./.venv/lib/python3.11/site-packages (from torch==2.6.0->torchvision) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.11/site-packages (from sympy==1.13.1->torch==2.6.0->torchvision) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.11/site-packages (from jinja2->torch==2.6.0->torchvision) (3.0.2)\n",
            "Requirement already satisfied: setuptools in ./.venv/lib/python3.11/site-packages (78.1.0)\n",
            "Requirement already satisfied: wandb in ./.venv/lib/python3.11/site-packages (0.19.9)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in ./.venv/lib/python3.11/site-packages (from wandb) (8.1.8)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in ./.venv/lib/python3.11/site-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in ./.venv/lib/python3.11/site-packages (from wandb) (3.1.44)\n",
            "Requirement already satisfied: platformdirs in ./.venv/lib/python3.11/site-packages (from wandb) (4.3.7)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in ./.venv/lib/python3.11/site-packages (from wandb) (5.29.4)\n",
            "Requirement already satisfied: psutil>=5.0.0 in ./.venv/lib/python3.11/site-packages (from wandb) (7.0.0)\n",
            "Requirement already satisfied: pydantic<3 in ./.venv/lib/python3.11/site-packages (from wandb) (2.11.3)\n",
            "Requirement already satisfied: pyyaml in ./.venv/lib/python3.11/site-packages (from wandb) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in ./.venv/lib/python3.11/site-packages (from wandb) (2.32.3)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in ./.venv/lib/python3.11/site-packages (from wandb) (2.26.1)\n",
            "Requirement already satisfied: setproctitle in ./.venv/lib/python3.11/site-packages (from wandb) (1.3.5)\n",
            "Requirement already satisfied: setuptools in ./.venv/lib/python3.11/site-packages (from wandb) (78.1.0)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4 in ./.venv/lib/python3.11/site-packages (from wandb) (4.13.2)\n",
            "Requirement already satisfied: six>=1.4.0 in ./.venv/lib/python3.11/site-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in ./.venv/lib/python3.11/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in ./.venv/lib/python3.11/site-packages (from pydantic<3->wandb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in ./.venv/lib/python3.11/site-packages (from pydantic<3->wandb) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in ./.venv/lib/python3.11/site-packages (from pydantic<3->wandb) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.11/site-packages (from requests<3,>=2.0.0->wandb) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.11/site-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.11/site-packages (from requests<3,>=2.0.0->wandb) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.11/site-packages (from requests<3,>=2.0.0->wandb) (2025.1.31)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in ./.venv/lib/python3.11/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n",
            "Name: wandb\n",
            "Version: 0.19.9\n",
            "Summary: A CLI and library for interacting with the Weights & Biases API.\n",
            "Home-page: \n",
            "Author: \n",
            "Author-email: Weights & Biases <support@wandb.com>\n",
            "License: MIT License\n",
            "\n",
            "Copyright (c) 2021 Weights and Biases, Inc.\n",
            "\n",
            "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
            "of this software and associated documentation files (the \"Software\"), to deal\n",
            "in the Software without restriction, including without limitation the rights\n",
            "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
            "copies of the Software, and to permit persons to whom the Software is\n",
            "furnished to do so, subject to the following conditions:\n",
            "\n",
            "The above copyright notice and this permission notice shall be included in all\n",
            "copies or substantial portions of the Software.\n",
            "\n",
            "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
            "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
            "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
            "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
            "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
            "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
            "SOFTWARE.\n",
            "Location: /Users/egoh02/Github/CS7643-Project-SP25/.venv/lib/python3.11/site-packages\n",
            "Requires: click, docker-pycreds, gitpython, platformdirs, protobuf, psutil, pydantic, pyyaml, requests, sentry-sdk, setproctitle, setuptools, typing-extensions\n",
            "Required-by: \n",
            "Requirement already satisfied: schedulefree in ./.venv/lib/python3.11/site-packages (1.4.1)\n",
            "Requirement already satisfied: torch in ./.venv/lib/python3.11/site-packages (from schedulefree) (2.6.0)\n",
            "Requirement already satisfied: typing-extensions in ./.venv/lib/python3.11/site-packages (from schedulefree) (4.13.2)\n",
            "Requirement already satisfied: filelock in ./.venv/lib/python3.11/site-packages (from torch->schedulefree) (3.18.0)\n",
            "Requirement already satisfied: networkx in ./.venv/lib/python3.11/site-packages (from torch->schedulefree) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in ./.venv/lib/python3.11/site-packages (from torch->schedulefree) (3.1.6)\n",
            "Requirement already satisfied: fsspec in ./.venv/lib/python3.11/site-packages (from torch->schedulefree) (2024.12.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in ./.venv/lib/python3.11/site-packages (from torch->schedulefree) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.11/site-packages (from sympy==1.13.1->torch->schedulefree) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.11/site-packages (from jinja2->torch->schedulefree) (3.0.2)\n",
            "Requirement already satisfied: nbformat in ./.venv/lib/python3.11/site-packages (5.10.4)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in ./.venv/lib/python3.11/site-packages (from nbformat) (2.21.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in ./.venv/lib/python3.11/site-packages (from nbformat) (4.23.0)\n",
            "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in ./.venv/lib/python3.11/site-packages (from nbformat) (5.7.2)\n",
            "Requirement already satisfied: traitlets>=5.1 in ./.venv/lib/python3.11/site-packages (from nbformat) (5.14.3)\n",
            "Requirement already satisfied: attrs>=22.2.0 in ./.venv/lib/python3.11/site-packages (from jsonschema>=2.6->nbformat) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in ./.venv/lib/python3.11/site-packages (from jsonschema>=2.6->nbformat) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in ./.venv/lib/python3.11/site-packages (from jsonschema>=2.6->nbformat) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in ./.venv/lib/python3.11/site-packages (from jsonschema>=2.6->nbformat) (0.24.0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in ./.venv/lib/python3.11/site-packages (from jupyter-core!=5.0.*,>=4.12->nbformat) (4.3.7)\n",
            "Requirement already satisfied: typing-extensions>=4.4.0 in ./.venv/lib/python3.11/site-packages (from referencing>=0.28.4->jsonschema>=2.6->nbformat) (4.13.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade pip\n",
        "!pip install tokenizers\n",
        "!pip install datasets --upgrade evaluate\n",
        "!pip install transformers\n",
        "!pip install numpy torch matplotlib pandas scikit-learn tqdm pillow\n",
        "!pip install datasets evaluate transformers\n",
        "!pip install torchvision\n",
        "!pip install setuptools\n",
        "!pip install wandb\n",
        "!pip show wandb\n",
        "!pip install schedulefree\n",
        "!pip install nbformat\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "nW76RvsBd0lZ",
        "outputId": "b8baebfa-b9de-4efd-e82b-fb778af23954"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/egoh02/Github/CS7643-Project-SP25/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from datasets import load_dataset\n",
        "from evaluate import load\n",
        "from transformers import (\n",
        "    ViTFeatureExtractor,\n",
        "    ViTForImageClassification,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    get_scheduler,\n",
        "    AutoImageProcessor\n",
        ")\n",
        "\n",
        "from torch.optim import AdamW, SGD\n",
        "import wandb\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "import random\n",
        "from tqdm.auto import tqdm\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from schedulefree import AdamWScheduleFree\n",
        "from torch.optim.lr_scheduler import CyclicLR, ExponentialLR, ReduceLROnPlateau\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "hsPdHp-P0Ult"
      },
      "outputs": [],
      "source": [
        "# sweep_config = {\n",
        "#     \"method\": \"grid\",  # we cna use \"grid\", \"random\", or \"bayes\"\n",
        "#     \"metric\": {\n",
        "#         \"name\": \"val_accuracy\",  # Metric to optimize\n",
        "#         \"goal\": \"maximize\"       # Goal: maximize or minimize\n",
        "#     },\n",
        "#     \"parameters\": {\n",
        "#         \"optimizer_name\": {\n",
        "#             \"values\": [\"AdamW\", \"SGD\", \"RMSProp\", \"AdaGrad\", \"schedule_free_adamw\"]  # Optimizers to test\n",
        "#         },\n",
        "#         \"learning_rate\": {\n",
        "#             \"values\": [2e-5, 2e-4, 2e-3, 2e-2, 2e-1]  # Fixed learning rate for simplicity\n",
        "#         },\n",
        "#         \"batch_size\": {\n",
        "#             \"values\": [16]  # Fixed batch size\n",
        "#         },\n",
        "#         \"num_epochs\": {\n",
        "#             \"values\": [3]  # Fixed number of epochs\n",
        "#         },\n",
        "#         \"scheduler_name\": {\n",
        "#             \"values\": [\"cosine\"]  # Fixed scheduler for simplicity\n",
        "#         }\n",
        "#     }\n",
        "# }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M5m2CPNN0Ulu"
      },
      "outputs": [],
      "source": [
        "# Set seed for reproducibility\n",
        "def set_seed(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "set_seed()\n",
        "\n",
        "# Initialize experiment tracking\n",
        "def init_wandb(project_name, experiment_name, config):\n",
        "    return wandb.init(\n",
        "        # entity=\"dl_project_sp25\",\n",
        "        project=project_name,\n",
        "        name=experiment_name,\n",
        "        config=config,\n",
        "        reinit=True\n",
        "    )\n",
        "\n",
        "# Load and prepare dataset\n",
        "def prepare_dataset(dataset_name, image_processor):\n",
        "    \"\"\"\n",
        "    Load and prepare a dataset from Hugging Face for ViT fine-tuning\n",
        "    \"\"\"\n",
        "    # Load the dataset\n",
        "    print(f\"Loading dataset: {dataset_name}\")\n",
        "    dataset = load_dataset(dataset_name)\n",
        "\n",
        "    # Get label information\n",
        "    if \"label\" in dataset[\"train\"].features:\n",
        "        labels = dataset[\"train\"].features[\"label\"].names\n",
        "    elif \"labels\" in dataset[\"train\"].features:\n",
        "        labels = dataset[\"train\"].features[\"labels\"].names\n",
        "    else:\n",
        "        # Count unique labels and create labels list\n",
        "        all_labels = dataset[\"train\"][0][\"label\"] if \"label\" in dataset[\"train\"][0] else dataset[\"train\"][0][\"labels\"]\n",
        "        num_labels = len(set(all_labels))\n",
        "        labels = [str(i) for i in range(num_labels)]\n",
        "\n",
        "    # Create label mappings\n",
        "    label2id = {label: i for i, label in enumerate(labels)}\n",
        "    id2label = {i: label for i, label in enumerate(labels)}\n",
        "\n",
        "    # Set up image transformations based on the model's requirements\n",
        "    normalize = transforms.Normalize(\n",
        "        mean=image_processor.image_mean,\n",
        "        std=image_processor.image_std\n",
        "    )\n",
        "\n",
        "    # Get the expected image size\n",
        "    if \"shortest_edge\" in image_processor.size:\n",
        "        size = image_processor.size[\"shortest_edge\"]\n",
        "    else:\n",
        "        size = (image_processor.size[\"height\"], image_processor.size[\"width\"])\n",
        "\n",
        "    # Define transforms for training data\n",
        "    train_transforms = transforms.Compose([\n",
        "        transforms.RandomResizedCrop(size),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        normalize,\n",
        "    ])\n",
        "\n",
        "    # Define transforms for validation/test data\n",
        "    val_transforms = transforms.Compose([\n",
        "        transforms.Resize(size),\n",
        "        transforms.CenterCrop(size),\n",
        "        transforms.ToTensor(),\n",
        "        normalize,\n",
        "    ])\n",
        "\n",
        "    # Apply transformations to the dataset\n",
        "    def preprocess_train(examples):\n",
        "        examples[\"pixel_values\"] = [\n",
        "            train_transforms(image.convert(\"RGB\"))\n",
        "            for image in examples[\"image\"]\n",
        "        ]\n",
        "        return examples\n",
        "\n",
        "    def preprocess_val(examples):\n",
        "        examples[\"pixel_values\"] = [\n",
        "            val_transforms(image.convert(\"RGB\"))\n",
        "            for image in examples[\"image\"]\n",
        "        ]\n",
        "        return examples\n",
        "\n",
        "    # Apply preprocessing to each split\n",
        "    train_dataset = dataset[\"train\"].map(\n",
        "        preprocess_train, batched=True, remove_columns=[\"image\"]\n",
        "    )\n",
        "\n",
        "    if \"validation\" in dataset:\n",
        "        val_dataset = dataset[\"validation\"].map(\n",
        "            preprocess_val, batched=True, remove_columns=[\"image\"]\n",
        "        )\n",
        "\n",
        "    else:\n",
        "        # Create a validation split if none exists\n",
        "        splits = train_dataset.train_test_split(test_size=0.2, seed=42)\n",
        "        train_dataset = splits[\"train\"]\n",
        "        val_dataset = splits[\"test\"]\n",
        "\n",
        "    if \"test\" in dataset:\n",
        "        test_dataset = dataset[\"test\"].map(\n",
        "            preprocess_val, batched=True, remove_columns=[\"image\"]\n",
        "        )\n",
        "    else:\n",
        "        # test_dataset = val_dataset    #split further rather than using validation as test dataset\n",
        "\n",
        "        # Further split validation dataset to create a test dataset\n",
        "        test_split = val_dataset.train_test_split(test_size=0.2, seed=42)\n",
        "        val_dataset = test_split[\"train\"]  # Update validation dataset\n",
        "        test_dataset = test_split[\"test\"]  # Create test dataset\n",
        "\n",
        "    print(f\"Dataset prepared with {len(train_dataset)} training, {len(val_dataset)} validation, and {len(test_dataset)} test examples\")\n",
        "\n",
        "    return train_dataset, val_dataset, test_dataset, id2label, label2id\n",
        "\n",
        "# Define compute_metrics function for evaluation\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average='weighted')\n",
        "    acc = accuracy_score(labels, predictions)\n",
        "\n",
        "    return {\n",
        "        'accuracy': acc,\n",
        "        'f1': f1,\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "    }\n",
        "\n",
        "# Main experiment pipeline\n",
        "def run_vit_experiment(config): \n",
        "    \"\"\"\n",
        "    Run a ViT experiment with the specified configuration\n",
        "    \"\"\"\n",
        "    # Initialize wandb for experiment tracking\n",
        "    # run = init_wandb(\"ViT-LR-Schedulers\", config[\"experiment_name\"], config)\n",
        "\n",
        "    # Initialize wandb for experiment tracking with proper config logging\n",
        "    run = wandb.init(\n",
        "        project=\"ViT-LR-Schedulers\",\n",
        "        name=config[\"experiment_name\"],\n",
        "        group=f\"{config['optimizer_name']}_experiments\",  # Group by optimizer\n",
        "        config={\n",
        "            # Explicitly list all important hyperparameters\n",
        "            \"optimizer\": config[\"optimizer_name\"],\n",
        "            \"scheduler\": config[\"scheduler_name\"],\n",
        "            \"learning_rate\": config[\"learning_rate\"],\n",
        "            \"batch_size\": config[\"batch_size\"],\n",
        "            \"num_epochs\": config[\"num_epochs\"],\n",
        "            \"weight_decay\": config[\"weight_decay\"],\n",
        "            \"warmup_ratio\": config.get(\"warmup_ratio\", 0.0),\n",
        "            \"dataset\": config[\"dataset_name\"],\n",
        "            \"model\": config[\"model_name\"],\n",
        "        },\n",
        "        tags=[config[\"optimizer_name\"], config[\"scheduler_name\"]],  # Add tags for easy filtering\n",
        "        reinit=True\n",
        "    )\n",
        "\n",
        "\n",
        "    # Load the image processor for the model\n",
        "    image_processor = AutoImageProcessor.from_pretrained(config[\"model_name\"], use_fast=True)\n",
        "\n",
        "    # Prepare the dataset\n",
        "    train_dataset, val_dataset, test_dataset, id2label, label2id = prepare_dataset(\n",
        "        config[\"dataset_name\"], image_processor\n",
        "    )\n",
        "\n",
        "    # # Visualize some images from the training dataset (do this w/o the remove_columns=[\"image\"])\n",
        "    # # Initialize a set to keep track of shown labels\n",
        "    # shown_labels = set()\n",
        "\n",
        "    # # Initialize the figure for plotting\n",
        "    # plt.figure(figsize=(15, 10))\n",
        "\n",
        "    # # Loop through the dataset and plot the first image of each label\n",
        "    # for i, sample in enumerate(train_dataset):\n",
        "    #     label = sample[\"label\"]\n",
        "    #     image = sample[\"image\"]\n",
        "\n",
        "    #     # Check if the label has already been shown\n",
        "    #     if label not in shown_labels:\n",
        "    #         plt.subplot(1, len(id2label), len(shown_labels) + 1)\n",
        "    #         plt.imshow(image.convert(\"RGB\"))  # Convert to RGB if necessary\n",
        "    #         plt.title(id2label[label])  # Get label name\n",
        "    #         plt.axis(\"off\")\n",
        "    #         shown_labels.add(label)\n",
        "\n",
        "    #         # Stop if all labels have been shown\n",
        "    #         if len(shown_labels) == len(id2label):\n",
        "    #             break\n",
        "\n",
        "    # plt.show()\n",
        "\n",
        "    # Load the ViT model\n",
        "    model = ViTForImageClassification.from_pretrained(\n",
        "        config[\"model_name\"],\n",
        "        num_labels=len(id2label),\n",
        "        id2label=id2label,\n",
        "        label2id=label2id,\n",
        "        ignore_mismatched_sizes=True\n",
        "    )\n",
        "\n",
        "    # Define training arguments\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=f\"./results/{config['experiment_name']}\",\n",
        "        per_device_train_batch_size=config[\"batch_size\"],\n",
        "        per_device_eval_batch_size=config[\"batch_size\"],\n",
        "        num_train_epochs=config[\"num_epochs\"],\n",
        "        weight_decay=config[\"weight_decay\"],\n",
        "        eval_strategy=\"steps\",\n",
        "        save_strategy=\"steps\",\n",
        "        logging_strategy=\"steps\",  # Ensure logging is enabled\n",
        "        logging_steps=10,          # Log every 10 steps (adjust as needed)\n",
        "        load_best_model_at_end=True,\n",
        "        metric_for_best_model=\"accuracy\",\n",
        "        push_to_hub=False,\n",
        "        report_to=\"wandb\",\n",
        "        remove_unused_columns=False,\n",
        "        learning_rate=config[\"learning_rate\"],\n",
        "    )\n",
        "\n",
        "    # Setup optimizer\n",
        "    # if config[\"optimizer_name\"] == \"AdamW\":\n",
        "    #     optimizer = AdamW(model.parameters(), lr=config[\"learning_rate\"])\n",
        "    # else:  # SGD\n",
        "    #     optimizer = SGD(model.parameters(), lr=config[\"learning_rate\"], momentum=0.9)\n",
        "\n",
        "    if config[\"optimizer_name\"] == \"schedule_free_adamw\":\n",
        "        optimizer = AdamWScheduleFree(model.parameters(), lr=config[\"learning_rate\"])\n",
        "    elif config[\"optimizer_name\"] == \"AdamW\":\n",
        "        optimizer = AdamW(model.parameters(), lr=config[\"learning_rate\"])\n",
        "    elif config[\"optimizer_name\"] == \"SGD\":\n",
        "        optimizer = SGD(model.parameters(), lr=config[\"learning_rate\"], momentum=0.9)\n",
        "    elif config[\"optimizer_name\"] == \"RMSProp\":\n",
        "        optimizer = torch.optim.RMSprop(model.parameters(), lr=config[\"learning_rate\"])\n",
        "    elif config[\"optimizer_name\"] == \"AdaGrad\":\n",
        "        optimizer = torch.optim.Adagrad(model.parameters(), lr=config[\"learning_rate\"])\n",
        "    else:\n",
        "        raise ValueError(f\"Optimizer {config['optimizer_name']} not supported\")\n",
        "\n",
        "    # Setup scheduler\n",
        "    num_training_steps = len(train_dataset) // config[\"batch_size\"] * config[\"num_epochs\"]\n",
        "    num_warmup_steps = int(num_training_steps * config[\"warmup_ratio\"]) if \"warmup_ratio\" in config else 0\n",
        "\n",
        "    scheduler_name = config[\"scheduler_name\"]\n",
        "    if scheduler_name == \"linear\":\n",
        "        scheduler = get_scheduler(\n",
        "            \"linear\",\n",
        "            optimizer=optimizer,\n",
        "            num_warmup_steps=num_warmup_steps,\n",
        "            num_training_steps=num_training_steps\n",
        "        )\n",
        "    elif scheduler_name == \"cosine\":\n",
        "        scheduler = get_scheduler(\n",
        "            \"cosine\",\n",
        "            optimizer=optimizer,\n",
        "            num_warmup_steps=num_warmup_steps,\n",
        "            num_training_steps=num_training_steps\n",
        "        )\n",
        "    \n",
        "    elif scheduler_name == \"polynomial\":\n",
        "        scheduler = get_scheduler(\n",
        "            \"polynomial\",\n",
        "            optimizer=optimizer,\n",
        "            num_warmup_steps=num_warmup_steps,\n",
        "            num_training_steps=num_training_steps,\n",
        "            # power=config.get(\"poly_power\", 1.0),\n",
        "        )\n",
        "    elif scheduler_name == \"cyclic\":\n",
        "        # CyclicLR from torch.optim.lr_scheduler\n",
        "        # Using step_size_up as 1/3 of training steps and step_size_down as 2/3\n",
        "        step_size_up = num_training_steps // 3\n",
        "        scheduler = CyclicLR(\n",
        "            optimizer,\n",
        "            base_lr=config[\"learning_rate\"] / 10,  # Lower bound of cycle\n",
        "            max_lr=config[\"learning_rate\"],       # Upper bound of cycle\n",
        "            step_size_up=step_size_up,\n",
        "            step_size_down=step_size_up * 2,\n",
        "            mode='triangular',                    # Three modes: triangular, triangular2, exp_range\n",
        "            cycle_momentum=False                  # Don't cycle momentum\n",
        "        )\n",
        "    elif scheduler_name == \"exponential\":\n",
        "        # ExponentialLR from torch.optim.lr_scheduler\n",
        "        # gamma < 1.0 for decay, common values: 0.9, 0.95, 0.99\n",
        "        scheduler = ExponentialLR(optimizer, gamma=0.95)\n",
        "\n",
        "    # elif scheduler_name == \"adaptive\":\n",
        "    #     # ReduceLROnPlateau - reduces LR when metric stops improving\n",
        "    #     # This requires modification to the training loop to update based on validation performance\n",
        "    #     scheduler = ReduceLROnPlateau(\n",
        "    #         optimizer, \n",
        "    #         mode='max',              # Since we want to maximize accuracy\n",
        "    #         factor=0.5,              # Multiply LR by this factor when plateauing\n",
        "    #         patience=2,              # Number of epochs with no improvement after which LR will be reduced\n",
        "    #         threshold=0.01,          # Threshold for measuring improvement\n",
        "    #         threshold_mode='rel',    # Interpret threshold as relative change\n",
        "    #         min_lr=1e-6              # Lower bound on the learning rate\n",
        "    #     )\n",
        "\n",
        "    elif scheduler_name == \"constant\":\n",
        "        scheduler = get_scheduler(\n",
        "            \"constant\",\n",
        "            optimizer=optimizer,\n",
        "        )\n",
        "    elif scheduler_name == \"cosine_with_restarts\":\n",
        "        scheduler = get_scheduler(\n",
        "            \"cosine_with_restarts\",\n",
        "            optimizer=optimizer,\n",
        "            num_warmup_steps=num_warmup_steps,\n",
        "            num_training_steps=num_training_steps,\n",
        "        )\n",
        "    elif scheduler_name == \"constant_with_warmup\":\n",
        "        scheduler = get_scheduler(\n",
        "            \"constant_with_warmup\",\n",
        "            optimizer=optimizer,\n",
        "            num_warmup_steps=num_warmup_steps,\n",
        "        )\n",
        "    # add more experiments if required ...\n",
        "\n",
        "    else:\n",
        "        raise ValueError(f\"Scheduler {scheduler_name} not supported\")\n",
        "\n",
        "    # Initialize Trainer\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=train_dataset,\n",
        "        eval_dataset=val_dataset,\n",
        "        compute_metrics=compute_metrics,\n",
        "        optimizers=(optimizer, scheduler)\n",
        "    )\n",
        "\n",
        "    # # Loss validation curve in the training loop to log metrics to W&B\n",
        "    # for epoch in range(config[\"num_epochs\"]):\n",
        "    #     print(f\"Epoch {epoch + 1}/{config['num_epochs']}\")\n",
        "\n",
        "    #     # Train for one epoch\n",
        "    #     trainer.train()\n",
        "\n",
        "    #     # Evaluate on validation set\n",
        "    #     eval_results = trainer.evaluate(val_dataset)\n",
        "\n",
        "    #     print(trainer.state.log_history)\n",
        "    #     if trainer.state.log_history and \"loss\" in trainer.state.log_history[-1]:\n",
        "    #         train_loss = trainer.state.log_history[-1][\"loss\"]\n",
        "    #     else:\n",
        "    #         train_loss = None\n",
        "\n",
        "    #     # Log training and validation metrics to W&B\n",
        "    #     wandb.log({\n",
        "    #         \"epoch\": epoch + 1,\n",
        "    #         \"train_loss\": trainer.state.log_history[-1].get(\"loss\", None),\n",
        "    #         \"val_loss\": eval_results[\"eval_loss\"],\n",
        "    #         \"val_accuracy\": eval_results[\"eval_accuracy\"],\n",
        "    #     })\n",
        "\n",
        "    # # Loss epoch curve in the training loop to log metrics to W&B\n",
        "    # for epoch in range(config[\"num_epochs\"]):\n",
        "    #     print(f\"Epoch {epoch + 1}/{config['num_epochs']}\")\n",
        "\n",
        "    #     # Train for one epoch\n",
        "    #     trainer.train()\n",
        "\n",
        "    #     # Evaluate on validation set\n",
        "    #     eval_results = trainer.evaluate(val_dataset)\n",
        "\n",
        "    #     # Extract training loss from the trainer's state\n",
        "    #     if trainer.state.log_history and \"loss\" in trainer.state.log_history[-1]:\n",
        "    #         train_loss = trainer.state.log_history[-1][\"loss\"]\n",
        "    #     else:\n",
        "    #         train_loss = None  # Handle missing loss gracefully\n",
        "\n",
        "    #     # Log training and validation metrics to W&B\n",
        "    #     wandb.log({\n",
        "    #         \"epoch\": epoch + 1,\n",
        "    #         \"train_loss\": train_loss,                  # Training loss\n",
        "    #         \"val_loss\": eval_results[\"eval_loss\"],    # Validation loss\n",
        "    #         \"val_accuracy\": eval_results[\"eval_accuracy\"],  # Validation accuracy\n",
        "    #     })\n",
        "\n",
        "    # Train the model\n",
        "    print(f\"Starting training for {config['experiment_name']}...\")\n",
        "    trainer.train()\n",
        "\n",
        "    # Evaluate the model\n",
        "    print(f\"Evaluating {config['experiment_name']}...\")\n",
        "    eval_results = trainer.evaluate(test_dataset)\n",
        "\n",
        "\n",
        "    # Log final metrics\n",
        "    wandb.log({\n",
        "        \"final_accuracy\": eval_results[\"eval_accuracy\"],\n",
        "        \"final_f1\": eval_results[\"eval_f1\"],\n",
        "        \"final_precision\": eval_results[\"eval_precision\"],\n",
        "        \"final_recall\": eval_results[\"eval_recall\"],\n",
        "    })\n",
        "\n",
        "    # Compute confusion matrix for test set\n",
        "    predictions, labels, _ = trainer.predict(test_dataset)\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "\n",
        "    # Convert to lists\n",
        "    labels = labels.tolist()\n",
        "    predictions = predictions.tolist()\n",
        "\n",
        "    # Log confusion matrix to W&B\n",
        "    wandb.log({\n",
        "        \"confusion_matrix_test\": wandb.plot.confusion_matrix(\n",
        "            probs=None,\n",
        "            y_true=labels,\n",
        "            preds=predictions,\n",
        "            class_names=[str(i) for i in range(len(np.unique(labels)))]\n",
        "        )\n",
        "    })\n",
        "\n",
        "\n",
        "\n",
        "    # Save the model\n",
        "    trainer.save_model(f\"./saved_models/{config['experiment_name']}\")\n",
        "\n",
        "    # Finish wandb run\n",
        "    # wandb.finish()\n",
        "\n",
        "    return eval_results\n",
        "\n",
        "# Get experiment configurations for challenging datasets\n",
        "def get_experiment_configs():\n",
        "    # We'll use a more complex dataset from Hugging Face\n",
        "    base_config = {\n",
        "        \"model_name\": \"google/vit-base-patch16-224-in21k\",\n",
        "        \"dataset_name\": \"jbarat/plant_species\",  # Any challenging dataset.\n",
        "        \"batch_size\": 16,\n",
        "        \"num_epochs\": 10, # let's keep smaller number to begin with.\n",
        "        \"weight_decay\": 0.01,\n",
        "        # \"optimizer_name\": \"AdamW\",\n",
        "    }\n",
        "\n",
        "    # Optimizers with their corresponding learning rates\n",
        "    optimizers = {\n",
        "        \"schedule_free_adamw\": 0.0002,\n",
        "        \"AdamW\": 0.0002,\n",
        "        \"RMSProp\": 0.0002,\n",
        "        \"AdaGrad\": 0.0002,\n",
        "        \"SGD\": 0.02,\n",
        "    }\n",
        "\n",
        "    # Schedulers to test\n",
        "    schedulers = [\n",
        "        \"linear\",\n",
        "        \"cosine\",\n",
        "        \"polynomial\",\n",
        "        \"cyclic\",\n",
        "        \"exponential\",\n",
        "        # \"adaptive\",\n",
        "        \"constant\",\n",
        "        \"cosine_with_restarts\",\n",
        "        \"constant_with_warmup\",\n",
        "\n",
        "    ]\n",
        "\n",
        "\n",
        "\n",
        "    # Different learning rate scheduler configurations\n",
        "    configs = []\n",
        "    \n",
        "    # # Constant learning rate (baseline)\n",
        "    # configs.append({\n",
        "    #     **base_config,\n",
        "    #     \"experiment_name\": \"vit_constant_lr\",\n",
        "    #     \"learning_rate\": 2e-4,\n",
        "    #     \"scheduler_name\": \"constant\",\n",
        "    # })\n",
        "\n",
        "    for optimizer_name, learning_rate in optimizers.items():\n",
        "        for scheduler_name in schedulers:\n",
        "            config = {\n",
        "                **base_config,\n",
        "                \"experiment_name\": f\"{optimizer_name}_{scheduler_name}\",\n",
        "                \"optimizer_name\": optimizer_name,\n",
        "                \"learning_rate\": learning_rate,\n",
        "                \"scheduler_name\": scheduler_name,\n",
        "                \"warmup_ratio\": 0.1,  # Keep warmup ratio consistent\n",
        "            }\n",
        "            configs.append(config)\n",
        "\n",
        "\n",
        "    # # Cosine with restarts\n",
        "    # configs.append({\n",
        "    #     **base_config,\n",
        "    #     \"experiment_name\": \"vit_cosine_restarts\",\n",
        "    #     \"learning_rate\": 2e-4,\n",
        "    #     \"scheduler_name\": \"cosine_with_restarts\",\n",
        "    #     \"warmup_ratio\": 0.1,\n",
        "    # })\n",
        "    \n",
        "    # # Constant with warmup\n",
        "    # configs.append({\n",
        "    #     **base_config,\n",
        "    #     \"experiment_name\": \"vit_constant_warmup\",\n",
        "    #     \"learning_rate\": 2e-4,\n",
        "    #     \"scheduler_name\": \"constant_with_warmup\",\n",
        "    #     \"warmup_ratio\": 0.1,\n",
        "    # })\n",
        "\n",
        "    # # Linear decay\n",
        "    # configs.append({\n",
        "    #     **base_config,\n",
        "    #     \"experiment_name\": \"vit_linear_decay\",\n",
        "    #     \"learning_rate\": 5e-5,\n",
        "    #     \"scheduler_name\": \"linear\",\n",
        "    #     \"warmup_ratio\": 0.1,\n",
        "    # })\n",
        "\n",
        "    # # Cosine decay (commonly used with ViT)\n",
        "    # configs.append({\n",
        "    #     **base_config,\n",
        "    #     \"experiment_name\": \"vit_cosine_decay\",\n",
        "    #     \"learning_rate\": 5e-5,\n",
        "    #     \"scheduler_name\": \"cosine\",\n",
        "    #     \"warmup_ratio\": 0.1,\n",
        "    # })\n",
        "\n",
        "\n",
        "    # # Polynomial decay\n",
        "    # configs.append({\n",
        "    #     **base_config,\n",
        "    #     \"experiment_name\": \"vit_polynomial\",\n",
        "    #     \"learning_rate\": 5e-5,\n",
        "    #     \"scheduler_name\": \"polynomial\",\n",
        "    #     \"warmup_ratio\": 0.1,\n",
        "    #     \"poly_power\": 2.0,\n",
        "    # })\n",
        "\n",
        "\n",
        "    # # Different learning rate experiments\n",
        "    # for lr in [1e-5, 3e-5, 1e-4]:\n",
        "    #     configs.append({\n",
        "    #         **base_config,\n",
        "    #         \"experiment_name\": f\"vit_cosine_lr_{lr}\",\n",
        "    #         \"learning_rate\": lr,\n",
        "    #         \"scheduler_name\": \"cosine\",\n",
        "    #         \"warmup_ratio\": 0.1,\n",
        "    #     })\n",
        "\n",
        "    # # Different optimizer experiments\n",
        "    # configs.append({\n",
        "    #     **base_config,\n",
        "    #     \"experiment_name\": \"vit_sgd_cosine\",\n",
        "    #     \"learning_rate\": 0.01,  # Higher LR for SGD\n",
        "    #     \"scheduler_name\": \"cosine\",\n",
        "    #     \"warmup_ratio\": 0.1,\n",
        "    #     \"optimizer_name\": \"SGD\",\n",
        "    # })\n",
        "\n",
        "    # here we can make changes to add new datasets to experiment.\n",
        "    # or change batch_size to see the impact.\n",
        "    # Other datasets to try (uncomment to use)\n",
        "    #   Erik: We can use a data set as a strech. Maybe something less similar than plants for better contrasting comparison?\n",
        "    # flowers dataset\n",
        "    # configs.append({\n",
        "    #     **base_config,\n",
        "    #     \"dataset_name\": \"huggan/flowers\",\n",
        "    #     \"experiment_name\": \"vit_flowers_cosine\",\n",
        "    #     \"learning_rate\": 5e-5,\n",
        "    #     \"scheduler_name\": \"cosine\",\n",
        "    #     \"warmup_ratio\": 0.1,\n",
        "    # })\n",
        "\n",
        "    return configs\n",
        "\n",
        "# Run experiments and visualize results\n",
        "def run_all_experiments():\n",
        "    configs = get_experiment_configs()\n",
        "    results = []\n",
        "\n",
        "    for config in configs:\n",
        "        print(f\"\\n{'='*50}\")\n",
        "        print(f\"Running experiment: {config['experiment_name']}\")\n",
        "        print(f\"{'='*50}\\n\")\n",
        "\n",
        "        eval_results = run_vit_experiment(config)\n",
        "        results.append({\n",
        "            \"experiment\": config['experiment_name'],\n",
        "            \"accuracy\": eval_results[\"eval_accuracy\"],\n",
        "            \"f1\": eval_results[\"eval_f1\"],\n",
        "            \"precision\": eval_results[\"eval_precision\"],\n",
        "            \"recall\": eval_results[\"eval_recall\"],\n",
        "            \"config\": config\n",
        "        })\n",
        "\n",
        "    # Make sure to close the final run\n",
        "    if wandb.run is not None:\n",
        "        wandb.finish()\n",
        "\n",
        "    return results\n",
        "\n",
        "# Visualize and compare results\n",
        "def visualize_results(results):\n",
        "    # Create DataFrame for easier plotting\n",
        "    df = pd.DataFrame([\n",
        "        {\n",
        "            \"Experiment\": result[\"experiment\"],\n",
        "            \"Accuracy\": result[\"accuracy\"],\n",
        "            \"F1 Score\": result[\"f1\"],\n",
        "            \"Precision\": result[\"precision\"],\n",
        "            \"Recall\": result[\"recall\"],\n",
        "            \"Learning Rate\": result[\"config\"][\"learning_rate\"],\n",
        "            \"Scheduler\": result[\"config\"][\"scheduler_name\"],\n",
        "            \"Optimizer\": result[\"config\"][\"optimizer_name\"],\n",
        "            \"Dataset\": result[\"config\"][\"dataset_name\"]\n",
        "        }\n",
        "        for result in results\n",
        "    ])\n",
        "\n",
        "    # Plot accuracy comparison\n",
        "    plt.figure(figsize=(14, 8))\n",
        "    ax = plt.bar(df[\"Experiment\"], df[\"Accuracy\"], color='skyblue')\n",
        "    plt.xlabel('Experiment')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.title('Comparison of Model Accuracy Across Experiments')\n",
        "    plt.xticks(rotation=45, ha='right')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(\"accuracy_comparison.png\")\n",
        "    plt.close()\n",
        "\n",
        "    # Plot all metrics for a more comprehensive comparison\n",
        "    plt.figure(figsize=(16, 10))\n",
        "    metrics = [\"Accuracy\", \"F1 Score\", \"Precision\", \"Recall\"]\n",
        "    x = np.arange(len(df[\"Experiment\"]))\n",
        "    width = 0.2\n",
        "\n",
        "    for i, metric in enumerate(metrics):\n",
        "        plt.bar(x + i*width, df[metric], width=width, label=metric)\n",
        "\n",
        "    plt.xlabel('Experiment')\n",
        "    plt.ylabel('Score')\n",
        "    plt.title('Comparison of Metrics Across Experiments')\n",
        "    plt.xticks(x + width*1.5, df[\"Experiment\"], rotation=45, ha='right')\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(\"metrics_comparison.png\")\n",
        "    plt.close()\n",
        "\n",
        "    # Plot results by scheduler type\n",
        "    plt.figure(figsize=(14, 8))\n",
        "    schedulers = df[\"Scheduler\"].unique()\n",
        "    for scheduler in schedulers:\n",
        "        scheduler_data = df[df[\"Scheduler\"] == scheduler]\n",
        "        plt.plot(scheduler_data[\"Learning Rate\"], scheduler_data[\"Accuracy\"], 'o-', label=scheduler)\n",
        "\n",
        "    plt.xlabel('Learning Rate')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.title('Accuracy vs. Learning Rate by Scheduler Type')\n",
        "    plt.xscale('log')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(\"scheduler_comparison.png\")\n",
        "    plt.close()\n",
        "\n",
        "    # Create a table with results\n",
        "    print(\"Results Summary:\")\n",
        "    print(df[[\"Experiment\", \"Accuracy\", \"F1 Score\", \"Precision\", \"Recall\", \"Scheduler\", \"Learning Rate\", \"Optimizer\", \"Dataset\"]])\n",
        "\n",
        "    # Save results to CSV\n",
        "    df.to_csv(\"experiment_results.csv\", index=False)\n",
        "\n",
        "    return df\n",
        "\n",
        "# Function to run a single experiment (useful for testing)\n",
        "def run_single_experiment(experiment_index=0):\n",
        "    configs = get_experiment_configs()\n",
        "    if experiment_index >= len(configs):\n",
        "        print(f\"Invalid experiment index. Choose between 0 and {len(configs)-1}\")\n",
        "        return\n",
        "\n",
        "    config = configs[experiment_index]\n",
        "    print(f\"Running single experiment: {config['experiment_name']}\")\n",
        "    eval_results = run_vit_experiment(config)\n",
        "\n",
        "    print(f\"\\nResults for {config['experiment_name']}:\")\n",
        "    print(f\"Accuracy: {eval_results['eval_accuracy']:.4f}\")\n",
        "    print(f\"F1 Score: {eval_results['eval_f1']:.4f}\")\n",
        "    print(f\"Precision: {eval_results['eval_precision']:.4f}\")\n",
        "    print(f\"Recall: {eval_results['eval_recall']:.4f}\")\n",
        "\n",
        "    return eval_results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "def run_optimizer_sweep():\n",
        "    # Initialize W&B run first, then access config\n",
        "    with wandb.init() as run:\n",
        "        print(f\"W&B initialized: {run.name}\")\n",
        "        \n",
        "        # Get config from sweep\n",
        "        config = wandb.config\n",
        "        \n",
        "        # Set experiment name based on sweep parameters\n",
        "        custom_name = f\"vit_{config.optimizer_name}_{config.learning_rate}\"\n",
        "        # Update the run name after initialization\n",
        "        wandb.run.name = custom_name\n",
        "        wandb.run.save()\n",
        "        \n",
        "        print(f\"Running experiment: {custom_name}\")\n",
        "        \n",
        "        # Load model and processor\n",
        "        model_name = \"google/vit-base-patch16-224-in21k\"\n",
        "        dataset_name = \"jbarat/plant_species\"\n",
        "        \n",
        "        # Load the image processor\n",
        "        image_processor = AutoImageProcessor.from_pretrained(model_name, use_fast=True)\n",
        "        \n",
        "        # Prepare dataset\n",
        "        train_dataset, val_dataset, test_dataset, id2label, label2id = prepare_dataset(\n",
        "            dataset_name, image_processor\n",
        "        )\n",
        "        \n",
        "        # Load the ViT model\n",
        "        model = ViTForImageClassification.from_pretrained(\n",
        "            model_name,\n",
        "            num_labels=len(id2label),\n",
        "            id2label=id2label,\n",
        "            label2id=label2id,\n",
        "            ignore_mismatched_sizes=True\n",
        "        )\n",
        "        \n",
        "        # Define training arguments\n",
        "        training_args = TrainingArguments(\n",
        "            output_dir=f\"./results/{custom_name}\",\n",
        "            per_device_train_batch_size=config.batch_size,\n",
        "            per_device_eval_batch_size=config.batch_size,\n",
        "            num_train_epochs=config.num_epochs,\n",
        "            weight_decay=0.01,\n",
        "            eval_strategy=\"steps\",\n",
        "            save_strategy=\"steps\",\n",
        "            logging_strategy=\"steps\",\n",
        "            logging_steps=10,\n",
        "            load_best_model_at_end=True,\n",
        "            metric_for_best_model=\"accuracy\",\n",
        "            push_to_hub=False,\n",
        "            report_to=\"wandb\",\n",
        "            remove_unused_columns=False,\n",
        "            learning_rate=config.learning_rate,\n",
        "        )\n",
        "        # Set up optimizer based on config\n",
        "        if config.optimizer_name == \"schedule_free_adamw\":\n",
        "            optimizer = AdamWScheduleFree(\n",
        "                model.parameters(),\n",
        "                lr=config.learning_rate,  # Learning rate\n",
        "                # warmup_steps=500  # Optional: Adjust based on your dataset\n",
        "            )\n",
        "        elif config.optimizer_name == \"AdamW\":\n",
        "            optimizer = AdamW(model.parameters(), lr=config.learning_rate)\n",
        "        elif config.optimizer_name == \"SGD\":\n",
        "            optimizer = SGD(model.parameters(), lr=config.learning_rate, momentum=0.9)\n",
        "        elif config.optimizer_name == \"RMSProp\":\n",
        "            optimizer = torch.optim.RMSprop(model.parameters(), lr=config.learning_rate)\n",
        "        elif config.optimizer_name == \"AdaGrad\":\n",
        "            optimizer = torch.optim.Adagrad(model.parameters(), lr=config.learning_rate)\n",
        "        else:\n",
        "            optimizer = AdamW(model.parameters(), lr=config.learning_rate)        \n",
        "        \n",
        "        # Setup scheduler\n",
        "        num_training_steps = len(train_dataset) // config.batch_size * config.num_epochs\n",
        "        num_warmup_steps = int(num_training_steps * 0.1)  # 10% warmup\n",
        "        \n",
        "        scheduler = get_scheduler(\n",
        "            config.scheduler_name,\n",
        "            optimizer=optimizer,\n",
        "            num_warmup_steps=num_warmup_steps,\n",
        "            num_training_steps=num_training_steps\n",
        "        )\n",
        "        \n",
        "        # Initialize Trainer\n",
        "        trainer = Trainer(\n",
        "            model=model,\n",
        "            args=training_args,\n",
        "            train_dataset=train_dataset,\n",
        "            eval_dataset=val_dataset,\n",
        "            compute_metrics=compute_metrics,\n",
        "            optimizers=(optimizer, scheduler)\n",
        "        )\n",
        "        \n",
        "        # Train the model\n",
        "        print(f\"Starting training...\")\n",
        "        # optimizer.train()  # Switch optimizer to training mode only for schedule_free\n",
        "        trainer.train()\n",
        "        \n",
        "        # Evaluate on validation dataset\n",
        "        print(f\"Evaluating on validation set...\")\n",
        "        # optimizer.eval()  # Switch optimizer to evaluation mode only for schedule_free\n",
        "        eval_results = trainer.evaluate(val_dataset)\n",
        "        \n",
        "        # Log validation metrics\n",
        "        run.log({\n",
        "            \"val_accuracy\": eval_results[\"eval_accuracy\"],\n",
        "            \"val_f1\": eval_results[\"eval_f1\"],\n",
        "            \"val_precision\": eval_results[\"eval_precision\"],\n",
        "            \"val_recall\": eval_results[\"eval_recall\"],\n",
        "            \"val_loss\": eval_results[\"eval_loss\"]\n",
        "        })\n",
        "        \n",
        "        # Evaluate on test dataset\n",
        "        print(f\"Evaluating on test set...\")\n",
        "        test_results = trainer.evaluate(test_dataset)\n",
        "        \n",
        "        # Log test metrics\n",
        "        run.log({\n",
        "            \"test_accuracy\": test_results[\"eval_accuracy\"],\n",
        "            \"test_f1\": test_results[\"eval_f1\"],\n",
        "            \"test_precision\": test_results[\"eval_precision\"],\n",
        "            \"test_recall\": test_results[\"eval_recall\"],\n",
        "            \"test_loss\": test_results[\"eval_loss\"]\n",
        "        })\n",
        "        \n",
        "        # Compute confusion matrix for test set\n",
        "        predictions, labels, _ = trainer.predict(test_dataset)\n",
        "        predictions = np.argmax(predictions, axis=1)\n",
        "        \n",
        "        # Log confusion matrix\n",
        "        run.log({\n",
        "            \"confusion_matrix\": wandb.plot.confusion_matrix(\n",
        "                probs=None,\n",
        "                y_true=labels.tolist(),\n",
        "                preds=predictions.tolist(),\n",
        "                class_names=[id2label[i] for i in range(len(id2label))]\n",
        "            )\n",
        "        })\n",
        "        \n",
        "        # Save the model\n",
        "        model_path = f\"./saved_models/{custom_name}\"\n",
        "        trainer.save_model(model_path)\n",
        "        print(f\"Model saved to {model_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "AgLdeTtFtIgc",
        "outputId": "457c59b4-f96e-4fbd-cd24-e66e95d759c5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting ViT experiments with different learning rate schedulers...\n",
            "\n",
            "==================================================\n",
            "Running experiment: schedule_free_adamw_linear\n",
            "==================================================\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mewg\u001b[0m (\u001b[33mdl_project_sp25\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Using a boolean value for 'reinit' is deprecated. Use 'return_previous' or 'finish_previous' instead.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/Users/egoh02/Github/CS7643-Project-SP25/wandb/run-20250420_015637-trdw894k</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/trdw894k' target=\"_blank\">schedule_free_adamw_linear</a></strong> to <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/trdw894k' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/trdw894k</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading dataset: jbarat/plant_species\n",
            "Dataset prepared with 640 training, 128 validation, and 32 test examples\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting training for schedule_free_adamw_linear...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='40' max='40' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [40/40 01:34, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>1.969000</td>\n",
              "      <td>1.785059</td>\n",
              "      <td>0.562500</td>\n",
              "      <td>0.536508</td>\n",
              "      <td>0.570873</td>\n",
              "      <td>0.562500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>1.660900</td>\n",
              "      <td>1.534147</td>\n",
              "      <td>0.710938</td>\n",
              "      <td>0.693423</td>\n",
              "      <td>0.725606</td>\n",
              "      <td>0.710938</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>1.474700</td>\n",
              "      <td>1.365635</td>\n",
              "      <td>0.742188</td>\n",
              "      <td>0.732892</td>\n",
              "      <td>0.756633</td>\n",
              "      <td>0.742188</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>1.300800</td>\n",
              "      <td>1.264886</td>\n",
              "      <td>0.796875</td>\n",
              "      <td>0.791564</td>\n",
              "      <td>0.802535</td>\n",
              "      <td>0.796875</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating schedule_free_adamw_linear...\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "Running experiment: schedule_free_adamw_cosine\n",
            "==================================================\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▅▆█▅</td></tr><tr><td>eval/f1</td><td>▁▅▆█▅</td></tr><tr><td>eval/loss</td><td>█▅▂▁▁</td></tr><tr><td>eval/precision</td><td>▁▆▇█▇</td></tr><tr><td>eval/recall</td><td>▁▅▆█▅</td></tr><tr><td>eval/runtime</td><td>█▇▇▇▁</td></tr><tr><td>eval/samples_per_second</td><td>▁██▅▁</td></tr><tr><td>eval/steps_per_second</td><td>▁██▄▁</td></tr><tr><td>final_accuracy</td><td>▁</td></tr><tr><td>final_f1</td><td>▁</td></tr><tr><td>final_precision</td><td>▁</td></tr><tr><td>final_recall</td><td>▁</td></tr><tr><td>test/accuracy</td><td>▁</td></tr><tr><td>test/f1</td><td>▁</td></tr><tr><td>test/loss</td><td>▁</td></tr><tr><td>test/precision</td><td>▁</td></tr><tr><td>test/recall</td><td>▁</td></tr><tr><td>test/runtime</td><td>▁</td></tr><tr><td>test/samples_per_second</td><td>▁</td></tr><tr><td>test/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▃▃▆▆████</td></tr><tr><td>train/global_step</td><td>▁▁▃▃▆▆███████</td></tr><tr><td>train/grad_norm</td><td>▁▄▂█</td></tr><tr><td>train/learning_rate</td><td>█▆▃▁</td></tr><tr><td>train/loss</td><td>█▅▃▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.6875</td></tr><tr><td>eval/f1</td><td>0.66977</td></tr><tr><td>eval/loss</td><td>1.28794</td></tr><tr><td>eval/precision</td><td>0.75986</td></tr><tr><td>eval/recall</td><td>0.6875</td></tr><tr><td>eval/runtime</td><td>1.9481</td></tr><tr><td>eval/samples_per_second</td><td>16.426</td></tr><tr><td>eval/steps_per_second</td><td>1.027</td></tr><tr><td>final_accuracy</td><td>0.6875</td></tr><tr><td>final_f1</td><td>0.66977</td></tr><tr><td>final_precision</td><td>0.75986</td></tr><tr><td>final_recall</td><td>0.6875</td></tr><tr><td>test/accuracy</td><td>0.6875</td></tr><tr><td>test/f1</td><td>0.66977</td></tr><tr><td>test/loss</td><td>1.28794</td></tr><tr><td>test/precision</td><td>0.75986</td></tr><tr><td>test/recall</td><td>0.6875</td></tr><tr><td>test/runtime</td><td>1.7284</td></tr><tr><td>test/samples_per_second</td><td>18.514</td></tr><tr><td>test/steps_per_second</td><td>1.157</td></tr><tr><td>total_flos</td><td>4.959754037231616e+16</td></tr><tr><td>train/epoch</td><td>1</td></tr><tr><td>train/global_step</td><td>40</td></tr><tr><td>train/grad_norm</td><td>2.42234</td></tr><tr><td>train/learning_rate</td><td>1e-05</td></tr><tr><td>train/loss</td><td>1.3008</td></tr><tr><td>train_loss</td><td>1.60134</td></tr><tr><td>train_runtime</td><td>98.2977</td></tr><tr><td>train_samples_per_second</td><td>6.511</td></tr><tr><td>train_steps_per_second</td><td>0.407</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">schedule_free_adamw_linear</strong> at: <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/trdw894k' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/trdw894k</a><br> View project at: <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers</a><br>Synced 5 W&B file(s), 1 media file(s), 2 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250420_015637-trdw894k/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/Users/egoh02/Github/CS7643-Project-SP25/wandb/run-20250420_015828-obdb42vm</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/obdb42vm' target=\"_blank\">schedule_free_adamw_cosine</a></strong> to <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/obdb42vm' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/obdb42vm</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading dataset: jbarat/plant_species\n",
            "Dataset prepared with 640 training, 128 validation, and 32 test examples\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting training for schedule_free_adamw_cosine...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='40' max='40' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [40/40 01:47, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>2.004500</td>\n",
              "      <td>1.822906</td>\n",
              "      <td>0.523438</td>\n",
              "      <td>0.455945</td>\n",
              "      <td>0.441909</td>\n",
              "      <td>0.523438</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>1.673600</td>\n",
              "      <td>1.545436</td>\n",
              "      <td>0.703125</td>\n",
              "      <td>0.676473</td>\n",
              "      <td>0.704491</td>\n",
              "      <td>0.703125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>1.460400</td>\n",
              "      <td>1.359837</td>\n",
              "      <td>0.703125</td>\n",
              "      <td>0.680371</td>\n",
              "      <td>0.739692</td>\n",
              "      <td>0.703125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>1.328700</td>\n",
              "      <td>1.271814</td>\n",
              "      <td>0.703125</td>\n",
              "      <td>0.685395</td>\n",
              "      <td>0.765694</td>\n",
              "      <td>0.703125</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/egoh02/Github/CS7643-Project-SP25/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating schedule_free_adamw_cosine...\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "Running experiment: schedule_free_adamw_polynomial\n",
            "==================================================\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▇▇▇█</td></tr><tr><td>eval/f1</td><td>▁▇▇██</td></tr><tr><td>eval/loss</td><td>█▄▂▁▁</td></tr><tr><td>eval/precision</td><td>▁▇▇██</td></tr><tr><td>eval/recall</td><td>▁▇▇▇█</td></tr><tr><td>eval/runtime</td><td>▆▇██▁</td></tr><tr><td>eval/samples_per_second</td><td>██▇▇▁</td></tr><tr><td>eval/steps_per_second</td><td>██▇▇▁</td></tr><tr><td>final_accuracy</td><td>▁</td></tr><tr><td>final_f1</td><td>▁</td></tr><tr><td>final_precision</td><td>▁</td></tr><tr><td>final_recall</td><td>▁</td></tr><tr><td>test/accuracy</td><td>▁</td></tr><tr><td>test/f1</td><td>▁</td></tr><tr><td>test/loss</td><td>▁</td></tr><tr><td>test/precision</td><td>▁</td></tr><tr><td>test/recall</td><td>▁</td></tr><tr><td>test/runtime</td><td>▁</td></tr><tr><td>test/samples_per_second</td><td>▁</td></tr><tr><td>test/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▃▃▆▆████</td></tr><tr><td>train/global_step</td><td>▁▁▃▃▆▆███████</td></tr><tr><td>train/grad_norm</td><td>▁▃█▇</td></tr><tr><td>train/learning_rate</td><td>█▆▃▁</td></tr><tr><td>train/loss</td><td>█▅▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.71875</td></tr><tr><td>eval/f1</td><td>0.70139</td></tr><tr><td>eval/loss</td><td>1.29235</td></tr><tr><td>eval/precision</td><td>0.76488</td></tr><tr><td>eval/recall</td><td>0.71875</td></tr><tr><td>eval/runtime</td><td>4.3331</td></tr><tr><td>eval/samples_per_second</td><td>7.385</td></tr><tr><td>eval/steps_per_second</td><td>0.462</td></tr><tr><td>final_accuracy</td><td>0.71875</td></tr><tr><td>final_f1</td><td>0.70139</td></tr><tr><td>final_precision</td><td>0.76488</td></tr><tr><td>final_recall</td><td>0.71875</td></tr><tr><td>test/accuracy</td><td>0.71875</td></tr><tr><td>test/f1</td><td>0.70139</td></tr><tr><td>test/loss</td><td>1.29235</td></tr><tr><td>test/precision</td><td>0.76488</td></tr><tr><td>test/recall</td><td>0.71875</td></tr><tr><td>test/runtime</td><td>1.7769</td></tr><tr><td>test/samples_per_second</td><td>18.008</td></tr><tr><td>test/steps_per_second</td><td>1.126</td></tr><tr><td>total_flos</td><td>4.959754037231616e+16</td></tr><tr><td>train/epoch</td><td>1</td></tr><tr><td>train/global_step</td><td>40</td></tr><tr><td>train/grad_norm</td><td>2.05916</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.3287</td></tr><tr><td>train_loss</td><td>1.61682</td></tr><tr><td>train_runtime</td><td>109.8028</td></tr><tr><td>train_samples_per_second</td><td>5.829</td></tr><tr><td>train_steps_per_second</td><td>0.364</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">schedule_free_adamw_cosine</strong> at: <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/obdb42vm' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/obdb42vm</a><br> View project at: <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers</a><br>Synced 5 W&B file(s), 1 media file(s), 2 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250420_015828-obdb42vm/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/Users/egoh02/Github/CS7643-Project-SP25/wandb/run-20250420_020036-cwyajqcv</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/cwyajqcv' target=\"_blank\">schedule_free_adamw_polynomial</a></strong> to <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/cwyajqcv' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/cwyajqcv</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading dataset: jbarat/plant_species\n",
            "Dataset prepared with 640 training, 128 validation, and 32 test examples\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting training for schedule_free_adamw_polynomial...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='40' max='40' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [40/40 01:29, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>2.005200</td>\n",
              "      <td>1.829432</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.437407</td>\n",
              "      <td>0.424158</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>1.694600</td>\n",
              "      <td>1.577289</td>\n",
              "      <td>0.679688</td>\n",
              "      <td>0.655775</td>\n",
              "      <td>0.678674</td>\n",
              "      <td>0.679688</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>1.498100</td>\n",
              "      <td>1.394659</td>\n",
              "      <td>0.703125</td>\n",
              "      <td>0.675911</td>\n",
              "      <td>0.758020</td>\n",
              "      <td>0.703125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>1.351500</td>\n",
              "      <td>1.293195</td>\n",
              "      <td>0.742188</td>\n",
              "      <td>0.737769</td>\n",
              "      <td>0.771663</td>\n",
              "      <td>0.742188</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating schedule_free_adamw_polynomial...\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "Running experiment: schedule_free_adamw_cyclic\n",
            "==================================================\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▆▇█▇</td></tr><tr><td>eval/f1</td><td>▁▆▇█▇</td></tr><tr><td>eval/loss</td><td>█▅▂▁▁</td></tr><tr><td>eval/precision</td><td>▁▆███</td></tr><tr><td>eval/recall</td><td>▁▆▇█▇</td></tr><tr><td>eval/runtime</td><td>█▇█▇▁</td></tr><tr><td>eval/samples_per_second</td><td>▅█▅█▁</td></tr><tr><td>eval/steps_per_second</td><td>▅█▅█▁</td></tr><tr><td>final_accuracy</td><td>▁</td></tr><tr><td>final_f1</td><td>▁</td></tr><tr><td>final_precision</td><td>▁</td></tr><tr><td>final_recall</td><td>▁</td></tr><tr><td>test/accuracy</td><td>▁</td></tr><tr><td>test/f1</td><td>▁</td></tr><tr><td>test/loss</td><td>▁</td></tr><tr><td>test/precision</td><td>▁</td></tr><tr><td>test/recall</td><td>▁</td></tr><tr><td>test/runtime</td><td>▁</td></tr><tr><td>test/samples_per_second</td><td>▁</td></tr><tr><td>test/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▃▃▆▆████</td></tr><tr><td>train/global_step</td><td>▁▁▃▃▆▆███████</td></tr><tr><td>train/grad_norm</td><td>▁▂▄█</td></tr><tr><td>train/learning_rate</td><td>█▆▃▁</td></tr><tr><td>train/loss</td><td>█▅▃▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.71875</td></tr><tr><td>eval/f1</td><td>0.70139</td></tr><tr><td>eval/loss</td><td>1.3112</td></tr><tr><td>eval/precision</td><td>0.76488</td></tr><tr><td>eval/recall</td><td>0.71875</td></tr><tr><td>eval/runtime</td><td>2.4683</td></tr><tr><td>eval/samples_per_second</td><td>12.964</td></tr><tr><td>eval/steps_per_second</td><td>0.81</td></tr><tr><td>final_accuracy</td><td>0.71875</td></tr><tr><td>final_f1</td><td>0.70139</td></tr><tr><td>final_precision</td><td>0.76488</td></tr><tr><td>final_recall</td><td>0.71875</td></tr><tr><td>test/accuracy</td><td>0.71875</td></tr><tr><td>test/f1</td><td>0.70139</td></tr><tr><td>test/loss</td><td>1.3112</td></tr><tr><td>test/precision</td><td>0.76488</td></tr><tr><td>test/recall</td><td>0.71875</td></tr><tr><td>test/runtime</td><td>1.748</td></tr><tr><td>test/samples_per_second</td><td>18.307</td></tr><tr><td>test/steps_per_second</td><td>1.144</td></tr><tr><td>total_flos</td><td>4.959754037231616e+16</td></tr><tr><td>train/epoch</td><td>1</td></tr><tr><td>train/global_step</td><td>40</td></tr><tr><td>train/grad_norm</td><td>2.09496</td></tr><tr><td>train/learning_rate</td><td>1e-05</td></tr><tr><td>train/loss</td><td>1.3515</td></tr><tr><td>train_loss</td><td>1.63735</td></tr><tr><td>train_runtime</td><td>91.6762</td></tr><tr><td>train_samples_per_second</td><td>6.981</td></tr><tr><td>train_steps_per_second</td><td>0.436</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">schedule_free_adamw_polynomial</strong> at: <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/cwyajqcv' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/cwyajqcv</a><br> View project at: <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers</a><br>Synced 5 W&B file(s), 1 media file(s), 2 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250420_020036-cwyajqcv/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/Users/egoh02/Github/CS7643-Project-SP25/wandb/run-20250420_020222-sm3vcjgd</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/sm3vcjgd' target=\"_blank\">schedule_free_adamw_cyclic</a></strong> to <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/sm3vcjgd' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/sm3vcjgd</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading dataset: jbarat/plant_species\n",
            "Dataset prepared with 640 training, 128 validation, and 32 test examples\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting training for schedule_free_adamw_cyclic...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='40' max='40' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [40/40 01:24, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>2.041400</td>\n",
              "      <td>1.918419</td>\n",
              "      <td>0.460938</td>\n",
              "      <td>0.430031</td>\n",
              "      <td>0.463105</td>\n",
              "      <td>0.460938</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>1.758900</td>\n",
              "      <td>1.617473</td>\n",
              "      <td>0.703125</td>\n",
              "      <td>0.685546</td>\n",
              "      <td>0.730205</td>\n",
              "      <td>0.703125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>1.494800</td>\n",
              "      <td>1.384420</td>\n",
              "      <td>0.671875</td>\n",
              "      <td>0.659804</td>\n",
              "      <td>0.704787</td>\n",
              "      <td>0.671875</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>1.325100</td>\n",
              "      <td>1.261860</td>\n",
              "      <td>0.726562</td>\n",
              "      <td>0.731078</td>\n",
              "      <td>0.746382</td>\n",
              "      <td>0.726562</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating schedule_free_adamw_cyclic...\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "Running experiment: schedule_free_adamw_exponential\n",
            "==================================================\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▇▇██</td></tr><tr><td>eval/f1</td><td>▁▇▆█▇</td></tr><tr><td>eval/loss</td><td>█▅▂▁▁</td></tr><tr><td>eval/precision</td><td>▁█▇██</td></tr><tr><td>eval/recall</td><td>▁▇▇██</td></tr><tr><td>eval/runtime</td><td>█▇▇▇▁</td></tr><tr><td>eval/samples_per_second</td><td>▄███▁</td></tr><tr><td>eval/steps_per_second</td><td>▄███▁</td></tr><tr><td>final_accuracy</td><td>▁</td></tr><tr><td>final_f1</td><td>▁</td></tr><tr><td>final_precision</td><td>▁</td></tr><tr><td>final_recall</td><td>▁</td></tr><tr><td>test/accuracy</td><td>▁</td></tr><tr><td>test/f1</td><td>▁</td></tr><tr><td>test/loss</td><td>▁</td></tr><tr><td>test/precision</td><td>▁</td></tr><tr><td>test/recall</td><td>▁</td></tr><tr><td>test/runtime</td><td>▁</td></tr><tr><td>test/samples_per_second</td><td>▁</td></tr><tr><td>test/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▃▃▆▆████</td></tr><tr><td>train/global_step</td><td>▁▁▃▃▆▆███████</td></tr><tr><td>train/grad_norm</td><td>▁▃▄█</td></tr><tr><td>train/learning_rate</td><td>▇█▅▁</td></tr><tr><td>train/loss</td><td>█▅▃▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.71875</td></tr><tr><td>eval/f1</td><td>0.70682</td></tr><tr><td>eval/loss</td><td>1.26214</td></tr><tr><td>eval/precision</td><td>0.7474</td></tr><tr><td>eval/recall</td><td>0.71875</td></tr><tr><td>eval/runtime</td><td>2.1355</td></tr><tr><td>eval/samples_per_second</td><td>14.985</td></tr><tr><td>eval/steps_per_second</td><td>0.937</td></tr><tr><td>final_accuracy</td><td>0.71875</td></tr><tr><td>final_f1</td><td>0.70682</td></tr><tr><td>final_precision</td><td>0.7474</td></tr><tr><td>final_recall</td><td>0.71875</td></tr><tr><td>test/accuracy</td><td>0.71875</td></tr><tr><td>test/f1</td><td>0.70682</td></tr><tr><td>test/loss</td><td>1.26214</td></tr><tr><td>test/precision</td><td>0.7474</td></tr><tr><td>test/recall</td><td>0.71875</td></tr><tr><td>test/runtime</td><td>1.7338</td></tr><tr><td>test/samples_per_second</td><td>18.456</td></tr><tr><td>test/steps_per_second</td><td>1.154</td></tr><tr><td>total_flos</td><td>4.959754037231616e+16</td></tr><tr><td>train/epoch</td><td>1</td></tr><tr><td>train/global_step</td><td>40</td></tr><tr><td>train/grad_norm</td><td>2.74462</td></tr><tr><td>train/learning_rate</td><td>2e-05</td></tr><tr><td>train/loss</td><td>1.3251</td></tr><tr><td>train_loss</td><td>1.65505</td></tr><tr><td>train_runtime</td><td>86.4712</td></tr><tr><td>train_samples_per_second</td><td>7.401</td></tr><tr><td>train_steps_per_second</td><td>0.463</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">schedule_free_adamw_cyclic</strong> at: <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/sm3vcjgd' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/sm3vcjgd</a><br> View project at: <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers</a><br>Synced 5 W&B file(s), 1 media file(s), 2 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250420_020222-sm3vcjgd/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/Users/egoh02/Github/CS7643-Project-SP25/wandb/run-20250420_020403-n0vognc4</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/n0vognc4' target=\"_blank\">schedule_free_adamw_exponential</a></strong> to <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/n0vognc4' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/n0vognc4</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading dataset: jbarat/plant_species\n",
            "Dataset prepared with 640 training, 128 validation, and 32 test examples\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting training for schedule_free_adamw_exponential...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='40' max='40' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [40/40 01:25, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>1.946400</td>\n",
              "      <td>1.808017</td>\n",
              "      <td>0.562500</td>\n",
              "      <td>0.527744</td>\n",
              "      <td>0.620940</td>\n",
              "      <td>0.562500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>1.702100</td>\n",
              "      <td>1.628185</td>\n",
              "      <td>0.671875</td>\n",
              "      <td>0.659342</td>\n",
              "      <td>0.690588</td>\n",
              "      <td>0.671875</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>1.581600</td>\n",
              "      <td>1.501522</td>\n",
              "      <td>0.687500</td>\n",
              "      <td>0.680385</td>\n",
              "      <td>0.716025</td>\n",
              "      <td>0.687500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>1.474000</td>\n",
              "      <td>1.410262</td>\n",
              "      <td>0.710938</td>\n",
              "      <td>0.700736</td>\n",
              "      <td>0.738974</td>\n",
              "      <td>0.710938</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating schedule_free_adamw_exponential...\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "Running experiment: schedule_free_adamw_constant\n",
            "==================================================\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▆▇█▂</td></tr><tr><td>eval/f1</td><td>▁▆▇█▃</td></tr><tr><td>eval/loss</td><td>█▅▃▁▂</td></tr><tr><td>eval/precision</td><td>▁▅▇█▁</td></tr><tr><td>eval/recall</td><td>▁▆▇█▂</td></tr><tr><td>eval/runtime</td><td>████▁</td></tr><tr><td>eval/samples_per_second</td><td>▇███▁</td></tr><tr><td>eval/steps_per_second</td><td>▇███▁</td></tr><tr><td>final_accuracy</td><td>▁</td></tr><tr><td>final_f1</td><td>▁</td></tr><tr><td>final_precision</td><td>▁</td></tr><tr><td>final_recall</td><td>▁</td></tr><tr><td>test/accuracy</td><td>▁</td></tr><tr><td>test/f1</td><td>▁</td></tr><tr><td>test/loss</td><td>▁</td></tr><tr><td>test/precision</td><td>▁</td></tr><tr><td>test/recall</td><td>▁</td></tr><tr><td>test/runtime</td><td>▁</td></tr><tr><td>test/samples_per_second</td><td>▁</td></tr><tr><td>test/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▃▃▆▆████</td></tr><tr><td>train/global_step</td><td>▁▁▃▃▆▆███████</td></tr><tr><td>train/grad_norm</td><td>▁█▄█</td></tr><tr><td>train/learning_rate</td><td>█▄▂▁</td></tr><tr><td>train/loss</td><td>█▄▃▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.59375</td></tr><tr><td>eval/f1</td><td>0.5875</td></tr><tr><td>eval/loss</td><td>1.45323</td></tr><tr><td>eval/precision</td><td>0.62202</td></tr><tr><td>eval/recall</td><td>0.59375</td></tr><tr><td>eval/runtime</td><td>2.1799</td></tr><tr><td>eval/samples_per_second</td><td>14.68</td></tr><tr><td>eval/steps_per_second</td><td>0.917</td></tr><tr><td>final_accuracy</td><td>0.59375</td></tr><tr><td>final_f1</td><td>0.5875</td></tr><tr><td>final_precision</td><td>0.62202</td></tr><tr><td>final_recall</td><td>0.59375</td></tr><tr><td>test/accuracy</td><td>0.59375</td></tr><tr><td>test/f1</td><td>0.5875</td></tr><tr><td>test/loss</td><td>1.45323</td></tr><tr><td>test/precision</td><td>0.62202</td></tr><tr><td>test/recall</td><td>0.59375</td></tr><tr><td>test/runtime</td><td>1.7446</td></tr><tr><td>test/samples_per_second</td><td>18.342</td></tr><tr><td>test/steps_per_second</td><td>1.146</td></tr><tr><td>total_flos</td><td>4.959754037231616e+16</td></tr><tr><td>train/epoch</td><td>1</td></tr><tr><td>train/global_step</td><td>40</td></tr><tr><td>train/grad_norm</td><td>2.44701</td></tr><tr><td>train/learning_rate</td><td>3e-05</td></tr><tr><td>train/loss</td><td>1.474</td></tr><tr><td>train_loss</td><td>1.67604</td></tr><tr><td>train_runtime</td><td>88.036</td></tr><tr><td>train_samples_per_second</td><td>7.27</td></tr><tr><td>train_steps_per_second</td><td>0.454</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">schedule_free_adamw_exponential</strong> at: <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/n0vognc4' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/n0vognc4</a><br> View project at: <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers</a><br>Synced 5 W&B file(s), 1 media file(s), 2 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250420_020403-n0vognc4/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/Users/egoh02/Github/CS7643-Project-SP25/wandb/run-20250420_020546-kzpsel24</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/kzpsel24' target=\"_blank\">schedule_free_adamw_constant</a></strong> to <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/kzpsel24' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/kzpsel24</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading dataset: jbarat/plant_species\n",
            "Dataset prepared with 640 training, 128 validation, and 32 test examples\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting training for schedule_free_adamw_constant...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='40' max='40' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [40/40 01:25, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>1.933900</td>\n",
              "      <td>1.765116</td>\n",
              "      <td>0.640625</td>\n",
              "      <td>0.621034</td>\n",
              "      <td>0.692215</td>\n",
              "      <td>0.640625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>1.604700</td>\n",
              "      <td>1.483805</td>\n",
              "      <td>0.726562</td>\n",
              "      <td>0.720873</td>\n",
              "      <td>0.746646</td>\n",
              "      <td>0.726562</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>1.370800</td>\n",
              "      <td>1.236748</td>\n",
              "      <td>0.765625</td>\n",
              "      <td>0.757758</td>\n",
              "      <td>0.790122</td>\n",
              "      <td>0.765625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>1.159600</td>\n",
              "      <td>1.081425</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.751156</td>\n",
              "      <td>0.775976</td>\n",
              "      <td>0.750000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating schedule_free_adamw_constant...\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "Running experiment: schedule_free_adamw_cosine_with_restarts\n",
            "==================================================\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▆█▇▇</td></tr><tr><td>eval/f1</td><td>▁▆██▇</td></tr><tr><td>eval/loss</td><td>█▅▃▁▁</td></tr><tr><td>eval/precision</td><td>▁▅█▇▇</td></tr><tr><td>eval/recall</td><td>▁▆█▇▇</td></tr><tr><td>eval/runtime</td><td>█▇▇▇▁</td></tr><tr><td>eval/samples_per_second</td><td>▁▇▇█▅</td></tr><tr><td>eval/steps_per_second</td><td>▁▇▇█▅</td></tr><tr><td>final_accuracy</td><td>▁</td></tr><tr><td>final_f1</td><td>▁</td></tr><tr><td>final_precision</td><td>▁</td></tr><tr><td>final_recall</td><td>▁</td></tr><tr><td>test/accuracy</td><td>▁</td></tr><tr><td>test/f1</td><td>▁</td></tr><tr><td>test/loss</td><td>▁</td></tr><tr><td>test/precision</td><td>▁</td></tr><tr><td>test/recall</td><td>▁</td></tr><tr><td>test/runtime</td><td>▁</td></tr><tr><td>test/samples_per_second</td><td>▁</td></tr><tr><td>test/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▃▃▆▆████</td></tr><tr><td>train/global_step</td><td>▁▁▃▃▆▆███████</td></tr><tr><td>train/grad_norm</td><td>▁▃█▆</td></tr><tr><td>train/learning_rate</td><td>▁▁▁▁</td></tr><tr><td>train/loss</td><td>█▅▃▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.75</td></tr><tr><td>eval/f1</td><td>0.73957</td></tr><tr><td>eval/loss</td><td>1.10172</td></tr><tr><td>eval/precision</td><td>0.77344</td></tr><tr><td>eval/recall</td><td>0.75</td></tr><tr><td>eval/runtime</td><td>1.7841</td></tr><tr><td>eval/samples_per_second</td><td>17.936</td></tr><tr><td>eval/steps_per_second</td><td>1.121</td></tr><tr><td>final_accuracy</td><td>0.75</td></tr><tr><td>final_f1</td><td>0.73957</td></tr><tr><td>final_precision</td><td>0.77344</td></tr><tr><td>final_recall</td><td>0.75</td></tr><tr><td>test/accuracy</td><td>0.75</td></tr><tr><td>test/f1</td><td>0.73957</td></tr><tr><td>test/loss</td><td>1.10172</td></tr><tr><td>test/precision</td><td>0.77344</td></tr><tr><td>test/recall</td><td>0.75</td></tr><tr><td>test/runtime</td><td>1.7272</td></tr><tr><td>test/samples_per_second</td><td>18.527</td></tr><tr><td>test/steps_per_second</td><td>1.158</td></tr><tr><td>total_flos</td><td>4.959754037231616e+16</td></tr><tr><td>train/epoch</td><td>1</td></tr><tr><td>train/global_step</td><td>40</td></tr><tr><td>train/grad_norm</td><td>2.23009</td></tr><tr><td>train/learning_rate</td><td>0.0002</td></tr><tr><td>train/loss</td><td>1.1596</td></tr><tr><td>train_loss</td><td>1.51724</td></tr><tr><td>train_runtime</td><td>87.7858</td></tr><tr><td>train_samples_per_second</td><td>7.29</td></tr><tr><td>train_steps_per_second</td><td>0.456</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">schedule_free_adamw_constant</strong> at: <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/kzpsel24' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/kzpsel24</a><br> View project at: <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers</a><br>Synced 5 W&B file(s), 1 media file(s), 2 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250420_020546-kzpsel24/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/Users/egoh02/Github/CS7643-Project-SP25/wandb/run-20250420_020729-49h0bldo</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/49h0bldo' target=\"_blank\">schedule_free_adamw_cosine_with_restarts</a></strong> to <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/49h0bldo' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/49h0bldo</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading dataset: jbarat/plant_species\n",
            "Dataset prepared with 640 training, 128 validation, and 32 test examples\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting training for schedule_free_adamw_cosine_with_restarts...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='40' max='40' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [40/40 01:25, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>2.004500</td>\n",
              "      <td>1.822906</td>\n",
              "      <td>0.523438</td>\n",
              "      <td>0.455945</td>\n",
              "      <td>0.441909</td>\n",
              "      <td>0.523438</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>1.673600</td>\n",
              "      <td>1.545436</td>\n",
              "      <td>0.703125</td>\n",
              "      <td>0.676473</td>\n",
              "      <td>0.704491</td>\n",
              "      <td>0.703125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>1.460400</td>\n",
              "      <td>1.359837</td>\n",
              "      <td>0.703125</td>\n",
              "      <td>0.680371</td>\n",
              "      <td>0.739692</td>\n",
              "      <td>0.703125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>1.328700</td>\n",
              "      <td>1.271814</td>\n",
              "      <td>0.703125</td>\n",
              "      <td>0.685395</td>\n",
              "      <td>0.765694</td>\n",
              "      <td>0.703125</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/egoh02/Github/CS7643-Project-SP25/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating schedule_free_adamw_cosine_with_restarts...\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "Running experiment: schedule_free_adamw_constant_with_warmup\n",
            "==================================================\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▇▇▇█</td></tr><tr><td>eval/f1</td><td>▁▇▇██</td></tr><tr><td>eval/loss</td><td>█▄▂▁▁</td></tr><tr><td>eval/precision</td><td>▁▇▇██</td></tr><tr><td>eval/recall</td><td>▁▇▇▇█</td></tr><tr><td>eval/runtime</td><td>▇▇▇█▁</td></tr><tr><td>eval/samples_per_second</td><td>███▇▁</td></tr><tr><td>eval/steps_per_second</td><td>███▇▁</td></tr><tr><td>final_accuracy</td><td>▁</td></tr><tr><td>final_f1</td><td>▁</td></tr><tr><td>final_precision</td><td>▁</td></tr><tr><td>final_recall</td><td>▁</td></tr><tr><td>test/accuracy</td><td>▁</td></tr><tr><td>test/f1</td><td>▁</td></tr><tr><td>test/loss</td><td>▁</td></tr><tr><td>test/precision</td><td>▁</td></tr><tr><td>test/recall</td><td>▁</td></tr><tr><td>test/runtime</td><td>▁</td></tr><tr><td>test/samples_per_second</td><td>▁</td></tr><tr><td>test/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▃▃▆▆████</td></tr><tr><td>train/global_step</td><td>▁▁▃▃▆▆███████</td></tr><tr><td>train/grad_norm</td><td>▁▃█▇</td></tr><tr><td>train/learning_rate</td><td>█▆▃▁</td></tr><tr><td>train/loss</td><td>█▅▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.71875</td></tr><tr><td>eval/f1</td><td>0.70139</td></tr><tr><td>eval/loss</td><td>1.29235</td></tr><tr><td>eval/precision</td><td>0.76488</td></tr><tr><td>eval/recall</td><td>0.71875</td></tr><tr><td>eval/runtime</td><td>3.8908</td></tr><tr><td>eval/samples_per_second</td><td>8.225</td></tr><tr><td>eval/steps_per_second</td><td>0.514</td></tr><tr><td>final_accuracy</td><td>0.71875</td></tr><tr><td>final_f1</td><td>0.70139</td></tr><tr><td>final_precision</td><td>0.76488</td></tr><tr><td>final_recall</td><td>0.71875</td></tr><tr><td>test/accuracy</td><td>0.71875</td></tr><tr><td>test/f1</td><td>0.70139</td></tr><tr><td>test/loss</td><td>1.29235</td></tr><tr><td>test/precision</td><td>0.76488</td></tr><tr><td>test/recall</td><td>0.71875</td></tr><tr><td>test/runtime</td><td>1.8178</td></tr><tr><td>test/samples_per_second</td><td>17.604</td></tr><tr><td>test/steps_per_second</td><td>1.1</td></tr><tr><td>total_flos</td><td>4.959754037231616e+16</td></tr><tr><td>train/epoch</td><td>1</td></tr><tr><td>train/global_step</td><td>40</td></tr><tr><td>train/grad_norm</td><td>2.05916</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.3287</td></tr><tr><td>train_loss</td><td>1.61682</td></tr><tr><td>train_runtime</td><td>87.4105</td></tr><tr><td>train_samples_per_second</td><td>7.322</td></tr><tr><td>train_steps_per_second</td><td>0.458</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">schedule_free_adamw_cosine_with_restarts</strong> at: <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/49h0bldo' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/49h0bldo</a><br> View project at: <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers</a><br>Synced 5 W&B file(s), 1 media file(s), 2 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250420_020729-49h0bldo/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/Users/egoh02/Github/CS7643-Project-SP25/wandb/run-20250420_020912-5mnpj8vx</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/5mnpj8vx' target=\"_blank\">schedule_free_adamw_constant_with_warmup</a></strong> to <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/5mnpj8vx' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/5mnpj8vx</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading dataset: jbarat/plant_species\n",
            "Dataset prepared with 640 training, 128 validation, and 32 test examples\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting training for schedule_free_adamw_constant_with_warmup...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='40' max='40' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [40/40 01:24, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>2.004300</td>\n",
              "      <td>1.820672</td>\n",
              "      <td>0.531250</td>\n",
              "      <td>0.466744</td>\n",
              "      <td>0.451774</td>\n",
              "      <td>0.531250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>1.662000</td>\n",
              "      <td>1.515369</td>\n",
              "      <td>0.718750</td>\n",
              "      <td>0.696790</td>\n",
              "      <td>0.728471</td>\n",
              "      <td>0.718750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>1.400500</td>\n",
              "      <td>1.253473</td>\n",
              "      <td>0.726562</td>\n",
              "      <td>0.708423</td>\n",
              "      <td>0.788283</td>\n",
              "      <td>0.726562</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>1.147000</td>\n",
              "      <td>1.078237</td>\n",
              "      <td>0.781250</td>\n",
              "      <td>0.781330</td>\n",
              "      <td>0.790185</td>\n",
              "      <td>0.781250</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating schedule_free_adamw_constant_with_warmup...\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "Running experiment: AdamW_linear\n",
            "==================================================\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▆▆▇█</td></tr><tr><td>eval/f1</td><td>▁▆▆▇█</td></tr><tr><td>eval/loss</td><td>█▅▃▁▁</td></tr><tr><td>eval/precision</td><td>▁▅▆▆█</td></tr><tr><td>eval/recall</td><td>▁▆▆▇█</td></tr><tr><td>eval/runtime</td><td>█▇█▇▁</td></tr><tr><td>eval/samples_per_second</td><td>▆▇▅█▁</td></tr><tr><td>eval/steps_per_second</td><td>▆▇▅█▁</td></tr><tr><td>final_accuracy</td><td>▁</td></tr><tr><td>final_f1</td><td>▁</td></tr><tr><td>final_precision</td><td>▁</td></tr><tr><td>final_recall</td><td>▁</td></tr><tr><td>test/accuracy</td><td>▁</td></tr><tr><td>test/f1</td><td>▁</td></tr><tr><td>test/loss</td><td>▁</td></tr><tr><td>test/precision</td><td>▁</td></tr><tr><td>test/recall</td><td>▁</td></tr><tr><td>test/runtime</td><td>▁</td></tr><tr><td>test/samples_per_second</td><td>▁</td></tr><tr><td>test/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▃▃▆▆████</td></tr><tr><td>train/global_step</td><td>▁▁▃▃▆▆███████</td></tr><tr><td>train/grad_norm</td><td>▁▂█▅</td></tr><tr><td>train/learning_rate</td><td>▁▁▁▁</td></tr><tr><td>train/loss</td><td>█▅▃▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.8125</td></tr><tr><td>eval/f1</td><td>0.81129</td></tr><tr><td>eval/loss</td><td>1.09211</td></tr><tr><td>eval/precision</td><td>0.89583</td></tr><tr><td>eval/recall</td><td>0.8125</td></tr><tr><td>eval/runtime</td><td>1.9812</td></tr><tr><td>eval/samples_per_second</td><td>16.152</td></tr><tr><td>eval/steps_per_second</td><td>1.009</td></tr><tr><td>final_accuracy</td><td>0.8125</td></tr><tr><td>final_f1</td><td>0.81129</td></tr><tr><td>final_precision</td><td>0.89583</td></tr><tr><td>final_recall</td><td>0.8125</td></tr><tr><td>test/accuracy</td><td>0.8125</td></tr><tr><td>test/f1</td><td>0.81129</td></tr><tr><td>test/loss</td><td>1.09211</td></tr><tr><td>test/precision</td><td>0.89583</td></tr><tr><td>test/recall</td><td>0.8125</td></tr><tr><td>test/runtime</td><td>1.7498</td></tr><tr><td>test/samples_per_second</td><td>18.288</td></tr><tr><td>test/steps_per_second</td><td>1.143</td></tr><tr><td>total_flos</td><td>4.959754037231616e+16</td></tr><tr><td>train/epoch</td><td>1</td></tr><tr><td>train/global_step</td><td>40</td></tr><tr><td>train/grad_norm</td><td>2.17794</td></tr><tr><td>train/learning_rate</td><td>0.0002</td></tr><tr><td>train/loss</td><td>1.147</td></tr><tr><td>train_loss</td><td>1.55345</td></tr><tr><td>train_runtime</td><td>86.0265</td></tr><tr><td>train_samples_per_second</td><td>7.44</td></tr><tr><td>train_steps_per_second</td><td>0.465</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">schedule_free_adamw_constant_with_warmup</strong> at: <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/5mnpj8vx' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/5mnpj8vx</a><br> View project at: <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers</a><br>Synced 5 W&B file(s), 1 media file(s), 2 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250420_020912-5mnpj8vx/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/Users/egoh02/Github/CS7643-Project-SP25/wandb/run-20250420_021050-hokxqdnb</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/hokxqdnb' target=\"_blank\">AdamW_linear</a></strong> to <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/hokxqdnb' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/hokxqdnb</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading dataset: jbarat/plant_species\n",
            "Dataset prepared with 640 training, 128 validation, and 32 test examples\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting training for AdamW_linear...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='40' max='40' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [40/40 01:25, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>1.975600</td>\n",
              "      <td>1.738839</td>\n",
              "      <td>0.601562</td>\n",
              "      <td>0.575367</td>\n",
              "      <td>0.706725</td>\n",
              "      <td>0.601562</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>1.588800</td>\n",
              "      <td>1.414873</td>\n",
              "      <td>0.695312</td>\n",
              "      <td>0.687290</td>\n",
              "      <td>0.786133</td>\n",
              "      <td>0.695312</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>1.384200</td>\n",
              "      <td>1.242133</td>\n",
              "      <td>0.742188</td>\n",
              "      <td>0.741756</td>\n",
              "      <td>0.794458</td>\n",
              "      <td>0.742188</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>1.246000</td>\n",
              "      <td>1.173809</td>\n",
              "      <td>0.781250</td>\n",
              "      <td>0.781559</td>\n",
              "      <td>0.801504</td>\n",
              "      <td>0.781250</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating AdamW_linear...\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "Running experiment: AdamW_cosine\n",
            "==================================================\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▅▆█▄</td></tr><tr><td>eval/f1</td><td>▁▅▇█▄</td></tr><tr><td>eval/loss</td><td>█▄▂▁▂</td></tr><tr><td>eval/precision</td><td>▁▇▇█▂</td></tr><tr><td>eval/recall</td><td>▁▅▆█▄</td></tr><tr><td>eval/runtime</td><td>███▇▁</td></tr><tr><td>eval/samples_per_second</td><td>▄▅▁█▁</td></tr><tr><td>eval/steps_per_second</td><td>▄▅▁█▁</td></tr><tr><td>final_accuracy</td><td>▁</td></tr><tr><td>final_f1</td><td>▁</td></tr><tr><td>final_precision</td><td>▁</td></tr><tr><td>final_recall</td><td>▁</td></tr><tr><td>test/accuracy</td><td>▁</td></tr><tr><td>test/f1</td><td>▁</td></tr><tr><td>test/loss</td><td>▁</td></tr><tr><td>test/precision</td><td>▁</td></tr><tr><td>test/recall</td><td>▁</td></tr><tr><td>test/runtime</td><td>▁</td></tr><tr><td>test/samples_per_second</td><td>▁</td></tr><tr><td>test/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▃▃▆▆████</td></tr><tr><td>train/global_step</td><td>▁▁▃▃▆▆███████</td></tr><tr><td>train/grad_norm</td><td>█▁▆▄</td></tr><tr><td>train/learning_rate</td><td>█▆▃▁</td></tr><tr><td>train/loss</td><td>█▄▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.6875</td></tr><tr><td>eval/f1</td><td>0.6776</td></tr><tr><td>eval/loss</td><td>1.21528</td></tr><tr><td>eval/precision</td><td>0.72619</td></tr><tr><td>eval/recall</td><td>0.6875</td></tr><tr><td>eval/runtime</td><td>1.771</td></tr><tr><td>eval/samples_per_second</td><td>18.069</td></tr><tr><td>eval/steps_per_second</td><td>1.129</td></tr><tr><td>final_accuracy</td><td>0.6875</td></tr><tr><td>final_f1</td><td>0.6776</td></tr><tr><td>final_precision</td><td>0.72619</td></tr><tr><td>final_recall</td><td>0.6875</td></tr><tr><td>test/accuracy</td><td>0.6875</td></tr><tr><td>test/f1</td><td>0.6776</td></tr><tr><td>test/loss</td><td>1.21528</td></tr><tr><td>test/precision</td><td>0.72619</td></tr><tr><td>test/recall</td><td>0.6875</td></tr><tr><td>test/runtime</td><td>1.7704</td></tr><tr><td>test/samples_per_second</td><td>18.075</td></tr><tr><td>test/steps_per_second</td><td>1.13</td></tr><tr><td>total_flos</td><td>4.959754037231616e+16</td></tr><tr><td>train/epoch</td><td>1</td></tr><tr><td>train/global_step</td><td>40</td></tr><tr><td>train/grad_norm</td><td>2.14549</td></tr><tr><td>train/learning_rate</td><td>1e-05</td></tr><tr><td>train/loss</td><td>1.246</td></tr><tr><td>train_loss</td><td>1.54865</td></tr><tr><td>train_runtime</td><td>87.659</td></tr><tr><td>train_samples_per_second</td><td>7.301</td></tr><tr><td>train_steps_per_second</td><td>0.456</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">AdamW_linear</strong> at: <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/hokxqdnb' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/hokxqdnb</a><br> View project at: <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers</a><br>Synced 5 W&B file(s), 1 media file(s), 2 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250420_021050-hokxqdnb/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/Users/egoh02/Github/CS7643-Project-SP25/wandb/run-20250420_021231-g8c0kf1e</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/g8c0kf1e' target=\"_blank\">AdamW_cosine</a></strong> to <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/g8c0kf1e' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/g8c0kf1e</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading dataset: jbarat/plant_species\n",
            "Dataset prepared with 640 training, 128 validation, and 32 test examples\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting training for AdamW_cosine...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='40' max='40' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [40/40 01:24, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>1.974200</td>\n",
              "      <td>1.728708</td>\n",
              "      <td>0.593750</td>\n",
              "      <td>0.569847</td>\n",
              "      <td>0.685227</td>\n",
              "      <td>0.593750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>1.567900</td>\n",
              "      <td>1.381277</td>\n",
              "      <td>0.695312</td>\n",
              "      <td>0.687373</td>\n",
              "      <td>0.769771</td>\n",
              "      <td>0.695312</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>1.350500</td>\n",
              "      <td>1.232498</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.743582</td>\n",
              "      <td>0.774330</td>\n",
              "      <td>0.750000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>1.247900</td>\n",
              "      <td>1.199448</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.746359</td>\n",
              "      <td>0.767571</td>\n",
              "      <td>0.750000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating AdamW_cosine...\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "Running experiment: AdamW_polynomial\n",
            "==================================================\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▆███</td></tr><tr><td>eval/f1</td><td>▁▆███</td></tr><tr><td>eval/loss</td><td>█▃▁▁▁</td></tr><tr><td>eval/precision</td><td>▁▆▆▆█</td></tr><tr><td>eval/recall</td><td>▁▆███</td></tr><tr><td>eval/runtime</td><td>████▁</td></tr><tr><td>eval/samples_per_second</td><td>▇▆█▂▁</td></tr><tr><td>eval/steps_per_second</td><td>▇▆█▂▁</td></tr><tr><td>final_accuracy</td><td>▁</td></tr><tr><td>final_f1</td><td>▁</td></tr><tr><td>final_precision</td><td>▁</td></tr><tr><td>final_recall</td><td>▁</td></tr><tr><td>test/accuracy</td><td>▁</td></tr><tr><td>test/f1</td><td>▁</td></tr><tr><td>test/loss</td><td>▁</td></tr><tr><td>test/precision</td><td>▁</td></tr><tr><td>test/recall</td><td>▁</td></tr><tr><td>test/runtime</td><td>▁</td></tr><tr><td>test/samples_per_second</td><td>▁</td></tr><tr><td>test/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▃▃▆▆████</td></tr><tr><td>train/global_step</td><td>▁▁▃▃▆▆███████</td></tr><tr><td>train/grad_norm</td><td>▁▇▆█</td></tr><tr><td>train/learning_rate</td><td>█▆▃▁</td></tr><tr><td>train/loss</td><td>█▄▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.75</td></tr><tr><td>eval/f1</td><td>0.73785</td></tr><tr><td>eval/loss</td><td>1.23107</td></tr><tr><td>eval/precision</td><td>0.81027</td></tr><tr><td>eval/recall</td><td>0.75</td></tr><tr><td>eval/runtime</td><td>1.7512</td></tr><tr><td>eval/samples_per_second</td><td>18.273</td></tr><tr><td>eval/steps_per_second</td><td>1.142</td></tr><tr><td>final_accuracy</td><td>0.75</td></tr><tr><td>final_f1</td><td>0.73785</td></tr><tr><td>final_precision</td><td>0.81027</td></tr><tr><td>final_recall</td><td>0.75</td></tr><tr><td>test/accuracy</td><td>0.75</td></tr><tr><td>test/f1</td><td>0.73785</td></tr><tr><td>test/loss</td><td>1.23107</td></tr><tr><td>test/precision</td><td>0.81027</td></tr><tr><td>test/recall</td><td>0.75</td></tr><tr><td>test/runtime</td><td>1.7301</td></tr><tr><td>test/samples_per_second</td><td>18.496</td></tr><tr><td>test/steps_per_second</td><td>1.156</td></tr><tr><td>total_flos</td><td>4.959754037231616e+16</td></tr><tr><td>train/epoch</td><td>1</td></tr><tr><td>train/global_step</td><td>40</td></tr><tr><td>train/grad_norm</td><td>2.22368</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.2479</td></tr><tr><td>train_loss</td><td>1.5351</td></tr><tr><td>train_runtime</td><td>86.1303</td></tr><tr><td>train_samples_per_second</td><td>7.431</td></tr><tr><td>train_steps_per_second</td><td>0.464</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">AdamW_cosine</strong> at: <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/g8c0kf1e' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/g8c0kf1e</a><br> View project at: <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers</a><br>Synced 5 W&B file(s), 1 media file(s), 2 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250420_021231-g8c0kf1e/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/Users/egoh02/Github/CS7643-Project-SP25/wandb/run-20250420_021410-sf20ptf4</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/sf20ptf4' target=\"_blank\">AdamW_polynomial</a></strong> to <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/sf20ptf4' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/sf20ptf4</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading dataset: jbarat/plant_species\n",
            "Dataset prepared with 640 training, 128 validation, and 32 test examples\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting training for AdamW_polynomial...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='40' max='40' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [40/40 01:24, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>1.975600</td>\n",
              "      <td>1.738788</td>\n",
              "      <td>0.601562</td>\n",
              "      <td>0.575367</td>\n",
              "      <td>0.706725</td>\n",
              "      <td>0.601562</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>1.589600</td>\n",
              "      <td>1.412154</td>\n",
              "      <td>0.687500</td>\n",
              "      <td>0.678462</td>\n",
              "      <td>0.772592</td>\n",
              "      <td>0.687500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>1.381400</td>\n",
              "      <td>1.238309</td>\n",
              "      <td>0.742188</td>\n",
              "      <td>0.739534</td>\n",
              "      <td>0.776489</td>\n",
              "      <td>0.742188</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>1.247400</td>\n",
              "      <td>1.172677</td>\n",
              "      <td>0.781250</td>\n",
              "      <td>0.781559</td>\n",
              "      <td>0.801504</td>\n",
              "      <td>0.781250</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating AdamW_polynomial...\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "Running experiment: AdamW_cyclic\n",
            "==================================================\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▄▆█▄</td></tr><tr><td>eval/f1</td><td>▁▄▇█▄</td></tr><tr><td>eval/loss</td><td>█▄▂▁▁</td></tr><tr><td>eval/precision</td><td>▁▆▆█▂</td></tr><tr><td>eval/recall</td><td>▁▄▆█▄</td></tr><tr><td>eval/runtime</td><td>████▁</td></tr><tr><td>eval/samples_per_second</td><td>▆▇▆█▁</td></tr><tr><td>eval/steps_per_second</td><td>▆▇▆█▁</td></tr><tr><td>final_accuracy</td><td>▁</td></tr><tr><td>final_f1</td><td>▁</td></tr><tr><td>final_precision</td><td>▁</td></tr><tr><td>final_recall</td><td>▁</td></tr><tr><td>test/accuracy</td><td>▁</td></tr><tr><td>test/f1</td><td>▁</td></tr><tr><td>test/loss</td><td>▁</td></tr><tr><td>test/precision</td><td>▁</td></tr><tr><td>test/recall</td><td>▁</td></tr><tr><td>test/runtime</td><td>▁</td></tr><tr><td>test/samples_per_second</td><td>▁</td></tr><tr><td>test/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▃▃▆▆████</td></tr><tr><td>train/global_step</td><td>▁▁▃▃▆▆███████</td></tr><tr><td>train/grad_norm</td><td>█▁▅▃</td></tr><tr><td>train/learning_rate</td><td>█▆▃▁</td></tr><tr><td>train/loss</td><td>█▄▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.6875</td></tr><tr><td>eval/f1</td><td>0.6776</td></tr><tr><td>eval/loss</td><td>1.20339</td></tr><tr><td>eval/precision</td><td>0.72619</td></tr><tr><td>eval/recall</td><td>0.6875</td></tr><tr><td>eval/runtime</td><td>1.7812</td></tr><tr><td>eval/samples_per_second</td><td>17.966</td></tr><tr><td>eval/steps_per_second</td><td>1.123</td></tr><tr><td>final_accuracy</td><td>0.6875</td></tr><tr><td>final_f1</td><td>0.6776</td></tr><tr><td>final_precision</td><td>0.72619</td></tr><tr><td>final_recall</td><td>0.6875</td></tr><tr><td>test/accuracy</td><td>0.6875</td></tr><tr><td>test/f1</td><td>0.6776</td></tr><tr><td>test/loss</td><td>1.20339</td></tr><tr><td>test/precision</td><td>0.72619</td></tr><tr><td>test/recall</td><td>0.6875</td></tr><tr><td>test/runtime</td><td>4.8267</td></tr><tr><td>test/samples_per_second</td><td>6.63</td></tr><tr><td>test/steps_per_second</td><td>0.414</td></tr><tr><td>total_flos</td><td>4.959754037231616e+16</td></tr><tr><td>train/epoch</td><td>1</td></tr><tr><td>train/global_step</td><td>40</td></tr><tr><td>train/grad_norm</td><td>2.16144</td></tr><tr><td>train/learning_rate</td><td>1e-05</td></tr><tr><td>train/loss</td><td>1.2474</td></tr><tr><td>train_loss</td><td>1.54849</td></tr><tr><td>train_runtime</td><td>86.0373</td></tr><tr><td>train_samples_per_second</td><td>7.439</td></tr><tr><td>train_steps_per_second</td><td>0.465</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">AdamW_polynomial</strong> at: <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/sf20ptf4' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/sf20ptf4</a><br> View project at: <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers</a><br>Synced 5 W&B file(s), 1 media file(s), 2 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250420_021410-sf20ptf4/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/Users/egoh02/Github/CS7643-Project-SP25/wandb/run-20250420_021553-u28gsx1s</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/u28gsx1s' target=\"_blank\">AdamW_cyclic</a></strong> to <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/u28gsx1s' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/u28gsx1s</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading dataset: jbarat/plant_species\n",
            "Dataset prepared with 640 training, 128 validation, and 32 test examples\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting training for AdamW_cyclic...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='40' max='40' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [40/40 01:24, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>2.024500</td>\n",
              "      <td>1.847460</td>\n",
              "      <td>0.570312</td>\n",
              "      <td>0.546791</td>\n",
              "      <td>0.637041</td>\n",
              "      <td>0.570312</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>1.667400</td>\n",
              "      <td>1.447330</td>\n",
              "      <td>0.718750</td>\n",
              "      <td>0.714054</td>\n",
              "      <td>0.758567</td>\n",
              "      <td>0.718750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>1.383900</td>\n",
              "      <td>1.216116</td>\n",
              "      <td>0.718750</td>\n",
              "      <td>0.701237</td>\n",
              "      <td>0.761840</td>\n",
              "      <td>0.718750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>1.207800</td>\n",
              "      <td>1.123825</td>\n",
              "      <td>0.765625</td>\n",
              "      <td>0.764782</td>\n",
              "      <td>0.793841</td>\n",
              "      <td>0.765625</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating AdamW_cyclic...\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "Running experiment: AdamW_exponential\n",
            "==================================================\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▆▆█▇</td></tr><tr><td>eval/f1</td><td>▁▆▆█▇</td></tr><tr><td>eval/loss</td><td>█▄▂▁▁</td></tr><tr><td>eval/precision</td><td>▁▅▅▆█</td></tr><tr><td>eval/recall</td><td>▁▆▆█▇</td></tr><tr><td>eval/runtime</td><td>▇▇█▇▁</td></tr><tr><td>eval/samples_per_second</td><td>██▇█▁</td></tr><tr><td>eval/steps_per_second</td><td>██▇█▁</td></tr><tr><td>final_accuracy</td><td>▁</td></tr><tr><td>final_f1</td><td>▁</td></tr><tr><td>final_precision</td><td>▁</td></tr><tr><td>final_recall</td><td>▁</td></tr><tr><td>test/accuracy</td><td>▁</td></tr><tr><td>test/f1</td><td>▁</td></tr><tr><td>test/loss</td><td>▁</td></tr><tr><td>test/precision</td><td>▁</td></tr><tr><td>test/recall</td><td>▁</td></tr><tr><td>test/runtime</td><td>▁</td></tr><tr><td>test/samples_per_second</td><td>▁</td></tr><tr><td>test/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▃▃▆▆████</td></tr><tr><td>train/global_step</td><td>▁▁▃▃▆▆███████</td></tr><tr><td>train/grad_norm</td><td>▁▂▅█</td></tr><tr><td>train/learning_rate</td><td>▇█▅▁</td></tr><tr><td>train/loss</td><td>█▅▃▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.75</td></tr><tr><td>eval/f1</td><td>0.74503</td></tr><tr><td>eval/loss</td><td>1.12907</td></tr><tr><td>eval/precision</td><td>0.86615</td></tr><tr><td>eval/recall</td><td>0.75</td></tr><tr><td>eval/runtime</td><td>2.5031</td></tr><tr><td>eval/samples_per_second</td><td>12.784</td></tr><tr><td>eval/steps_per_second</td><td>0.799</td></tr><tr><td>final_accuracy</td><td>0.75</td></tr><tr><td>final_f1</td><td>0.74503</td></tr><tr><td>final_precision</td><td>0.86615</td></tr><tr><td>final_recall</td><td>0.75</td></tr><tr><td>test/accuracy</td><td>0.75</td></tr><tr><td>test/f1</td><td>0.74503</td></tr><tr><td>test/loss</td><td>1.12907</td></tr><tr><td>test/precision</td><td>0.86615</td></tr><tr><td>test/recall</td><td>0.75</td></tr><tr><td>test/runtime</td><td>1.8888</td></tr><tr><td>test/samples_per_second</td><td>16.942</td></tr><tr><td>test/steps_per_second</td><td>1.059</td></tr><tr><td>total_flos</td><td>4.959754037231616e+16</td></tr><tr><td>train/epoch</td><td>1</td></tr><tr><td>train/global_step</td><td>40</td></tr><tr><td>train/grad_norm</td><td>2.69933</td></tr><tr><td>train/learning_rate</td><td>2e-05</td></tr><tr><td>train/loss</td><td>1.2078</td></tr><tr><td>train_loss</td><td>1.5709</td></tr><tr><td>train_runtime</td><td>87.027</td></tr><tr><td>train_samples_per_second</td><td>7.354</td></tr><tr><td>train_steps_per_second</td><td>0.46</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">AdamW_cyclic</strong> at: <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/u28gsx1s' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/u28gsx1s</a><br> View project at: <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers</a><br>Synced 5 W&B file(s), 1 media file(s), 2 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250420_021553-u28gsx1s/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/Users/egoh02/Github/CS7643-Project-SP25/wandb/run-20250420_021735-seoyy430</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/seoyy430' target=\"_blank\">AdamW_exponential</a></strong> to <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/seoyy430' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/seoyy430</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading dataset: jbarat/plant_species\n",
            "Dataset prepared with 640 training, 128 validation, and 32 test examples\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting training for AdamW_exponential...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='40' max='40' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [40/40 01:28, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>1.901300</td>\n",
              "      <td>1.687914</td>\n",
              "      <td>0.625000</td>\n",
              "      <td>0.588474</td>\n",
              "      <td>0.646874</td>\n",
              "      <td>0.625000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>1.579400</td>\n",
              "      <td>1.465805</td>\n",
              "      <td>0.718750</td>\n",
              "      <td>0.704750</td>\n",
              "      <td>0.755665</td>\n",
              "      <td>0.718750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>1.441900</td>\n",
              "      <td>1.325186</td>\n",
              "      <td>0.718750</td>\n",
              "      <td>0.707302</td>\n",
              "      <td>0.773397</td>\n",
              "      <td>0.718750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>1.334700</td>\n",
              "      <td>1.246722</td>\n",
              "      <td>0.757812</td>\n",
              "      <td>0.756578</td>\n",
              "      <td>0.790443</td>\n",
              "      <td>0.757812</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/egoh02/Github/CS7643-Project-SP25/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating AdamW_exponential...\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "Running experiment: AdamW_constant\n",
            "==================================================\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▆▆█▁</td></tr><tr><td>eval/f1</td><td>▁▆▆█▃</td></tr><tr><td>eval/loss</td><td>█▄▂▁▂</td></tr><tr><td>eval/precision</td><td>▁▆▇█▄</td></tr><tr><td>eval/recall</td><td>▁▆▆█▁</td></tr><tr><td>eval/runtime</td><td>█▇▇█▁</td></tr><tr><td>eval/samples_per_second</td><td>▄██▄▁</td></tr><tr><td>eval/steps_per_second</td><td>▄██▄▁</td></tr><tr><td>final_accuracy</td><td>▁</td></tr><tr><td>final_f1</td><td>▁</td></tr><tr><td>final_precision</td><td>▁</td></tr><tr><td>final_recall</td><td>▁</td></tr><tr><td>test/accuracy</td><td>▁</td></tr><tr><td>test/f1</td><td>▁</td></tr><tr><td>test/loss</td><td>▁</td></tr><tr><td>test/precision</td><td>▁</td></tr><tr><td>test/recall</td><td>▁</td></tr><tr><td>test/runtime</td><td>▁</td></tr><tr><td>test/samples_per_second</td><td>▁</td></tr><tr><td>test/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▃▃▆▆████</td></tr><tr><td>train/global_step</td><td>▁▁▃▃▆▆███████</td></tr><tr><td>train/grad_norm</td><td>▁▃▇█</td></tr><tr><td>train/learning_rate</td><td>█▄▂▁</td></tr><tr><td>train/loss</td><td>█▄▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.625</td></tr><tr><td>eval/f1</td><td>0.62969</td></tr><tr><td>eval/loss</td><td>1.31451</td></tr><tr><td>eval/precision</td><td>0.70379</td></tr><tr><td>eval/recall</td><td>0.625</td></tr><tr><td>eval/runtime</td><td>1.9897</td></tr><tr><td>eval/samples_per_second</td><td>16.083</td></tr><tr><td>eval/steps_per_second</td><td>1.005</td></tr><tr><td>final_accuracy</td><td>0.625</td></tr><tr><td>final_f1</td><td>0.62969</td></tr><tr><td>final_precision</td><td>0.70379</td></tr><tr><td>final_recall</td><td>0.625</td></tr><tr><td>test/accuracy</td><td>0.625</td></tr><tr><td>test/f1</td><td>0.62969</td></tr><tr><td>test/loss</td><td>1.31451</td></tr><tr><td>test/precision</td><td>0.70379</td></tr><tr><td>test/recall</td><td>0.625</td></tr><tr><td>test/runtime</td><td>1.998</td></tr><tr><td>test/samples_per_second</td><td>16.016</td></tr><tr><td>test/steps_per_second</td><td>1.001</td></tr><tr><td>total_flos</td><td>4.959754037231616e+16</td></tr><tr><td>train/epoch</td><td>1</td></tr><tr><td>train/global_step</td><td>40</td></tr><tr><td>train/grad_norm</td><td>2.3902</td></tr><tr><td>train/learning_rate</td><td>3e-05</td></tr><tr><td>train/loss</td><td>1.3347</td></tr><tr><td>train_loss</td><td>1.56433</td></tr><tr><td>train_runtime</td><td>90.6502</td></tr><tr><td>train_samples_per_second</td><td>7.06</td></tr><tr><td>train_steps_per_second</td><td>0.441</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">AdamW_exponential</strong> at: <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/seoyy430' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/seoyy430</a><br> View project at: <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers</a><br>Synced 5 W&B file(s), 1 media file(s), 2 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250420_021735-seoyy430/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/Users/egoh02/Github/CS7643-Project-SP25/wandb/run-20250420_021919-tshlji87</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/tshlji87' target=\"_blank\">AdamW_constant</a></strong> to <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/tshlji87' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/tshlji87</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading dataset: jbarat/plant_species\n",
            "Dataset prepared with 640 training, 128 validation, and 32 test examples\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting training for AdamW_constant...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='40' max='40' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [40/40 01:27, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>1.883500</td>\n",
              "      <td>1.655026</td>\n",
              "      <td>0.601562</td>\n",
              "      <td>0.553895</td>\n",
              "      <td>0.599219</td>\n",
              "      <td>0.601562</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>1.474600</td>\n",
              "      <td>1.296949</td>\n",
              "      <td>0.703125</td>\n",
              "      <td>0.692798</td>\n",
              "      <td>0.770689</td>\n",
              "      <td>0.703125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>1.232400</td>\n",
              "      <td>1.073685</td>\n",
              "      <td>0.773438</td>\n",
              "      <td>0.774397</td>\n",
              "      <td>0.780395</td>\n",
              "      <td>0.773438</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>1.049500</td>\n",
              "      <td>0.968165</td>\n",
              "      <td>0.734375</td>\n",
              "      <td>0.742283</td>\n",
              "      <td>0.828007</td>\n",
              "      <td>0.734375</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/egoh02/Github/CS7643-Project-SP25/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating AdamW_constant...\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "Running experiment: AdamW_cosine_with_restarts\n",
            "==================================================\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▅█▆▇</td></tr><tr><td>eval/f1</td><td>▁▅█▇▇</td></tr><tr><td>eval/loss</td><td>█▄▂▁▁</td></tr><tr><td>eval/precision</td><td>▁▆▆▇█</td></tr><tr><td>eval/recall</td><td>▁▅█▆▇</td></tr><tr><td>eval/runtime</td><td>████▁</td></tr><tr><td>eval/samples_per_second</td><td>▆▆▇█▁</td></tr><tr><td>eval/steps_per_second</td><td>▆▆▇█▁</td></tr><tr><td>final_accuracy</td><td>▁</td></tr><tr><td>final_f1</td><td>▁</td></tr><tr><td>final_precision</td><td>▁</td></tr><tr><td>final_recall</td><td>▁</td></tr><tr><td>test/accuracy</td><td>▁</td></tr><tr><td>test/f1</td><td>▁</td></tr><tr><td>test/loss</td><td>▁</td></tr><tr><td>test/precision</td><td>▁</td></tr><tr><td>test/recall</td><td>▁</td></tr><tr><td>test/runtime</td><td>▁</td></tr><tr><td>test/samples_per_second</td><td>▁</td></tr><tr><td>test/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▃▃▆▆████</td></tr><tr><td>train/global_step</td><td>▁▁▃▃▆▆███████</td></tr><tr><td>train/grad_norm</td><td>▁▃▃█</td></tr><tr><td>train/learning_rate</td><td>▁▁▁▁</td></tr><tr><td>train/loss</td><td>█▅▃▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.75</td></tr><tr><td>eval/f1</td><td>0.741</td></tr><tr><td>eval/loss</td><td>0.97039</td></tr><tr><td>eval/precision</td><td>0.84866</td></tr><tr><td>eval/recall</td><td>0.75</td></tr><tr><td>eval/runtime</td><td>1.846</td></tr><tr><td>eval/samples_per_second</td><td>17.335</td></tr><tr><td>eval/steps_per_second</td><td>1.083</td></tr><tr><td>final_accuracy</td><td>0.75</td></tr><tr><td>final_f1</td><td>0.741</td></tr><tr><td>final_precision</td><td>0.84866</td></tr><tr><td>final_recall</td><td>0.75</td></tr><tr><td>test/accuracy</td><td>0.75</td></tr><tr><td>test/f1</td><td>0.741</td></tr><tr><td>test/loss</td><td>0.97039</td></tr><tr><td>test/precision</td><td>0.84866</td></tr><tr><td>test/recall</td><td>0.75</td></tr><tr><td>test/runtime</td><td>1.8835</td></tr><tr><td>test/samples_per_second</td><td>16.99</td></tr><tr><td>test/steps_per_second</td><td>1.062</td></tr><tr><td>total_flos</td><td>4.959754037231616e+16</td></tr><tr><td>train/epoch</td><td>1</td></tr><tr><td>train/global_step</td><td>40</td></tr><tr><td>train/grad_norm</td><td>3.31446</td></tr><tr><td>train/learning_rate</td><td>0.0002</td></tr><tr><td>train/loss</td><td>1.0495</td></tr><tr><td>train_loss</td><td>1.40999</td></tr><tr><td>train_runtime</td><td>89.7927</td></tr><tr><td>train_samples_per_second</td><td>7.128</td></tr><tr><td>train_steps_per_second</td><td>0.445</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">AdamW_constant</strong> at: <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/tshlji87' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/tshlji87</a><br> View project at: <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers</a><br>Synced 5 W&B file(s), 1 media file(s), 2 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250420_021919-tshlji87/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/Users/egoh02/Github/CS7643-Project-SP25/wandb/run-20250420_022103-23beph57</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/23beph57' target=\"_blank\">AdamW_cosine_with_restarts</a></strong> to <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/23beph57' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/23beph57</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading dataset: jbarat/plant_species\n",
            "Dataset prepared with 640 training, 128 validation, and 32 test examples\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting training for AdamW_cosine_with_restarts...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='40' max='40' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [40/40 01:24, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>1.974200</td>\n",
              "      <td>1.728708</td>\n",
              "      <td>0.593750</td>\n",
              "      <td>0.569847</td>\n",
              "      <td>0.685227</td>\n",
              "      <td>0.593750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>1.567900</td>\n",
              "      <td>1.381277</td>\n",
              "      <td>0.695312</td>\n",
              "      <td>0.687373</td>\n",
              "      <td>0.769771</td>\n",
              "      <td>0.695312</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>1.350500</td>\n",
              "      <td>1.232498</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.743582</td>\n",
              "      <td>0.774330</td>\n",
              "      <td>0.750000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>1.247900</td>\n",
              "      <td>1.199448</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.746359</td>\n",
              "      <td>0.767571</td>\n",
              "      <td>0.750000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating AdamW_cosine_with_restarts...\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "Running experiment: AdamW_constant_with_warmup\n",
            "==================================================\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▆███</td></tr><tr><td>eval/f1</td><td>▁▆███</td></tr><tr><td>eval/loss</td><td>█▃▁▁▁</td></tr><tr><td>eval/precision</td><td>▁▆▆▆█</td></tr><tr><td>eval/recall</td><td>▁▆███</td></tr><tr><td>eval/runtime</td><td>▇█▇▇▁</td></tr><tr><td>eval/samples_per_second</td><td>▆▁██▅</td></tr><tr><td>eval/steps_per_second</td><td>▆▁██▅</td></tr><tr><td>final_accuracy</td><td>▁</td></tr><tr><td>final_f1</td><td>▁</td></tr><tr><td>final_precision</td><td>▁</td></tr><tr><td>final_recall</td><td>▁</td></tr><tr><td>test/accuracy</td><td>▁</td></tr><tr><td>test/f1</td><td>▁</td></tr><tr><td>test/loss</td><td>▁</td></tr><tr><td>test/precision</td><td>▁</td></tr><tr><td>test/recall</td><td>▁</td></tr><tr><td>test/runtime</td><td>▁</td></tr><tr><td>test/samples_per_second</td><td>▁</td></tr><tr><td>test/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▃▃▆▆████</td></tr><tr><td>train/global_step</td><td>▁▁▃▃▆▆███████</td></tr><tr><td>train/grad_norm</td><td>▁▇▆█</td></tr><tr><td>train/learning_rate</td><td>█▆▃▁</td></tr><tr><td>train/loss</td><td>█▄▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.75</td></tr><tr><td>eval/f1</td><td>0.73785</td></tr><tr><td>eval/loss</td><td>1.23107</td></tr><tr><td>eval/precision</td><td>0.81027</td></tr><tr><td>eval/recall</td><td>0.75</td></tr><tr><td>eval/runtime</td><td>1.7877</td></tr><tr><td>eval/samples_per_second</td><td>17.9</td></tr><tr><td>eval/steps_per_second</td><td>1.119</td></tr><tr><td>final_accuracy</td><td>0.75</td></tr><tr><td>final_f1</td><td>0.73785</td></tr><tr><td>final_precision</td><td>0.81027</td></tr><tr><td>final_recall</td><td>0.75</td></tr><tr><td>test/accuracy</td><td>0.75</td></tr><tr><td>test/f1</td><td>0.73785</td></tr><tr><td>test/loss</td><td>1.23107</td></tr><tr><td>test/precision</td><td>0.81027</td></tr><tr><td>test/recall</td><td>0.75</td></tr><tr><td>test/runtime</td><td>1.7368</td></tr><tr><td>test/samples_per_second</td><td>18.425</td></tr><tr><td>test/steps_per_second</td><td>1.152</td></tr><tr><td>total_flos</td><td>4.959754037231616e+16</td></tr><tr><td>train/epoch</td><td>1</td></tr><tr><td>train/global_step</td><td>40</td></tr><tr><td>train/grad_norm</td><td>2.22368</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.2479</td></tr><tr><td>train_loss</td><td>1.5351</td></tr><tr><td>train_runtime</td><td>86.6383</td></tr><tr><td>train_samples_per_second</td><td>7.387</td></tr><tr><td>train_steps_per_second</td><td>0.462</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">AdamW_cosine_with_restarts</strong> at: <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/23beph57' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/23beph57</a><br> View project at: <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers</a><br>Synced 5 W&B file(s), 1 media file(s), 2 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250420_022103-23beph57/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/Users/egoh02/Github/CS7643-Project-SP25/wandb/run-20250420_022244-8lhatv24</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/8lhatv24' target=\"_blank\">AdamW_constant_with_warmup</a></strong> to <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/8lhatv24' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/8lhatv24</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading dataset: jbarat/plant_species\n",
            "Dataset prepared with 640 training, 128 validation, and 32 test examples\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting training for AdamW_constant_with_warmup...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='40' max='40' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [40/40 01:25, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>1.974300</td>\n",
              "      <td>1.726062</td>\n",
              "      <td>0.585938</td>\n",
              "      <td>0.558176</td>\n",
              "      <td>0.663926</td>\n",
              "      <td>0.585938</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>1.542900</td>\n",
              "      <td>1.324070</td>\n",
              "      <td>0.656250</td>\n",
              "      <td>0.639517</td>\n",
              "      <td>0.766891</td>\n",
              "      <td>0.656250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>1.261800</td>\n",
              "      <td>1.103872</td>\n",
              "      <td>0.765625</td>\n",
              "      <td>0.769430</td>\n",
              "      <td>0.793967</td>\n",
              "      <td>0.765625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>1.023500</td>\n",
              "      <td>0.934381</td>\n",
              "      <td>0.734375</td>\n",
              "      <td>0.743295</td>\n",
              "      <td>0.795639</td>\n",
              "      <td>0.734375</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating AdamW_constant_with_warmup...\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "Running experiment: RMSProp_linear\n",
            "==================================================\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▄▇▆█</td></tr><tr><td>eval/f1</td><td>▁▄█▇█</td></tr><tr><td>eval/loss</td><td>█▄▃▁▁</td></tr><tr><td>eval/precision</td><td>▁▅▆▆█</td></tr><tr><td>eval/recall</td><td>▁▄▇▆█</td></tr><tr><td>eval/runtime</td><td>████▁</td></tr><tr><td>eval/samples_per_second</td><td>▄▇█▅▁</td></tr><tr><td>eval/steps_per_second</td><td>▄▇█▅▁</td></tr><tr><td>final_accuracy</td><td>▁</td></tr><tr><td>final_f1</td><td>▁</td></tr><tr><td>final_precision</td><td>▁</td></tr><tr><td>final_recall</td><td>▁</td></tr><tr><td>test/accuracy</td><td>▁</td></tr><tr><td>test/f1</td><td>▁</td></tr><tr><td>test/loss</td><td>▁</td></tr><tr><td>test/precision</td><td>▁</td></tr><tr><td>test/recall</td><td>▁</td></tr><tr><td>test/runtime</td><td>▁</td></tr><tr><td>test/samples_per_second</td><td>▁</td></tr><tr><td>test/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▃▃▆▆████</td></tr><tr><td>train/global_step</td><td>▁▁▃▃▆▆███████</td></tr><tr><td>train/grad_norm</td><td>▁▁▇█</td></tr><tr><td>train/learning_rate</td><td>▁▁▁▁</td></tr><tr><td>train/loss</td><td>█▅▃▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.78125</td></tr><tr><td>eval/f1</td><td>0.77131</td></tr><tr><td>eval/loss</td><td>0.92843</td></tr><tr><td>eval/precision</td><td>0.86354</td></tr><tr><td>eval/recall</td><td>0.78125</td></tr><tr><td>eval/runtime</td><td>1.7726</td></tr><tr><td>eval/samples_per_second</td><td>18.052</td></tr><tr><td>eval/steps_per_second</td><td>1.128</td></tr><tr><td>final_accuracy</td><td>0.78125</td></tr><tr><td>final_f1</td><td>0.77131</td></tr><tr><td>final_precision</td><td>0.86354</td></tr><tr><td>final_recall</td><td>0.78125</td></tr><tr><td>test/accuracy</td><td>0.78125</td></tr><tr><td>test/f1</td><td>0.77131</td></tr><tr><td>test/loss</td><td>0.92843</td></tr><tr><td>test/precision</td><td>0.86354</td></tr><tr><td>test/recall</td><td>0.78125</td></tr><tr><td>test/runtime</td><td>1.8082</td></tr><tr><td>test/samples_per_second</td><td>17.697</td></tr><tr><td>test/steps_per_second</td><td>1.106</td></tr><tr><td>total_flos</td><td>4.959754037231616e+16</td></tr><tr><td>train/epoch</td><td>1</td></tr><tr><td>train/global_step</td><td>40</td></tr><tr><td>train/grad_norm</td><td>2.26277</td></tr><tr><td>train/learning_rate</td><td>0.0002</td></tr><tr><td>train/loss</td><td>1.0235</td></tr><tr><td>train_loss</td><td>1.45062</td></tr><tr><td>train_runtime</td><td>87.6249</td></tr><tr><td>train_samples_per_second</td><td>7.304</td></tr><tr><td>train_steps_per_second</td><td>0.456</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">AdamW_constant_with_warmup</strong> at: <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/8lhatv24' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/8lhatv24</a><br> View project at: <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers</a><br>Synced 5 W&B file(s), 1 media file(s), 2 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250420_022244-8lhatv24/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/Users/egoh02/Github/CS7643-Project-SP25/wandb/run-20250420_022426-y3hyhgwc</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/y3hyhgwc' target=\"_blank\">RMSProp_linear</a></strong> to <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/y3hyhgwc' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/y3hyhgwc</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading dataset: jbarat/plant_species\n",
            "Dataset prepared with 640 training, 128 validation, and 32 test examples\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting training for RMSProp_linear...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='40' max='40' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [40/40 01:22, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>2.064900</td>\n",
              "      <td>2.037004</td>\n",
              "      <td>0.156250</td>\n",
              "      <td>0.043403</td>\n",
              "      <td>0.025202</td>\n",
              "      <td>0.156250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>1.795300</td>\n",
              "      <td>1.613360</td>\n",
              "      <td>0.351562</td>\n",
              "      <td>0.297356</td>\n",
              "      <td>0.485626</td>\n",
              "      <td>0.351562</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>1.445700</td>\n",
              "      <td>1.113543</td>\n",
              "      <td>0.718750</td>\n",
              "      <td>0.708677</td>\n",
              "      <td>0.719411</td>\n",
              "      <td>0.718750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>1.089000</td>\n",
              "      <td>1.025261</td>\n",
              "      <td>0.742188</td>\n",
              "      <td>0.746120</td>\n",
              "      <td>0.773297</td>\n",
              "      <td>0.742188</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/egoh02/Github/CS7643-Project-SP25/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating RMSProp_linear...\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "Running experiment: RMSProp_cosine\n",
            "==================================================\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▃██▇</td></tr><tr><td>eval/f1</td><td>▁▄██▇</td></tr><tr><td>eval/loss</td><td>█▅▂▁▁</td></tr><tr><td>eval/precision</td><td>▁▅▇██</td></tr><tr><td>eval/recall</td><td>▁▃██▇</td></tr><tr><td>eval/runtime</td><td>████▁</td></tr><tr><td>eval/samples_per_second</td><td>▇█▇▇▁</td></tr><tr><td>eval/steps_per_second</td><td>▇█▇▇▁</td></tr><tr><td>final_accuracy</td><td>▁</td></tr><tr><td>final_f1</td><td>▁</td></tr><tr><td>final_precision</td><td>▁</td></tr><tr><td>final_recall</td><td>▁</td></tr><tr><td>test/accuracy</td><td>▁</td></tr><tr><td>test/f1</td><td>▁</td></tr><tr><td>test/loss</td><td>▁</td></tr><tr><td>test/precision</td><td>▁</td></tr><tr><td>test/recall</td><td>▁</td></tr><tr><td>test/runtime</td><td>▁</td></tr><tr><td>test/samples_per_second</td><td>▁</td></tr><tr><td>test/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▃▃▆▆████</td></tr><tr><td>train/global_step</td><td>▁▁▃▃▆▆███████</td></tr><tr><td>train/grad_norm</td><td>▁▂▅█</td></tr><tr><td>train/learning_rate</td><td>█▆▃▁</td></tr><tr><td>train/loss</td><td>█▆▄▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.6875</td></tr><tr><td>eval/f1</td><td>0.67505</td></tr><tr><td>eval/loss</td><td>1.04252</td></tr><tr><td>eval/precision</td><td>0.76178</td></tr><tr><td>eval/recall</td><td>0.6875</td></tr><tr><td>eval/runtime</td><td>1.8162</td></tr><tr><td>eval/samples_per_second</td><td>17.619</td></tr><tr><td>eval/steps_per_second</td><td>1.101</td></tr><tr><td>final_accuracy</td><td>0.6875</td></tr><tr><td>final_f1</td><td>0.67505</td></tr><tr><td>final_precision</td><td>0.76178</td></tr><tr><td>final_recall</td><td>0.6875</td></tr><tr><td>test/accuracy</td><td>0.6875</td></tr><tr><td>test/f1</td><td>0.67505</td></tr><tr><td>test/loss</td><td>1.04252</td></tr><tr><td>test/precision</td><td>0.76178</td></tr><tr><td>test/recall</td><td>0.6875</td></tr><tr><td>test/runtime</td><td>3.8138</td></tr><tr><td>test/samples_per_second</td><td>8.391</td></tr><tr><td>test/steps_per_second</td><td>0.524</td></tr><tr><td>total_flos</td><td>4.959754037231616e+16</td></tr><tr><td>train/epoch</td><td>1</td></tr><tr><td>train/global_step</td><td>40</td></tr><tr><td>train/grad_norm</td><td>2.08793</td></tr><tr><td>train/learning_rate</td><td>1e-05</td></tr><tr><td>train/loss</td><td>1.089</td></tr><tr><td>train_loss</td><td>1.59874</td></tr><tr><td>train_runtime</td><td>84.9762</td></tr><tr><td>train_samples_per_second</td><td>7.532</td></tr><tr><td>train_steps_per_second</td><td>0.471</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">RMSProp_linear</strong> at: <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/y3hyhgwc' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/y3hyhgwc</a><br> View project at: <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers</a><br>Synced 5 W&B file(s), 1 media file(s), 2 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250420_022426-y3hyhgwc/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/Users/egoh02/Github/CS7643-Project-SP25/wandb/run-20250420_022607-yk8qc66y</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/yk8qc66y' target=\"_blank\">RMSProp_cosine</a></strong> to <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/yk8qc66y' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/yk8qc66y</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading dataset: jbarat/plant_species\n",
            "Dataset prepared with 640 training, 128 validation, and 32 test examples\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting training for RMSProp_cosine...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='40' max='40' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [40/40 01:22, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>2.078100</td>\n",
              "      <td>2.053473</td>\n",
              "      <td>0.156250</td>\n",
              "      <td>0.042517</td>\n",
              "      <td>0.024606</td>\n",
              "      <td>0.156250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>1.883300</td>\n",
              "      <td>1.531483</td>\n",
              "      <td>0.468750</td>\n",
              "      <td>0.432240</td>\n",
              "      <td>0.460962</td>\n",
              "      <td>0.468750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>1.455200</td>\n",
              "      <td>1.160432</td>\n",
              "      <td>0.695312</td>\n",
              "      <td>0.692808</td>\n",
              "      <td>0.704568</td>\n",
              "      <td>0.695312</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>1.159000</td>\n",
              "      <td>1.119615</td>\n",
              "      <td>0.710938</td>\n",
              "      <td>0.706062</td>\n",
              "      <td>0.728813</td>\n",
              "      <td>0.710938</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/egoh02/Github/CS7643-Project-SP25/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/Users/egoh02/Github/CS7643-Project-SP25/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating RMSProp_cosine...\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "Running experiment: RMSProp_polynomial\n",
            "==================================================\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▅██▇</td></tr><tr><td>eval/f1</td><td>▁▅██▇</td></tr><tr><td>eval/loss</td><td>█▄▁▁▁</td></tr><tr><td>eval/precision</td><td>▁▅███</td></tr><tr><td>eval/recall</td><td>▁▅██▇</td></tr><tr><td>eval/runtime</td><td>████▁</td></tr><tr><td>eval/samples_per_second</td><td>▅█▄▅▁</td></tr><tr><td>eval/steps_per_second</td><td>▅█▄▅▁</td></tr><tr><td>final_accuracy</td><td>▁</td></tr><tr><td>final_f1</td><td>▁</td></tr><tr><td>final_precision</td><td>▁</td></tr><tr><td>final_recall</td><td>▁</td></tr><tr><td>test/accuracy</td><td>▁</td></tr><tr><td>test/f1</td><td>▁</td></tr><tr><td>test/loss</td><td>▁</td></tr><tr><td>test/precision</td><td>▁</td></tr><tr><td>test/recall</td><td>▁</td></tr><tr><td>test/runtime</td><td>▁</td></tr><tr><td>test/samples_per_second</td><td>▁</td></tr><tr><td>test/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▃▃▆▆████</td></tr><tr><td>train/global_step</td><td>▁▁▃▃▆▆███████</td></tr><tr><td>train/grad_norm</td><td>▄█▁▁</td></tr><tr><td>train/learning_rate</td><td>█▆▃▁</td></tr><tr><td>train/loss</td><td>█▇▃▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.625</td></tr><tr><td>eval/f1</td><td>0.5969</td></tr><tr><td>eval/loss</td><td>1.13021</td></tr><tr><td>eval/precision</td><td>0.7322</td></tr><tr><td>eval/recall</td><td>0.625</td></tr><tr><td>eval/runtime</td><td>1.7807</td></tr><tr><td>eval/samples_per_second</td><td>17.97</td></tr><tr><td>eval/steps_per_second</td><td>1.123</td></tr><tr><td>final_accuracy</td><td>0.625</td></tr><tr><td>final_f1</td><td>0.5969</td></tr><tr><td>final_precision</td><td>0.7322</td></tr><tr><td>final_recall</td><td>0.625</td></tr><tr><td>test/accuracy</td><td>0.625</td></tr><tr><td>test/f1</td><td>0.5969</td></tr><tr><td>test/loss</td><td>1.13021</td></tr><tr><td>test/precision</td><td>0.7322</td></tr><tr><td>test/recall</td><td>0.625</td></tr><tr><td>test/runtime</td><td>1.8554</td></tr><tr><td>test/samples_per_second</td><td>17.247</td></tr><tr><td>test/steps_per_second</td><td>1.078</td></tr><tr><td>total_flos</td><td>4.959754037231616e+16</td></tr><tr><td>train/epoch</td><td>1</td></tr><tr><td>train/global_step</td><td>40</td></tr><tr><td>train/grad_norm</td><td>1.76835</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.159</td></tr><tr><td>train_loss</td><td>1.64391</td></tr><tr><td>train_runtime</td><td>85.0609</td></tr><tr><td>train_samples_per_second</td><td>7.524</td></tr><tr><td>train_steps_per_second</td><td>0.47</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">RMSProp_cosine</strong> at: <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/yk8qc66y' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/yk8qc66y</a><br> View project at: <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers</a><br>Synced 5 W&B file(s), 1 media file(s), 2 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250420_022607-yk8qc66y/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/Users/egoh02/Github/CS7643-Project-SP25/wandb/run-20250420_022744-9h33dnls</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/9h33dnls' target=\"_blank\">RMSProp_polynomial</a></strong> to <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/9h33dnls' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/9h33dnls</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading dataset: jbarat/plant_species\n",
            "Dataset prepared with 640 training, 128 validation, and 32 test examples\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting training for RMSProp_polynomial...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='40' max='40' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [40/40 01:23, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>2.065100</td>\n",
              "      <td>2.039762</td>\n",
              "      <td>0.156250</td>\n",
              "      <td>0.042517</td>\n",
              "      <td>0.024606</td>\n",
              "      <td>0.156250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>1.830000</td>\n",
              "      <td>1.507426</td>\n",
              "      <td>0.515625</td>\n",
              "      <td>0.481928</td>\n",
              "      <td>0.524813</td>\n",
              "      <td>0.515625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>1.441000</td>\n",
              "      <td>1.208421</td>\n",
              "      <td>0.687500</td>\n",
              "      <td>0.688099</td>\n",
              "      <td>0.703151</td>\n",
              "      <td>0.687500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>1.152200</td>\n",
              "      <td>1.081533</td>\n",
              "      <td>0.757812</td>\n",
              "      <td>0.758268</td>\n",
              "      <td>0.773814</td>\n",
              "      <td>0.757812</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/egoh02/Github/CS7643-Project-SP25/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating RMSProp_polynomial...\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "Running experiment: RMSProp_cyclic\n",
            "==================================================\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▅▇█▇</td></tr><tr><td>eval/f1</td><td>▁▅▇█▇</td></tr><tr><td>eval/loss</td><td>█▄▂▁▁</td></tr><tr><td>eval/precision</td><td>▁▆▇██</td></tr><tr><td>eval/recall</td><td>▁▅▇█▇</td></tr><tr><td>eval/runtime</td><td>████▁</td></tr><tr><td>eval/samples_per_second</td><td>████▁</td></tr><tr><td>eval/steps_per_second</td><td>██▇█▁</td></tr><tr><td>final_accuracy</td><td>▁</td></tr><tr><td>final_f1</td><td>▁</td></tr><tr><td>final_precision</td><td>▁</td></tr><tr><td>final_recall</td><td>▁</td></tr><tr><td>test/accuracy</td><td>▁</td></tr><tr><td>test/f1</td><td>▁</td></tr><tr><td>test/loss</td><td>▁</td></tr><tr><td>test/precision</td><td>▁</td></tr><tr><td>test/recall</td><td>▁</td></tr><tr><td>test/runtime</td><td>▁</td></tr><tr><td>test/samples_per_second</td><td>▁</td></tr><tr><td>test/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▃▃▆▆████</td></tr><tr><td>train/global_step</td><td>▁▁▃▃▆▆███████</td></tr><tr><td>train/grad_norm</td><td>▁█▁▃</td></tr><tr><td>train/learning_rate</td><td>█▆▃▁</td></tr><tr><td>train/loss</td><td>█▆▃▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.65625</td></tr><tr><td>eval/f1</td><td>0.62892</td></tr><tr><td>eval/loss</td><td>1.11313</td></tr><tr><td>eval/precision</td><td>0.75484</td></tr><tr><td>eval/recall</td><td>0.65625</td></tr><tr><td>eval/runtime</td><td>1.816</td></tr><tr><td>eval/samples_per_second</td><td>17.621</td></tr><tr><td>eval/steps_per_second</td><td>1.101</td></tr><tr><td>final_accuracy</td><td>0.65625</td></tr><tr><td>final_f1</td><td>0.62892</td></tr><tr><td>final_precision</td><td>0.75484</td></tr><tr><td>final_recall</td><td>0.65625</td></tr><tr><td>test/accuracy</td><td>0.65625</td></tr><tr><td>test/f1</td><td>0.62892</td></tr><tr><td>test/loss</td><td>1.11313</td></tr><tr><td>test/precision</td><td>0.75484</td></tr><tr><td>test/recall</td><td>0.65625</td></tr><tr><td>test/runtime</td><td>1.795</td></tr><tr><td>test/samples_per_second</td><td>17.828</td></tr><tr><td>test/steps_per_second</td><td>1.114</td></tr><tr><td>total_flos</td><td>4.959754037231616e+16</td></tr><tr><td>train/epoch</td><td>1</td></tr><tr><td>train/global_step</td><td>40</td></tr><tr><td>train/grad_norm</td><td>2.1119</td></tr><tr><td>train/learning_rate</td><td>1e-05</td></tr><tr><td>train/loss</td><td>1.1522</td></tr><tr><td>train_loss</td><td>1.62208</td></tr><tr><td>train_runtime</td><td>85.5902</td></tr><tr><td>train_samples_per_second</td><td>7.477</td></tr><tr><td>train_steps_per_second</td><td>0.467</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">RMSProp_polynomial</strong> at: <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/9h33dnls' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/9h33dnls</a><br> View project at: <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers</a><br>Synced 5 W&B file(s), 1 media file(s), 2 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250420_022744-9h33dnls/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/Users/egoh02/Github/CS7643-Project-SP25/wandb/run-20250420_022922-alqe1ql4</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/alqe1ql4' target=\"_blank\">RMSProp_cyclic</a></strong> to <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/alqe1ql4' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/alqe1ql4</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading dataset: jbarat/plant_species\n",
            "Dataset prepared with 640 training, 128 validation, and 32 test examples\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting training for RMSProp_cyclic...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='40' max='40' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [40/40 01:22, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>1.923100</td>\n",
              "      <td>1.687377</td>\n",
              "      <td>0.554688</td>\n",
              "      <td>0.495165</td>\n",
              "      <td>0.578912</td>\n",
              "      <td>0.554688</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>2.032100</td>\n",
              "      <td>2.076891</td>\n",
              "      <td>0.156250</td>\n",
              "      <td>0.042230</td>\n",
              "      <td>0.024414</td>\n",
              "      <td>0.156250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>2.088400</td>\n",
              "      <td>2.078687</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>0.045616</td>\n",
              "      <td>0.056822</td>\n",
              "      <td>0.125000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>2.083000</td>\n",
              "      <td>2.079400</td>\n",
              "      <td>0.109375</td>\n",
              "      <td>0.021567</td>\n",
              "      <td>0.011963</td>\n",
              "      <td>0.109375</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/egoh02/Github/CS7643-Project-SP25/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/Users/egoh02/Github/CS7643-Project-SP25/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/Users/egoh02/Github/CS7643-Project-SP25/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating RMSProp_cyclic...\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/egoh02/Github/CS7643-Project-SP25/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/Users/egoh02/Github/CS7643-Project-SP25/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "Running experiment: RMSProp_exponential\n",
            "==================================================\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>█▂▁▁▁</td></tr><tr><td>eval/f1</td><td>█▁▁▁▁</td></tr><tr><td>eval/loss</td><td>▁████</td></tr><tr><td>eval/precision</td><td>█▁▂▁▁</td></tr><tr><td>eval/recall</td><td>█▂▁▁▁</td></tr><tr><td>eval/runtime</td><td>████▁</td></tr><tr><td>eval/samples_per_second</td><td>▇▆▅█▁</td></tr><tr><td>eval/steps_per_second</td><td>▇▆▅█▁</td></tr><tr><td>final_accuracy</td><td>▁</td></tr><tr><td>final_f1</td><td>▁</td></tr><tr><td>final_precision</td><td>▁</td></tr><tr><td>final_recall</td><td>▁</td></tr><tr><td>test/accuracy</td><td>▁</td></tr><tr><td>test/f1</td><td>▁</td></tr><tr><td>test/loss</td><td>▁</td></tr><tr><td>test/precision</td><td>▁</td></tr><tr><td>test/recall</td><td>▁</td></tr><tr><td>test/runtime</td><td>▁</td></tr><tr><td>test/samples_per_second</td><td>▁</td></tr><tr><td>test/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▃▃▆▆████</td></tr><tr><td>train/global_step</td><td>▁▁▃▃▆▆███████</td></tr><tr><td>train/grad_norm</td><td>█▁▁▁</td></tr><tr><td>train/learning_rate</td><td>▇█▅▁</td></tr><tr><td>train/loss</td><td>▁▆██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.125</td></tr><tr><td>eval/f1</td><td>0.03472</td></tr><tr><td>eval/loss</td><td>2.07143</td></tr><tr><td>eval/precision</td><td>0.02016</td></tr><tr><td>eval/recall</td><td>0.125</td></tr><tr><td>eval/runtime</td><td>1.7488</td></tr><tr><td>eval/samples_per_second</td><td>18.298</td></tr><tr><td>eval/steps_per_second</td><td>1.144</td></tr><tr><td>final_accuracy</td><td>0.125</td></tr><tr><td>final_f1</td><td>0.03472</td></tr><tr><td>final_precision</td><td>0.02016</td></tr><tr><td>final_recall</td><td>0.125</td></tr><tr><td>test/accuracy</td><td>0.125</td></tr><tr><td>test/f1</td><td>0.03472</td></tr><tr><td>test/loss</td><td>2.07143</td></tr><tr><td>test/precision</td><td>0.02016</td></tr><tr><td>test/recall</td><td>0.125</td></tr><tr><td>test/runtime</td><td>1.7874</td></tr><tr><td>test/samples_per_second</td><td>17.903</td></tr><tr><td>test/steps_per_second</td><td>1.119</td></tr><tr><td>total_flos</td><td>4.959754037231616e+16</td></tr><tr><td>train/epoch</td><td>1</td></tr><tr><td>train/global_step</td><td>40</td></tr><tr><td>train/grad_norm</td><td>0.54583</td></tr><tr><td>train/learning_rate</td><td>2e-05</td></tr><tr><td>train/loss</td><td>2.083</td></tr><tr><td>train_loss</td><td>2.03164</td></tr><tr><td>train_runtime</td><td>84.4074</td></tr><tr><td>train_samples_per_second</td><td>7.582</td></tr><tr><td>train_steps_per_second</td><td>0.474</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">RMSProp_cyclic</strong> at: <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/alqe1ql4' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/alqe1ql4</a><br> View project at: <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers</a><br>Synced 5 W&B file(s), 1 media file(s), 2 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250420_022922-alqe1ql4/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/Users/egoh02/Github/CS7643-Project-SP25/wandb/run-20250420_023100-ckaqryah</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/ckaqryah' target=\"_blank\">RMSProp_exponential</a></strong> to <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/ckaqryah' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/ckaqryah</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading dataset: jbarat/plant_species\n",
            "Dataset prepared with 640 training, 128 validation, and 32 test examples\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting training for RMSProp_exponential...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='40' max='40' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [40/40 01:22, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>2.116000</td>\n",
              "      <td>2.088271</td>\n",
              "      <td>0.117188</td>\n",
              "      <td>0.024585</td>\n",
              "      <td>0.013733</td>\n",
              "      <td>0.117188</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>2.099500</td>\n",
              "      <td>2.080530</td>\n",
              "      <td>0.109375</td>\n",
              "      <td>0.021720</td>\n",
              "      <td>0.012057</td>\n",
              "      <td>0.109375</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>2.084500</td>\n",
              "      <td>2.079837</td>\n",
              "      <td>0.140625</td>\n",
              "      <td>0.064912</td>\n",
              "      <td>0.048751</td>\n",
              "      <td>0.140625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>2.079400</td>\n",
              "      <td>2.069796</td>\n",
              "      <td>0.187500</td>\n",
              "      <td>0.099839</td>\n",
              "      <td>0.089115</td>\n",
              "      <td>0.187500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/egoh02/Github/CS7643-Project-SP25/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/Users/egoh02/Github/CS7643-Project-SP25/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/Users/egoh02/Github/CS7643-Project-SP25/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/Users/egoh02/Github/CS7643-Project-SP25/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating RMSProp_exponential...\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/egoh02/Github/CS7643-Project-SP25/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/Users/egoh02/Github/CS7643-Project-SP25/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "Running experiment: RMSProp_constant\n",
            "==================================================\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▂▁▄█▅</td></tr><tr><td>eval/f1</td><td>▁▁▅█▇</td></tr><tr><td>eval/loss</td><td>█▅▅▁▅</td></tr><tr><td>eval/precision</td><td>▁▁▄█▅</td></tr><tr><td>eval/recall</td><td>▂▁▄█▅</td></tr><tr><td>eval/runtime</td><td>████▁</td></tr><tr><td>eval/samples_per_second</td><td>▆▆▆█▁</td></tr><tr><td>eval/steps_per_second</td><td>▆▆▆█▁</td></tr><tr><td>final_accuracy</td><td>▁</td></tr><tr><td>final_f1</td><td>▁</td></tr><tr><td>final_precision</td><td>▁</td></tr><tr><td>final_recall</td><td>▁</td></tr><tr><td>test/accuracy</td><td>▁</td></tr><tr><td>test/f1</td><td>▁</td></tr><tr><td>test/loss</td><td>▁</td></tr><tr><td>test/precision</td><td>▁</td></tr><tr><td>test/recall</td><td>▁</td></tr><tr><td>test/runtime</td><td>▁</td></tr><tr><td>test/samples_per_second</td><td>▁</td></tr><tr><td>test/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▃▃▆▆████</td></tr><tr><td>train/global_step</td><td>▁▁▃▃▆▆███████</td></tr><tr><td>train/grad_norm</td><td>█▁▂▁</td></tr><tr><td>train/learning_rate</td><td>█▄▂▁</td></tr><tr><td>train/loss</td><td>█▅▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.15625</td></tr><tr><td>eval/f1</td><td>0.08364</td></tr><tr><td>eval/loss</td><td>2.07939</td></tr><tr><td>eval/precision</td><td>0.05729</td></tr><tr><td>eval/recall</td><td>0.15625</td></tr><tr><td>eval/runtime</td><td>1.7821</td></tr><tr><td>eval/samples_per_second</td><td>17.957</td></tr><tr><td>eval/steps_per_second</td><td>1.122</td></tr><tr><td>final_accuracy</td><td>0.15625</td></tr><tr><td>final_f1</td><td>0.08364</td></tr><tr><td>final_precision</td><td>0.05729</td></tr><tr><td>final_recall</td><td>0.15625</td></tr><tr><td>test/accuracy</td><td>0.15625</td></tr><tr><td>test/f1</td><td>0.08364</td></tr><tr><td>test/loss</td><td>2.07939</td></tr><tr><td>test/precision</td><td>0.05729</td></tr><tr><td>test/recall</td><td>0.15625</td></tr><tr><td>test/runtime</td><td>1.8335</td></tr><tr><td>test/samples_per_second</td><td>17.453</td></tr><tr><td>test/steps_per_second</td><td>1.091</td></tr><tr><td>total_flos</td><td>4.959754037231616e+16</td></tr><tr><td>train/epoch</td><td>1</td></tr><tr><td>train/global_step</td><td>40</td></tr><tr><td>train/grad_norm</td><td>0.52669</td></tr><tr><td>train/learning_rate</td><td>3e-05</td></tr><tr><td>train/loss</td><td>2.0794</td></tr><tr><td>train_loss</td><td>2.09486</td></tr><tr><td>train_runtime</td><td>84.7431</td></tr><tr><td>train_samples_per_second</td><td>7.552</td></tr><tr><td>train_steps_per_second</td><td>0.472</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">RMSProp_exponential</strong> at: <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/ckaqryah' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/ckaqryah</a><br> View project at: <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers</a><br>Synced 5 W&B file(s), 1 media file(s), 2 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250420_023100-ckaqryah/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/Users/egoh02/Github/CS7643-Project-SP25/wandb/run-20250420_023241-jicmrjc7</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/jicmrjc7' target=\"_blank\">RMSProp_constant</a></strong> to <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/jicmrjc7' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/jicmrjc7</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading dataset: jbarat/plant_species\n",
            "Dataset prepared with 640 training, 128 validation, and 32 test examples\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting training for RMSProp_constant...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='40' max='40' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [40/40 01:24, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>2.132300</td>\n",
              "      <td>2.087856</td>\n",
              "      <td>0.117188</td>\n",
              "      <td>0.024585</td>\n",
              "      <td>0.013733</td>\n",
              "      <td>0.117188</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>2.107100</td>\n",
              "      <td>2.072129</td>\n",
              "      <td>0.156250</td>\n",
              "      <td>0.042517</td>\n",
              "      <td>0.024606</td>\n",
              "      <td>0.156250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>2.086800</td>\n",
              "      <td>2.011781</td>\n",
              "      <td>0.210938</td>\n",
              "      <td>0.137153</td>\n",
              "      <td>0.140625</td>\n",
              "      <td>0.210938</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>2.081800</td>\n",
              "      <td>2.069034</td>\n",
              "      <td>0.187500</td>\n",
              "      <td>0.121596</td>\n",
              "      <td>0.174322</td>\n",
              "      <td>0.187500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/egoh02/Github/CS7643-Project-SP25/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/Users/egoh02/Github/CS7643-Project-SP25/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/Users/egoh02/Github/CS7643-Project-SP25/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/Users/egoh02/Github/CS7643-Project-SP25/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating RMSProp_constant...\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/egoh02/Github/CS7643-Project-SP25/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/Users/egoh02/Github/CS7643-Project-SP25/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "Running experiment: RMSProp_cosine_with_restarts\n",
            "==================================================\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▄█▆▄</td></tr><tr><td>eval/f1</td><td>▁▂█▇▄</td></tr><tr><td>eval/loss</td><td>█▇▁▆█</td></tr><tr><td>eval/precision</td><td>▁▁▇█▂</td></tr><tr><td>eval/recall</td><td>▁▄█▆▄</td></tr><tr><td>eval/runtime</td><td>████▁</td></tr><tr><td>eval/samples_per_second</td><td>▅██▇▁</td></tr><tr><td>eval/steps_per_second</td><td>▅██▇▁</td></tr><tr><td>final_accuracy</td><td>▁</td></tr><tr><td>final_f1</td><td>▁</td></tr><tr><td>final_precision</td><td>▁</td></tr><tr><td>final_recall</td><td>▁</td></tr><tr><td>test/accuracy</td><td>▁</td></tr><tr><td>test/f1</td><td>▁</td></tr><tr><td>test/loss</td><td>▁</td></tr><tr><td>test/precision</td><td>▁</td></tr><tr><td>test/recall</td><td>▁</td></tr><tr><td>test/runtime</td><td>▁</td></tr><tr><td>test/samples_per_second</td><td>▁</td></tr><tr><td>test/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▃▃▆▆████</td></tr><tr><td>train/global_step</td><td>▁▁▃▃▆▆███████</td></tr><tr><td>train/grad_norm</td><td>▄▂▁█</td></tr><tr><td>train/learning_rate</td><td>▁▁▁▁</td></tr><tr><td>train/loss</td><td>█▅▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.15625</td></tr><tr><td>eval/f1</td><td>0.07083</td></tr><tr><td>eval/loss</td><td>2.08417</td></tr><tr><td>eval/precision</td><td>0.04688</td></tr><tr><td>eval/recall</td><td>0.15625</td></tr><tr><td>eval/runtime</td><td>1.8655</td></tr><tr><td>eval/samples_per_second</td><td>17.154</td></tr><tr><td>eval/steps_per_second</td><td>1.072</td></tr><tr><td>final_accuracy</td><td>0.15625</td></tr><tr><td>final_f1</td><td>0.07083</td></tr><tr><td>final_precision</td><td>0.04688</td></tr><tr><td>final_recall</td><td>0.15625</td></tr><tr><td>test/accuracy</td><td>0.15625</td></tr><tr><td>test/f1</td><td>0.07083</td></tr><tr><td>test/loss</td><td>2.08417</td></tr><tr><td>test/precision</td><td>0.04688</td></tr><tr><td>test/recall</td><td>0.15625</td></tr><tr><td>test/runtime</td><td>1.7662</td></tr><tr><td>test/samples_per_second</td><td>18.118</td></tr><tr><td>test/steps_per_second</td><td>1.132</td></tr><tr><td>total_flos</td><td>4.959754037231616e+16</td></tr><tr><td>train/epoch</td><td>1</td></tr><tr><td>train/global_step</td><td>40</td></tr><tr><td>train/grad_norm</td><td>2.08696</td></tr><tr><td>train/learning_rate</td><td>0.0002</td></tr><tr><td>train/loss</td><td>2.0818</td></tr><tr><td>train_loss</td><td>2.102</td></tr><tr><td>train_runtime</td><td>86.7659</td></tr><tr><td>train_samples_per_second</td><td>7.376</td></tr><tr><td>train_steps_per_second</td><td>0.461</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">RMSProp_constant</strong> at: <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/jicmrjc7' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/jicmrjc7</a><br> View project at: <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers</a><br>Synced 5 W&B file(s), 1 media file(s), 2 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250420_023241-jicmrjc7/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/Users/egoh02/Github/CS7643-Project-SP25/wandb/run-20250420_023422-vhyhn0me</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/vhyhn0me' target=\"_blank\">RMSProp_cosine_with_restarts</a></strong> to <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/vhyhn0me' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/vhyhn0me</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading dataset: jbarat/plant_species\n",
            "Dataset prepared with 640 training, 128 validation, and 32 test examples\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting training for RMSProp_cosine_with_restarts...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='40' max='40' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [40/40 01:23, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>2.078100</td>\n",
              "      <td>2.053473</td>\n",
              "      <td>0.156250</td>\n",
              "      <td>0.042517</td>\n",
              "      <td>0.024606</td>\n",
              "      <td>0.156250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>1.883300</td>\n",
              "      <td>1.531483</td>\n",
              "      <td>0.468750</td>\n",
              "      <td>0.432240</td>\n",
              "      <td>0.460962</td>\n",
              "      <td>0.468750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>1.455200</td>\n",
              "      <td>1.160432</td>\n",
              "      <td>0.695312</td>\n",
              "      <td>0.692808</td>\n",
              "      <td>0.704568</td>\n",
              "      <td>0.695312</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>1.159000</td>\n",
              "      <td>1.119615</td>\n",
              "      <td>0.710938</td>\n",
              "      <td>0.706062</td>\n",
              "      <td>0.728813</td>\n",
              "      <td>0.710938</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/egoh02/Github/CS7643-Project-SP25/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/Users/egoh02/Github/CS7643-Project-SP25/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating RMSProp_cosine_with_restarts...\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "Running experiment: RMSProp_constant_with_warmup\n",
            "==================================================\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▅██▇</td></tr><tr><td>eval/f1</td><td>▁▅██▇</td></tr><tr><td>eval/loss</td><td>█▄▁▁▁</td></tr><tr><td>eval/precision</td><td>▁▅███</td></tr><tr><td>eval/recall</td><td>▁▅██▇</td></tr><tr><td>eval/runtime</td><td>████▁</td></tr><tr><td>eval/samples_per_second</td><td>▇█▆█▁</td></tr><tr><td>eval/steps_per_second</td><td>▇█▆█▁</td></tr><tr><td>final_accuracy</td><td>▁</td></tr><tr><td>final_f1</td><td>▁</td></tr><tr><td>final_precision</td><td>▁</td></tr><tr><td>final_recall</td><td>▁</td></tr><tr><td>test/accuracy</td><td>▁</td></tr><tr><td>test/f1</td><td>▁</td></tr><tr><td>test/loss</td><td>▁</td></tr><tr><td>test/precision</td><td>▁</td></tr><tr><td>test/recall</td><td>▁</td></tr><tr><td>test/runtime</td><td>▁</td></tr><tr><td>test/samples_per_second</td><td>▁</td></tr><tr><td>test/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▃▃▆▆████</td></tr><tr><td>train/global_step</td><td>▁▁▃▃▆▆███████</td></tr><tr><td>train/grad_norm</td><td>▄█▁▁</td></tr><tr><td>train/learning_rate</td><td>█▆▃▁</td></tr><tr><td>train/loss</td><td>█▇▃▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.625</td></tr><tr><td>eval/f1</td><td>0.5969</td></tr><tr><td>eval/loss</td><td>1.13021</td></tr><tr><td>eval/precision</td><td>0.7322</td></tr><tr><td>eval/recall</td><td>0.625</td></tr><tr><td>eval/runtime</td><td>1.7888</td></tr><tr><td>eval/samples_per_second</td><td>17.889</td></tr><tr><td>eval/steps_per_second</td><td>1.118</td></tr><tr><td>final_accuracy</td><td>0.625</td></tr><tr><td>final_f1</td><td>0.5969</td></tr><tr><td>final_precision</td><td>0.7322</td></tr><tr><td>final_recall</td><td>0.625</td></tr><tr><td>test/accuracy</td><td>0.625</td></tr><tr><td>test/f1</td><td>0.5969</td></tr><tr><td>test/loss</td><td>1.13021</td></tr><tr><td>test/precision</td><td>0.7322</td></tr><tr><td>test/recall</td><td>0.625</td></tr><tr><td>test/runtime</td><td>1.8016</td></tr><tr><td>test/samples_per_second</td><td>17.762</td></tr><tr><td>test/steps_per_second</td><td>1.11</td></tr><tr><td>total_flos</td><td>4.959754037231616e+16</td></tr><tr><td>train/epoch</td><td>1</td></tr><tr><td>train/global_step</td><td>40</td></tr><tr><td>train/grad_norm</td><td>1.76835</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.159</td></tr><tr><td>train_loss</td><td>1.64391</td></tr><tr><td>train_runtime</td><td>85.1876</td></tr><tr><td>train_samples_per_second</td><td>7.513</td></tr><tr><td>train_steps_per_second</td><td>0.47</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">RMSProp_cosine_with_restarts</strong> at: <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/vhyhn0me' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/vhyhn0me</a><br> View project at: <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers</a><br>Synced 5 W&B file(s), 1 media file(s), 2 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250420_023422-vhyhn0me/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/Users/egoh02/Github/CS7643-Project-SP25/wandb/run-20250420_023601-x4c0ebwj</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/x4c0ebwj' target=\"_blank\">RMSProp_constant_with_warmup</a></strong> to <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/x4c0ebwj' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/x4c0ebwj</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading dataset: jbarat/plant_species\n",
            "Dataset prepared with 640 training, 128 validation, and 32 test examples\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting training for RMSProp_constant_with_warmup...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='40' max='40' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [40/40 01:23, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>2.082600</td>\n",
              "      <td>2.013290</td>\n",
              "      <td>0.195312</td>\n",
              "      <td>0.080926</td>\n",
              "      <td>0.051322</td>\n",
              "      <td>0.195312</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>2.001000</td>\n",
              "      <td>1.734530</td>\n",
              "      <td>0.375000</td>\n",
              "      <td>0.324564</td>\n",
              "      <td>0.468404</td>\n",
              "      <td>0.375000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>1.885800</td>\n",
              "      <td>1.568198</td>\n",
              "      <td>0.484375</td>\n",
              "      <td>0.471100</td>\n",
              "      <td>0.566581</td>\n",
              "      <td>0.484375</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>1.675500</td>\n",
              "      <td>1.524685</td>\n",
              "      <td>0.453125</td>\n",
              "      <td>0.426373</td>\n",
              "      <td>0.485537</td>\n",
              "      <td>0.453125</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/egoh02/Github/CS7643-Project-SP25/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/Users/egoh02/Github/CS7643-Project-SP25/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/Users/egoh02/Github/CS7643-Project-SP25/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating RMSProp_constant_with_warmup...\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/egoh02/Github/CS7643-Project-SP25/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/Users/egoh02/Github/CS7643-Project-SP25/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "Running experiment: AdaGrad_linear\n",
            "==================================================\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▅█▇▅</td></tr><tr><td>eval/f1</td><td>▁▅█▇▆</td></tr><tr><td>eval/loss</td><td>█▄▂▁▃</td></tr><tr><td>eval/precision</td><td>▁▇█▇█</td></tr><tr><td>eval/recall</td><td>▁▅█▇▅</td></tr><tr><td>eval/runtime</td><td>████▁</td></tr><tr><td>eval/samples_per_second</td><td>████▁</td></tr><tr><td>eval/steps_per_second</td><td>████▁</td></tr><tr><td>final_accuracy</td><td>▁</td></tr><tr><td>final_f1</td><td>▁</td></tr><tr><td>final_precision</td><td>▁</td></tr><tr><td>final_recall</td><td>▁</td></tr><tr><td>test/accuracy</td><td>▁</td></tr><tr><td>test/f1</td><td>▁</td></tr><tr><td>test/loss</td><td>▁</td></tr><tr><td>test/precision</td><td>▁</td></tr><tr><td>test/recall</td><td>▁</td></tr><tr><td>test/runtime</td><td>▁</td></tr><tr><td>test/samples_per_second</td><td>▁</td></tr><tr><td>test/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▃▃▆▆████</td></tr><tr><td>train/global_step</td><td>▁▁▃▃▆▆███████</td></tr><tr><td>train/grad_norm</td><td>█▁▆▆</td></tr><tr><td>train/learning_rate</td><td>▁▁▁▁</td></tr><tr><td>train/loss</td><td>█▇▅▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.375</td></tr><tr><td>eval/f1</td><td>0.37296</td></tr><tr><td>eval/loss</td><td>1.64107</td></tr><tr><td>eval/precision</td><td>0.56042</td></tr><tr><td>eval/recall</td><td>0.375</td></tr><tr><td>eval/runtime</td><td>2.0846</td></tr><tr><td>eval/samples_per_second</td><td>15.351</td></tr><tr><td>eval/steps_per_second</td><td>0.959</td></tr><tr><td>final_accuracy</td><td>0.375</td></tr><tr><td>final_f1</td><td>0.37296</td></tr><tr><td>final_precision</td><td>0.56042</td></tr><tr><td>final_recall</td><td>0.375</td></tr><tr><td>test/accuracy</td><td>0.375</td></tr><tr><td>test/f1</td><td>0.37296</td></tr><tr><td>test/loss</td><td>1.64107</td></tr><tr><td>test/precision</td><td>0.56042</td></tr><tr><td>test/recall</td><td>0.375</td></tr><tr><td>test/runtime</td><td>1.8163</td></tr><tr><td>test/samples_per_second</td><td>17.618</td></tr><tr><td>test/steps_per_second</td><td>1.101</td></tr><tr><td>total_flos</td><td>4.959754037231616e+16</td></tr><tr><td>train/epoch</td><td>1</td></tr><tr><td>train/global_step</td><td>40</td></tr><tr><td>train/grad_norm</td><td>1.92874</td></tr><tr><td>train/learning_rate</td><td>0.0002</td></tr><tr><td>train/loss</td><td>1.6755</td></tr><tr><td>train_loss</td><td>1.91122</td></tr><tr><td>train_runtime</td><td>85.637</td></tr><tr><td>train_samples_per_second</td><td>7.473</td></tr><tr><td>train_steps_per_second</td><td>0.467</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">RMSProp_constant_with_warmup</strong> at: <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/x4c0ebwj' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/x4c0ebwj</a><br> View project at: <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers</a><br>Synced 5 W&B file(s), 1 media file(s), 2 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250420_023601-x4c0ebwj/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/Users/egoh02/Github/CS7643-Project-SP25/wandb/run-20250420_023741-2hcg36wg</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/2hcg36wg' target=\"_blank\">AdaGrad_linear</a></strong> to <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/2hcg36wg' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/2hcg36wg</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading dataset: jbarat/plant_species\n",
            "Dataset prepared with 640 training, 128 validation, and 32 test examples\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting training for AdaGrad_linear...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='40' max='40' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [40/40 01:26, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>2.029000</td>\n",
              "      <td>1.904799</td>\n",
              "      <td>0.453125</td>\n",
              "      <td>0.412828</td>\n",
              "      <td>0.451332</td>\n",
              "      <td>0.453125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>1.842100</td>\n",
              "      <td>1.768967</td>\n",
              "      <td>0.617188</td>\n",
              "      <td>0.600757</td>\n",
              "      <td>0.651637</td>\n",
              "      <td>0.617188</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>1.772900</td>\n",
              "      <td>1.704880</td>\n",
              "      <td>0.687500</td>\n",
              "      <td>0.677798</td>\n",
              "      <td>0.693264</td>\n",
              "      <td>0.687500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>1.723300</td>\n",
              "      <td>1.683993</td>\n",
              "      <td>0.695312</td>\n",
              "      <td>0.690554</td>\n",
              "      <td>0.709719</td>\n",
              "      <td>0.695312</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating AdaGrad_linear...\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "Running experiment: AdaGrad_cosine\n",
            "==================================================\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▆██▆</td></tr><tr><td>eval/f1</td><td>▁▆██▆</td></tr><tr><td>eval/loss</td><td>█▄▂▁▁</td></tr><tr><td>eval/precision</td><td>▁▆▇▇█</td></tr><tr><td>eval/recall</td><td>▁▆██▆</td></tr><tr><td>eval/runtime</td><td>████▁</td></tr><tr><td>eval/samples_per_second</td><td>▇▇▄█▁</td></tr><tr><td>eval/steps_per_second</td><td>▇▇▄█▁</td></tr><tr><td>final_accuracy</td><td>▁</td></tr><tr><td>final_f1</td><td>▁</td></tr><tr><td>final_precision</td><td>▁</td></tr><tr><td>final_recall</td><td>▁</td></tr><tr><td>test/accuracy</td><td>▁</td></tr><tr><td>test/f1</td><td>▁</td></tr><tr><td>test/loss</td><td>▁</td></tr><tr><td>test/precision</td><td>▁</td></tr><tr><td>test/recall</td><td>▁</td></tr><tr><td>test/runtime</td><td>▁</td></tr><tr><td>test/samples_per_second</td><td>▁</td></tr><tr><td>test/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▃▃▆▆████</td></tr><tr><td>train/global_step</td><td>▁▁▃▃▆▆███████</td></tr><tr><td>train/grad_norm</td><td>▂▂▁█</td></tr><tr><td>train/learning_rate</td><td>█▆▃▁</td></tr><tr><td>train/loss</td><td>█▄▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.625</td></tr><tr><td>eval/f1</td><td>0.60608</td></tr><tr><td>eval/loss</td><td>1.66723</td></tr><tr><td>eval/precision</td><td>0.74033</td></tr><tr><td>eval/recall</td><td>0.625</td></tr><tr><td>eval/runtime</td><td>1.7604</td></tr><tr><td>eval/samples_per_second</td><td>18.178</td></tr><tr><td>eval/steps_per_second</td><td>1.136</td></tr><tr><td>final_accuracy</td><td>0.625</td></tr><tr><td>final_f1</td><td>0.60608</td></tr><tr><td>final_precision</td><td>0.74033</td></tr><tr><td>final_recall</td><td>0.625</td></tr><tr><td>test/accuracy</td><td>0.625</td></tr><tr><td>test/f1</td><td>0.60608</td></tr><tr><td>test/loss</td><td>1.66723</td></tr><tr><td>test/precision</td><td>0.74033</td></tr><tr><td>test/recall</td><td>0.625</td></tr><tr><td>test/runtime</td><td>1.7149</td></tr><tr><td>test/samples_per_second</td><td>18.66</td></tr><tr><td>test/steps_per_second</td><td>1.166</td></tr><tr><td>total_flos</td><td>4.959754037231616e+16</td></tr><tr><td>train/epoch</td><td>1</td></tr><tr><td>train/global_step</td><td>40</td></tr><tr><td>train/grad_norm</td><td>2.35135</td></tr><tr><td>train/learning_rate</td><td>1e-05</td></tr><tr><td>train/loss</td><td>1.7233</td></tr><tr><td>train_loss</td><td>1.8418</td></tr><tr><td>train_runtime</td><td>88.3578</td></tr><tr><td>train_samples_per_second</td><td>7.243</td></tr><tr><td>train_steps_per_second</td><td>0.453</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">AdaGrad_linear</strong> at: <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/2hcg36wg' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/2hcg36wg</a><br> View project at: <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers</a><br>Synced 5 W&B file(s), 1 media file(s), 2 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250420_023741-2hcg36wg/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/Users/egoh02/Github/CS7643-Project-SP25/wandb/run-20250420_023924-m54m50ur</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/m54m50ur' target=\"_blank\">AdaGrad_cosine</a></strong> to <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/m54m50ur' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/m54m50ur</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading dataset: jbarat/plant_species\n",
            "Dataset prepared with 640 training, 128 validation, and 32 test examples\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting training for AdaGrad_cosine...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='40' max='40' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [40/40 01:25, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>2.028300</td>\n",
              "      <td>1.895772</td>\n",
              "      <td>0.468750</td>\n",
              "      <td>0.431102</td>\n",
              "      <td>0.473485</td>\n",
              "      <td>0.468750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>1.828600</td>\n",
              "      <td>1.750714</td>\n",
              "      <td>0.625000</td>\n",
              "      <td>0.615312</td>\n",
              "      <td>0.672165</td>\n",
              "      <td>0.625000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>1.754500</td>\n",
              "      <td>1.687636</td>\n",
              "      <td>0.671875</td>\n",
              "      <td>0.667164</td>\n",
              "      <td>0.678261</td>\n",
              "      <td>0.671875</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>1.713600</td>\n",
              "      <td>1.677780</td>\n",
              "      <td>0.679688</td>\n",
              "      <td>0.675768</td>\n",
              "      <td>0.692624</td>\n",
              "      <td>0.679688</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating AdaGrad_cosine...\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "Running experiment: AdaGrad_polynomial\n",
            "==================================================\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▆██▇</td></tr><tr><td>eval/f1</td><td>▁▆██▇</td></tr><tr><td>eval/loss</td><td>█▄▂▁▁</td></tr><tr><td>eval/precision</td><td>▁▇███</td></tr><tr><td>eval/recall</td><td>▁▆██▇</td></tr><tr><td>eval/runtime</td><td>████▁</td></tr><tr><td>eval/samples_per_second</td><td>▇▆▅█▁</td></tr><tr><td>eval/steps_per_second</td><td>▇▆▅█▁</td></tr><tr><td>final_accuracy</td><td>▁</td></tr><tr><td>final_f1</td><td>▁</td></tr><tr><td>final_precision</td><td>▁</td></tr><tr><td>final_recall</td><td>▁</td></tr><tr><td>test/accuracy</td><td>▁</td></tr><tr><td>test/f1</td><td>▁</td></tr><tr><td>test/loss</td><td>▁</td></tr><tr><td>test/precision</td><td>▁</td></tr><tr><td>test/recall</td><td>▁</td></tr><tr><td>test/runtime</td><td>▁</td></tr><tr><td>test/samples_per_second</td><td>▁</td></tr><tr><td>test/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▃▃▆▆████</td></tr><tr><td>train/global_step</td><td>▁▁▃▃▆▆███████</td></tr><tr><td>train/grad_norm</td><td>▄▁▃█</td></tr><tr><td>train/learning_rate</td><td>█▆▃▁</td></tr><tr><td>train/loss</td><td>█▄▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.65625</td></tr><tr><td>eval/f1</td><td>0.65455</td></tr><tr><td>eval/loss</td><td>1.66387</td></tr><tr><td>eval/precision</td><td>0.69271</td></tr><tr><td>eval/recall</td><td>0.65625</td></tr><tr><td>eval/runtime</td><td>1.7982</td></tr><tr><td>eval/samples_per_second</td><td>17.796</td></tr><tr><td>eval/steps_per_second</td><td>1.112</td></tr><tr><td>final_accuracy</td><td>0.65625</td></tr><tr><td>final_f1</td><td>0.65455</td></tr><tr><td>final_precision</td><td>0.69271</td></tr><tr><td>final_recall</td><td>0.65625</td></tr><tr><td>test/accuracy</td><td>0.65625</td></tr><tr><td>test/f1</td><td>0.65455</td></tr><tr><td>test/loss</td><td>1.66387</td></tr><tr><td>test/precision</td><td>0.69271</td></tr><tr><td>test/recall</td><td>0.65625</td></tr><tr><td>test/runtime</td><td>2.3426</td></tr><tr><td>test/samples_per_second</td><td>13.66</td></tr><tr><td>test/steps_per_second</td><td>0.854</td></tr><tr><td>total_flos</td><td>4.959754037231616e+16</td></tr><tr><td>train/epoch</td><td>1</td></tr><tr><td>train/global_step</td><td>40</td></tr><tr><td>train/grad_norm</td><td>1.92878</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.7136</td></tr><tr><td>train_loss</td><td>1.83125</td></tr><tr><td>train_runtime</td><td>87.6842</td></tr><tr><td>train_samples_per_second</td><td>7.299</td></tr><tr><td>train_steps_per_second</td><td>0.456</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">AdaGrad_cosine</strong> at: <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/m54m50ur' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/m54m50ur</a><br> View project at: <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers</a><br>Synced 5 W&B file(s), 1 media file(s), 2 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250420_023924-m54m50ur/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/Users/egoh02/Github/CS7643-Project-SP25/wandb/run-20250420_024106-vro8j1yr</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/vro8j1yr' target=\"_blank\">AdaGrad_polynomial</a></strong> to <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/vro8j1yr' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/vro8j1yr</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading dataset: jbarat/plant_species\n",
            "Dataset prepared with 640 training, 128 validation, and 32 test examples\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting training for AdaGrad_polynomial...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='40' max='40' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [40/40 01:24, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>2.029000</td>\n",
              "      <td>1.904788</td>\n",
              "      <td>0.453125</td>\n",
              "      <td>0.412828</td>\n",
              "      <td>0.451332</td>\n",
              "      <td>0.453125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>1.843600</td>\n",
              "      <td>1.771494</td>\n",
              "      <td>0.625000</td>\n",
              "      <td>0.609987</td>\n",
              "      <td>0.660550</td>\n",
              "      <td>0.625000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>1.777900</td>\n",
              "      <td>1.706696</td>\n",
              "      <td>0.664062</td>\n",
              "      <td>0.656226</td>\n",
              "      <td>0.670772</td>\n",
              "      <td>0.664062</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>1.727100</td>\n",
              "      <td>1.685879</td>\n",
              "      <td>0.679688</td>\n",
              "      <td>0.677485</td>\n",
              "      <td>0.703575</td>\n",
              "      <td>0.679688</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating AdaGrad_polynomial...\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "Running experiment: AdaGrad_cyclic\n",
            "==================================================\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▆██▆</td></tr><tr><td>eval/f1</td><td>▁▆▇█▆</td></tr><tr><td>eval/loss</td><td>█▄▂▂▁</td></tr><tr><td>eval/precision</td><td>▁▇▇██</td></tr><tr><td>eval/recall</td><td>▁▆██▆</td></tr><tr><td>eval/runtime</td><td>████▁</td></tr><tr><td>eval/samples_per_second</td><td>▂▇▃█▁</td></tr><tr><td>eval/steps_per_second</td><td>▂▇▃█▁</td></tr><tr><td>final_accuracy</td><td>▁</td></tr><tr><td>final_f1</td><td>▁</td></tr><tr><td>final_precision</td><td>▁</td></tr><tr><td>final_recall</td><td>▁</td></tr><tr><td>test/accuracy</td><td>▁</td></tr><tr><td>test/f1</td><td>▁</td></tr><tr><td>test/loss</td><td>▁</td></tr><tr><td>test/precision</td><td>▁</td></tr><tr><td>test/recall</td><td>▁</td></tr><tr><td>test/runtime</td><td>▁</td></tr><tr><td>test/samples_per_second</td><td>▁</td></tr><tr><td>test/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▃▃▆▆████</td></tr><tr><td>train/global_step</td><td>▁▁▃▃▆▆███████</td></tr><tr><td>train/grad_norm</td><td>▄▂▁█</td></tr><tr><td>train/learning_rate</td><td>█▆▃▁</td></tr><tr><td>train/loss</td><td>█▄▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.625</td></tr><tr><td>eval/f1</td><td>0.6117</td></tr><tr><td>eval/loss</td><td>1.66859</td></tr><tr><td>eval/precision</td><td>0.70156</td></tr><tr><td>eval/recall</td><td>0.625</td></tr><tr><td>eval/runtime</td><td>1.7216</td></tr><tr><td>eval/samples_per_second</td><td>18.587</td></tr><tr><td>eval/steps_per_second</td><td>1.162</td></tr><tr><td>final_accuracy</td><td>0.625</td></tr><tr><td>final_f1</td><td>0.6117</td></tr><tr><td>final_precision</td><td>0.70156</td></tr><tr><td>final_recall</td><td>0.625</td></tr><tr><td>test/accuracy</td><td>0.625</td></tr><tr><td>test/f1</td><td>0.6117</td></tr><tr><td>test/loss</td><td>1.66859</td></tr><tr><td>test/precision</td><td>0.70156</td></tr><tr><td>test/recall</td><td>0.625</td></tr><tr><td>test/runtime</td><td>1.709</td></tr><tr><td>test/samples_per_second</td><td>18.724</td></tr><tr><td>test/steps_per_second</td><td>1.17</td></tr><tr><td>total_flos</td><td>4.959754037231616e+16</td></tr><tr><td>train/epoch</td><td>1</td></tr><tr><td>train/global_step</td><td>40</td></tr><tr><td>train/grad_norm</td><td>1.95836</td></tr><tr><td>train/learning_rate</td><td>1e-05</td></tr><tr><td>train/loss</td><td>1.7271</td></tr><tr><td>train_loss</td><td>1.84438</td></tr><tr><td>train_runtime</td><td>86.8234</td></tr><tr><td>train_samples_per_second</td><td>7.371</td></tr><tr><td>train_steps_per_second</td><td>0.461</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">AdaGrad_polynomial</strong> at: <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/vro8j1yr' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/vro8j1yr</a><br> View project at: <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers</a><br>Synced 5 W&B file(s), 1 media file(s), 2 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250420_024106-vro8j1yr/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/Users/egoh02/Github/CS7643-Project-SP25/wandb/run-20250420_024246-4mckgrr2</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/4mckgrr2' target=\"_blank\">AdaGrad_cyclic</a></strong> to <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/4mckgrr2' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/4mckgrr2</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading dataset: jbarat/plant_species\n",
            "Dataset prepared with 640 training, 128 validation, and 32 test examples\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting training for AdaGrad_cyclic...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='40' max='40' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [40/40 01:26, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>2.058800</td>\n",
              "      <td>1.987516</td>\n",
              "      <td>0.375000</td>\n",
              "      <td>0.356469</td>\n",
              "      <td>0.385841</td>\n",
              "      <td>0.375000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>1.907300</td>\n",
              "      <td>1.827820</td>\n",
              "      <td>0.593750</td>\n",
              "      <td>0.575573</td>\n",
              "      <td>0.608016</td>\n",
              "      <td>0.593750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>1.803200</td>\n",
              "      <td>1.739220</td>\n",
              "      <td>0.625000</td>\n",
              "      <td>0.620006</td>\n",
              "      <td>0.633901</td>\n",
              "      <td>0.625000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>1.741500</td>\n",
              "      <td>1.705353</td>\n",
              "      <td>0.640625</td>\n",
              "      <td>0.637246</td>\n",
              "      <td>0.655621</td>\n",
              "      <td>0.640625</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating AdaGrad_cyclic...\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "Running experiment: AdaGrad_exponential\n",
            "==================================================\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▇██▇</td></tr><tr><td>eval/f1</td><td>▁▆██▇</td></tr><tr><td>eval/loss</td><td>█▄▂▁▁</td></tr><tr><td>eval/precision</td><td>▁▇▇█▇</td></tr><tr><td>eval/recall</td><td>▁▇██▇</td></tr><tr><td>eval/runtime</td><td>████▁</td></tr><tr><td>eval/samples_per_second</td><td>█▇█▇▁</td></tr><tr><td>eval/steps_per_second</td><td>█▇█▇▁</td></tr><tr><td>final_accuracy</td><td>▁</td></tr><tr><td>final_f1</td><td>▁</td></tr><tr><td>final_precision</td><td>▁</td></tr><tr><td>final_recall</td><td>▁</td></tr><tr><td>test/accuracy</td><td>▁</td></tr><tr><td>test/f1</td><td>▁</td></tr><tr><td>test/loss</td><td>▁</td></tr><tr><td>test/precision</td><td>▁</td></tr><tr><td>test/recall</td><td>▁</td></tr><tr><td>test/runtime</td><td>▁</td></tr><tr><td>test/samples_per_second</td><td>▁</td></tr><tr><td>test/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▃▃▆▆████</td></tr><tr><td>train/global_step</td><td>▁▁▃▃▆▆███████</td></tr><tr><td>train/grad_norm</td><td>▁▄▄█</td></tr><tr><td>train/learning_rate</td><td>▇█▅▁</td></tr><tr><td>train/loss</td><td>█▅▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.59375</td></tr><tr><td>eval/f1</td><td>0.58045</td></tr><tr><td>eval/loss</td><td>1.68392</td></tr><tr><td>eval/precision</td><td>0.63542</td></tr><tr><td>eval/recall</td><td>0.59375</td></tr><tr><td>eval/runtime</td><td>1.8159</td></tr><tr><td>eval/samples_per_second</td><td>17.622</td></tr><tr><td>eval/steps_per_second</td><td>1.101</td></tr><tr><td>final_accuracy</td><td>0.59375</td></tr><tr><td>final_f1</td><td>0.58045</td></tr><tr><td>final_precision</td><td>0.63542</td></tr><tr><td>final_recall</td><td>0.59375</td></tr><tr><td>test/accuracy</td><td>0.59375</td></tr><tr><td>test/f1</td><td>0.58045</td></tr><tr><td>test/loss</td><td>1.68392</td></tr><tr><td>test/precision</td><td>0.63542</td></tr><tr><td>test/recall</td><td>0.59375</td></tr><tr><td>test/runtime</td><td>1.7626</td></tr><tr><td>test/samples_per_second</td><td>18.155</td></tr><tr><td>test/steps_per_second</td><td>1.135</td></tr><tr><td>total_flos</td><td>4.959754037231616e+16</td></tr><tr><td>train/epoch</td><td>1</td></tr><tr><td>train/global_step</td><td>40</td></tr><tr><td>train/grad_norm</td><td>2.14124</td></tr><tr><td>train/learning_rate</td><td>2e-05</td></tr><tr><td>train/loss</td><td>1.7415</td></tr><tr><td>train_loss</td><td>1.87769</td></tr><tr><td>train_runtime</td><td>89.5279</td></tr><tr><td>train_samples_per_second</td><td>7.149</td></tr><tr><td>train_steps_per_second</td><td>0.447</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">AdaGrad_cyclic</strong> at: <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/4mckgrr2' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/4mckgrr2</a><br> View project at: <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers</a><br>Synced 5 W&B file(s), 1 media file(s), 2 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250420_024246-4mckgrr2/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/Users/egoh02/Github/CS7643-Project-SP25/wandb/run-20250420_024429-176js5kg</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/176js5kg' target=\"_blank\">AdaGrad_exponential</a></strong> to <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/176js5kg' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/176js5kg</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading dataset: jbarat/plant_species\n",
            "Dataset prepared with 640 training, 128 validation, and 32 test examples\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting training for AdaGrad_exponential...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='40' max='40' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [40/40 01:26, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>1.950900</td>\n",
              "      <td>1.830168</td>\n",
              "      <td>0.570312</td>\n",
              "      <td>0.539615</td>\n",
              "      <td>0.600633</td>\n",
              "      <td>0.570312</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>1.789600</td>\n",
              "      <td>1.742023</td>\n",
              "      <td>0.617188</td>\n",
              "      <td>0.585584</td>\n",
              "      <td>0.620709</td>\n",
              "      <td>0.617188</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>1.761300</td>\n",
              "      <td>1.705084</td>\n",
              "      <td>0.648438</td>\n",
              "      <td>0.623617</td>\n",
              "      <td>0.673866</td>\n",
              "      <td>0.648438</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>1.729100</td>\n",
              "      <td>1.683209</td>\n",
              "      <td>0.664062</td>\n",
              "      <td>0.644618</td>\n",
              "      <td>0.693414</td>\n",
              "      <td>0.664062</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating AdaGrad_exponential...\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/egoh02/Github/CS7643-Project-SP25/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/Users/egoh02/Github/CS7643-Project-SP25/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "Running experiment: AdaGrad_constant\n",
            "==================================================\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▅▇█▃</td></tr><tr><td>eval/f1</td><td>▁▄▇█▃</td></tr><tr><td>eval/loss</td><td>█▄▂▁▂</td></tr><tr><td>eval/precision</td><td>▁▃▇█▆</td></tr><tr><td>eval/recall</td><td>▁▅▇█▃</td></tr><tr><td>eval/runtime</td><td>▇█▇█▁</td></tr><tr><td>eval/samples_per_second</td><td>█▁█▃▆</td></tr><tr><td>eval/steps_per_second</td><td>█▁█▃▆</td></tr><tr><td>final_accuracy</td><td>▁</td></tr><tr><td>final_f1</td><td>▁</td></tr><tr><td>final_precision</td><td>▁</td></tr><tr><td>final_recall</td><td>▁</td></tr><tr><td>test/accuracy</td><td>▁</td></tr><tr><td>test/f1</td><td>▁</td></tr><tr><td>test/loss</td><td>▁</td></tr><tr><td>test/precision</td><td>▁</td></tr><tr><td>test/recall</td><td>▁</td></tr><tr><td>test/runtime</td><td>▁</td></tr><tr><td>test/samples_per_second</td><td>▁</td></tr><tr><td>test/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▃▃▆▆████</td></tr><tr><td>train/global_step</td><td>▁▁▃▃▆▆███████</td></tr><tr><td>train/grad_norm</td><td>▁▁▂█</td></tr><tr><td>train/learning_rate</td><td>█▄▂▁</td></tr><tr><td>train/loss</td><td>█▃▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.59375</td></tr><tr><td>eval/f1</td><td>0.573</td></tr><tr><td>eval/loss</td><td>1.69698</td></tr><tr><td>eval/precision</td><td>0.66183</td></tr><tr><td>eval/recall</td><td>0.59375</td></tr><tr><td>eval/runtime</td><td>1.7457</td></tr><tr><td>eval/samples_per_second</td><td>18.331</td></tr><tr><td>eval/steps_per_second</td><td>1.146</td></tr><tr><td>final_accuracy</td><td>0.59375</td></tr><tr><td>final_f1</td><td>0.573</td></tr><tr><td>final_precision</td><td>0.66183</td></tr><tr><td>final_recall</td><td>0.59375</td></tr><tr><td>test/accuracy</td><td>0.59375</td></tr><tr><td>test/f1</td><td>0.573</td></tr><tr><td>test/loss</td><td>1.69698</td></tr><tr><td>test/precision</td><td>0.66183</td></tr><tr><td>test/recall</td><td>0.59375</td></tr><tr><td>test/runtime</td><td>1.7376</td></tr><tr><td>test/samples_per_second</td><td>18.416</td></tr><tr><td>test/steps_per_second</td><td>1.151</td></tr><tr><td>total_flos</td><td>4.959754037231616e+16</td></tr><tr><td>train/epoch</td><td>1</td></tr><tr><td>train/global_step</td><td>40</td></tr><tr><td>train/grad_norm</td><td>1.93998</td></tr><tr><td>train/learning_rate</td><td>3e-05</td></tr><tr><td>train/loss</td><td>1.7291</td></tr><tr><td>train_loss</td><td>1.80773</td></tr><tr><td>train_runtime</td><td>88.934</td></tr><tr><td>train_samples_per_second</td><td>7.196</td></tr><tr><td>train_steps_per_second</td><td>0.45</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">AdaGrad_exponential</strong> at: <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/176js5kg' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/176js5kg</a><br> View project at: <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers</a><br>Synced 5 W&B file(s), 1 media file(s), 2 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250420_024429-176js5kg/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/Users/egoh02/Github/CS7643-Project-SP25/wandb/run-20250420_024612-fkkg92x5</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/fkkg92x5' target=\"_blank\">AdaGrad_constant</a></strong> to <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/fkkg92x5' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/fkkg92x5</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading dataset: jbarat/plant_species\n",
            "Dataset prepared with 640 training, 128 validation, and 32 test examples\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting training for AdaGrad_constant...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='40' max='40' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [40/40 01:24, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>1.939300</td>\n",
              "      <td>1.785121</td>\n",
              "      <td>0.640625</td>\n",
              "      <td>0.620058</td>\n",
              "      <td>0.678666</td>\n",
              "      <td>0.640625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>1.711900</td>\n",
              "      <td>1.617373</td>\n",
              "      <td>0.664062</td>\n",
              "      <td>0.647575</td>\n",
              "      <td>0.722936</td>\n",
              "      <td>0.664062</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>1.582100</td>\n",
              "      <td>1.468101</td>\n",
              "      <td>0.718750</td>\n",
              "      <td>0.719058</td>\n",
              "      <td>0.734227</td>\n",
              "      <td>0.718750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>1.462600</td>\n",
              "      <td>1.372445</td>\n",
              "      <td>0.703125</td>\n",
              "      <td>0.697905</td>\n",
              "      <td>0.736233</td>\n",
              "      <td>0.703125</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating AdaGrad_constant...\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "Running experiment: AdaGrad_cosine_with_restarts\n",
            "==================================================\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▃█▇▅</td></tr><tr><td>eval/f1</td><td>▁▃█▇▆</td></tr><tr><td>eval/loss</td><td>█▅▃▁▂</td></tr><tr><td>eval/precision</td><td>▁▃▄▄█</td></tr><tr><td>eval/recall</td><td>▁▃█▇▅</td></tr><tr><td>eval/runtime</td><td>██▇█▁</td></tr><tr><td>eval/samples_per_second</td><td>▇▄█▇▁</td></tr><tr><td>eval/steps_per_second</td><td>▇▄█▇▁</td></tr><tr><td>final_accuracy</td><td>▁</td></tr><tr><td>final_f1</td><td>▁</td></tr><tr><td>final_precision</td><td>▁</td></tr><tr><td>final_recall</td><td>▁</td></tr><tr><td>test/accuracy</td><td>▁</td></tr><tr><td>test/f1</td><td>▁</td></tr><tr><td>test/loss</td><td>▁</td></tr><tr><td>test/precision</td><td>▁</td></tr><tr><td>test/recall</td><td>▁</td></tr><tr><td>test/runtime</td><td>▁</td></tr><tr><td>test/samples_per_second</td><td>▁</td></tr><tr><td>test/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▃▃▆▆████</td></tr><tr><td>train/global_step</td><td>▁▁▃▃▆▆███████</td></tr><tr><td>train/grad_norm</td><td>█▂▁▃</td></tr><tr><td>train/learning_rate</td><td>▁▁▁▁</td></tr><tr><td>train/loss</td><td>█▅▃▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.6875</td></tr><tr><td>eval/f1</td><td>0.68512</td></tr><tr><td>eval/loss</td><td>1.40856</td></tr><tr><td>eval/precision</td><td>0.82812</td></tr><tr><td>eval/recall</td><td>0.6875</td></tr><tr><td>eval/runtime</td><td>1.8806</td></tr><tr><td>eval/samples_per_second</td><td>17.016</td></tr><tr><td>eval/steps_per_second</td><td>1.064</td></tr><tr><td>final_accuracy</td><td>0.6875</td></tr><tr><td>final_f1</td><td>0.68512</td></tr><tr><td>final_precision</td><td>0.82812</td></tr><tr><td>final_recall</td><td>0.6875</td></tr><tr><td>test/accuracy</td><td>0.6875</td></tr><tr><td>test/f1</td><td>0.68512</td></tr><tr><td>test/loss</td><td>1.40856</td></tr><tr><td>test/precision</td><td>0.82812</td></tr><tr><td>test/recall</td><td>0.6875</td></tr><tr><td>test/runtime</td><td>3.6153</td></tr><tr><td>test/samples_per_second</td><td>8.851</td></tr><tr><td>test/steps_per_second</td><td>0.553</td></tr><tr><td>total_flos</td><td>4.959754037231616e+16</td></tr><tr><td>train/epoch</td><td>1</td></tr><tr><td>train/global_step</td><td>40</td></tr><tr><td>train/grad_norm</td><td>2.09323</td></tr><tr><td>train/learning_rate</td><td>0.0002</td></tr><tr><td>train/loss</td><td>1.4626</td></tr><tr><td>train_loss</td><td>1.67398</td></tr><tr><td>train_runtime</td><td>87.0288</td></tr><tr><td>train_samples_per_second</td><td>7.354</td></tr><tr><td>train_steps_per_second</td><td>0.46</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">AdaGrad_constant</strong> at: <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/fkkg92x5' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/fkkg92x5</a><br> View project at: <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers</a><br>Synced 5 W&B file(s), 1 media file(s), 2 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250420_024612-fkkg92x5/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/Users/egoh02/Github/CS7643-Project-SP25/wandb/run-20250420_024755-m0o3q5sn</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/m0o3q5sn' target=\"_blank\">AdaGrad_cosine_with_restarts</a></strong> to <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/m0o3q5sn' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/m0o3q5sn</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading dataset: jbarat/plant_species\n",
            "Dataset prepared with 640 training, 128 validation, and 32 test examples\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting training for AdaGrad_cosine_with_restarts...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='40' max='40' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [40/40 01:27, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>2.028300</td>\n",
              "      <td>1.895772</td>\n",
              "      <td>0.468750</td>\n",
              "      <td>0.431102</td>\n",
              "      <td>0.473485</td>\n",
              "      <td>0.468750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>1.828600</td>\n",
              "      <td>1.750714</td>\n",
              "      <td>0.625000</td>\n",
              "      <td>0.615312</td>\n",
              "      <td>0.672165</td>\n",
              "      <td>0.625000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>1.754500</td>\n",
              "      <td>1.687636</td>\n",
              "      <td>0.671875</td>\n",
              "      <td>0.667164</td>\n",
              "      <td>0.678261</td>\n",
              "      <td>0.671875</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>1.713600</td>\n",
              "      <td>1.677780</td>\n",
              "      <td>0.679688</td>\n",
              "      <td>0.675768</td>\n",
              "      <td>0.692624</td>\n",
              "      <td>0.679688</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating AdaGrad_cosine_with_restarts...\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "Running experiment: AdaGrad_constant_with_warmup\n",
            "==================================================\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▆██▇</td></tr><tr><td>eval/f1</td><td>▁▆██▇</td></tr><tr><td>eval/loss</td><td>█▄▂▁▁</td></tr><tr><td>eval/precision</td><td>▁▇███</td></tr><tr><td>eval/recall</td><td>▁▆██▇</td></tr><tr><td>eval/runtime</td><td>████▁</td></tr><tr><td>eval/samples_per_second</td><td>███▁▁</td></tr><tr><td>eval/steps_per_second</td><td>███▁▁</td></tr><tr><td>final_accuracy</td><td>▁</td></tr><tr><td>final_f1</td><td>▁</td></tr><tr><td>final_precision</td><td>▁</td></tr><tr><td>final_recall</td><td>▁</td></tr><tr><td>test/accuracy</td><td>▁</td></tr><tr><td>test/f1</td><td>▁</td></tr><tr><td>test/loss</td><td>▁</td></tr><tr><td>test/precision</td><td>▁</td></tr><tr><td>test/recall</td><td>▁</td></tr><tr><td>test/runtime</td><td>▁</td></tr><tr><td>test/samples_per_second</td><td>▁</td></tr><tr><td>test/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▃▃▆▆████</td></tr><tr><td>train/global_step</td><td>▁▁▃▃▆▆███████</td></tr><tr><td>train/grad_norm</td><td>▄▁▃█</td></tr><tr><td>train/learning_rate</td><td>█▆▃▁</td></tr><tr><td>train/loss</td><td>█▄▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.65625</td></tr><tr><td>eval/f1</td><td>0.65455</td></tr><tr><td>eval/loss</td><td>1.66387</td></tr><tr><td>eval/precision</td><td>0.69271</td></tr><tr><td>eval/recall</td><td>0.65625</td></tr><tr><td>eval/runtime</td><td>1.7498</td></tr><tr><td>eval/samples_per_second</td><td>18.288</td></tr><tr><td>eval/steps_per_second</td><td>1.143</td></tr><tr><td>final_accuracy</td><td>0.65625</td></tr><tr><td>final_f1</td><td>0.65455</td></tr><tr><td>final_precision</td><td>0.69271</td></tr><tr><td>final_recall</td><td>0.65625</td></tr><tr><td>test/accuracy</td><td>0.65625</td></tr><tr><td>test/f1</td><td>0.65455</td></tr><tr><td>test/loss</td><td>1.66387</td></tr><tr><td>test/precision</td><td>0.69271</td></tr><tr><td>test/recall</td><td>0.65625</td></tr><tr><td>test/runtime</td><td>1.7697</td></tr><tr><td>test/samples_per_second</td><td>18.082</td></tr><tr><td>test/steps_per_second</td><td>1.13</td></tr><tr><td>total_flos</td><td>4.959754037231616e+16</td></tr><tr><td>train/epoch</td><td>1</td></tr><tr><td>train/global_step</td><td>40</td></tr><tr><td>train/grad_norm</td><td>1.92878</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.7136</td></tr><tr><td>train_loss</td><td>1.83125</td></tr><tr><td>train_runtime</td><td>89.9483</td></tr><tr><td>train_samples_per_second</td><td>7.115</td></tr><tr><td>train_steps_per_second</td><td>0.445</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">AdaGrad_cosine_with_restarts</strong> at: <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/m0o3q5sn' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/m0o3q5sn</a><br> View project at: <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers</a><br>Synced 5 W&B file(s), 1 media file(s), 2 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250420_024755-m0o3q5sn/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/Users/egoh02/Github/CS7643-Project-SP25/wandb/run-20250420_024940-7yyob59r</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/7yyob59r' target=\"_blank\">AdaGrad_constant_with_warmup</a></strong> to <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/7yyob59r' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/7yyob59r</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading dataset: jbarat/plant_species\n",
            "Dataset prepared with 640 training, 128 validation, and 32 test examples\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting training for AdaGrad_constant_with_warmup...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='40' max='40' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [40/40 01:28, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>2.028300</td>\n",
              "      <td>1.892875</td>\n",
              "      <td>0.468750</td>\n",
              "      <td>0.431102</td>\n",
              "      <td>0.473485</td>\n",
              "      <td>0.468750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>1.814000</td>\n",
              "      <td>1.711545</td>\n",
              "      <td>0.664062</td>\n",
              "      <td>0.655242</td>\n",
              "      <td>0.686345</td>\n",
              "      <td>0.664062</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>1.684900</td>\n",
              "      <td>1.566004</td>\n",
              "      <td>0.664062</td>\n",
              "      <td>0.660124</td>\n",
              "      <td>0.667430</td>\n",
              "      <td>0.664062</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>1.546600</td>\n",
              "      <td>1.455386</td>\n",
              "      <td>0.664062</td>\n",
              "      <td>0.664035</td>\n",
              "      <td>0.734983</td>\n",
              "      <td>0.664062</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating AdaGrad_constant_with_warmup...\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "Running experiment: SGD_linear\n",
            "==================================================\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▆▆▆█</td></tr><tr><td>eval/f1</td><td>▁▆▆▆█</td></tr><tr><td>eval/loss</td><td>█▅▃▁▁</td></tr><tr><td>eval/precision</td><td>▁▅▅▆█</td></tr><tr><td>eval/recall</td><td>▁▆▆▆█</td></tr><tr><td>eval/runtime</td><td>████▁</td></tr><tr><td>eval/samples_per_second</td><td>▄▇██▁</td></tr><tr><td>eval/steps_per_second</td><td>▄▇██▁</td></tr><tr><td>final_accuracy</td><td>▁</td></tr><tr><td>final_f1</td><td>▁</td></tr><tr><td>final_precision</td><td>▁</td></tr><tr><td>final_recall</td><td>▁</td></tr><tr><td>test/accuracy</td><td>▁</td></tr><tr><td>test/f1</td><td>▁</td></tr><tr><td>test/loss</td><td>▁</td></tr><tr><td>test/precision</td><td>▁</td></tr><tr><td>test/recall</td><td>▁</td></tr><tr><td>test/runtime</td><td>▁</td></tr><tr><td>test/samples_per_second</td><td>▁</td></tr><tr><td>test/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▃▃▆▆████</td></tr><tr><td>train/global_step</td><td>▁▁▃▃▆▆███████</td></tr><tr><td>train/grad_norm</td><td>▂▁▄█</td></tr><tr><td>train/learning_rate</td><td>▁▁▁▁</td></tr><tr><td>train/loss</td><td>█▅▃▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.75</td></tr><tr><td>eval/f1</td><td>0.73559</td></tr><tr><td>eval/loss</td><td>1.47829</td></tr><tr><td>eval/precision</td><td>0.85417</td></tr><tr><td>eval/recall</td><td>0.75</td></tr><tr><td>eval/runtime</td><td>1.8388</td></tr><tr><td>eval/samples_per_second</td><td>17.402</td></tr><tr><td>eval/steps_per_second</td><td>1.088</td></tr><tr><td>final_accuracy</td><td>0.75</td></tr><tr><td>final_f1</td><td>0.73559</td></tr><tr><td>final_precision</td><td>0.85417</td></tr><tr><td>final_recall</td><td>0.75</td></tr><tr><td>test/accuracy</td><td>0.75</td></tr><tr><td>test/f1</td><td>0.73559</td></tr><tr><td>test/loss</td><td>1.47829</td></tr><tr><td>test/precision</td><td>0.85417</td></tr><tr><td>test/recall</td><td>0.75</td></tr><tr><td>test/runtime</td><td>1.8144</td></tr><tr><td>test/samples_per_second</td><td>17.637</td></tr><tr><td>test/steps_per_second</td><td>1.102</td></tr><tr><td>total_flos</td><td>4.959754037231616e+16</td></tr><tr><td>train/epoch</td><td>1</td></tr><tr><td>train/global_step</td><td>40</td></tr><tr><td>train/grad_norm</td><td>2.12869</td></tr><tr><td>train/learning_rate</td><td>0.0002</td></tr><tr><td>train/loss</td><td>1.5466</td></tr><tr><td>train_loss</td><td>1.76846</td></tr><tr><td>train_runtime</td><td>90.1572</td></tr><tr><td>train_samples_per_second</td><td>7.099</td></tr><tr><td>train_steps_per_second</td><td>0.444</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">AdaGrad_constant_with_warmup</strong> at: <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/7yyob59r' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/7yyob59r</a><br> View project at: <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers</a><br>Synced 5 W&B file(s), 1 media file(s), 2 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250420_024940-7yyob59r/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/Users/egoh02/Github/CS7643-Project-SP25/wandb/run-20250420_025125-t4pwlu3d</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/t4pwlu3d' target=\"_blank\">SGD_linear</a></strong> to <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/t4pwlu3d' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/t4pwlu3d</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading dataset: jbarat/plant_species\n",
            "Dataset prepared with 640 training, 128 validation, and 32 test examples\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting training for SGD_linear...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='40' max='40' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [40/40 01:31, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>2.040200</td>\n",
              "      <td>1.875883</td>\n",
              "      <td>0.539062</td>\n",
              "      <td>0.506938</td>\n",
              "      <td>0.533774</td>\n",
              "      <td>0.539062</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>1.712100</td>\n",
              "      <td>1.530677</td>\n",
              "      <td>0.710938</td>\n",
              "      <td>0.694397</td>\n",
              "      <td>0.718191</td>\n",
              "      <td>0.710938</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>1.468400</td>\n",
              "      <td>1.322560</td>\n",
              "      <td>0.734375</td>\n",
              "      <td>0.723579</td>\n",
              "      <td>0.758398</td>\n",
              "      <td>0.734375</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>1.332800</td>\n",
              "      <td>1.259260</td>\n",
              "      <td>0.742188</td>\n",
              "      <td>0.729673</td>\n",
              "      <td>0.773403</td>\n",
              "      <td>0.742188</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating SGD_linear...\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "Running experiment: SGD_cosine\n",
            "==================================================\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▇██▄</td></tr><tr><td>eval/f1</td><td>▁▇██▃</td></tr><tr><td>eval/loss</td><td>█▄▂▁▁</td></tr><tr><td>eval/precision</td><td>▁▆██▂</td></tr><tr><td>eval/recall</td><td>▁▇██▄</td></tr><tr><td>eval/runtime</td><td>█▅▇▇▁</td></tr><tr><td>eval/samples_per_second</td><td>▁█▂▂▇</td></tr><tr><td>eval/steps_per_second</td><td>▁█▂▂▇</td></tr><tr><td>final_accuracy</td><td>▁</td></tr><tr><td>final_f1</td><td>▁</td></tr><tr><td>final_precision</td><td>▁</td></tr><tr><td>final_recall</td><td>▁</td></tr><tr><td>test/accuracy</td><td>▁</td></tr><tr><td>test/f1</td><td>▁</td></tr><tr><td>test/loss</td><td>▁</td></tr><tr><td>test/precision</td><td>▁</td></tr><tr><td>test/recall</td><td>▁</td></tr><tr><td>test/runtime</td><td>▁</td></tr><tr><td>test/samples_per_second</td><td>▁</td></tr><tr><td>test/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▃▃▆▆████</td></tr><tr><td>train/global_step</td><td>▁▁▃▃▆▆███████</td></tr><tr><td>train/grad_norm</td><td>▁▂▇█</td></tr><tr><td>train/learning_rate</td><td>█▆▃▁</td></tr><tr><td>train/loss</td><td>█▅▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.625</td></tr><tr><td>eval/f1</td><td>0.57761</td></tr><tr><td>eval/loss</td><td>1.23707</td></tr><tr><td>eval/precision</td><td>0.56944</td></tr><tr><td>eval/recall</td><td>0.625</td></tr><tr><td>eval/runtime</td><td>1.8263</td></tr><tr><td>eval/samples_per_second</td><td>17.522</td></tr><tr><td>eval/steps_per_second</td><td>1.095</td></tr><tr><td>final_accuracy</td><td>0.625</td></tr><tr><td>final_f1</td><td>0.57761</td></tr><tr><td>final_precision</td><td>0.56944</td></tr><tr><td>final_recall</td><td>0.625</td></tr><tr><td>test/accuracy</td><td>0.625</td></tr><tr><td>test/f1</td><td>0.57761</td></tr><tr><td>test/loss</td><td>1.23707</td></tr><tr><td>test/precision</td><td>0.56944</td></tr><tr><td>test/recall</td><td>0.625</td></tr><tr><td>test/runtime</td><td>1.7704</td></tr><tr><td>test/samples_per_second</td><td>18.075</td></tr><tr><td>test/steps_per_second</td><td>1.13</td></tr><tr><td>total_flos</td><td>4.959754037231616e+16</td></tr><tr><td>train/epoch</td><td>1</td></tr><tr><td>train/global_step</td><td>40</td></tr><tr><td>train/grad_norm</td><td>2.42714</td></tr><tr><td>train/learning_rate</td><td>0.00056</td></tr><tr><td>train/loss</td><td>1.3328</td></tr><tr><td>train_loss</td><td>1.63839</td></tr><tr><td>train_runtime</td><td>93.9628</td></tr><tr><td>train_samples_per_second</td><td>6.811</td></tr><tr><td>train_steps_per_second</td><td>0.426</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">SGD_linear</strong> at: <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/t4pwlu3d' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/t4pwlu3d</a><br> View project at: <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers</a><br>Synced 5 W&B file(s), 1 media file(s), 2 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250420_025125-t4pwlu3d/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/Users/egoh02/Github/CS7643-Project-SP25/wandb/run-20250420_025314-cg13gkix</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/cg13gkix' target=\"_blank\">SGD_cosine</a></strong> to <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/cg13gkix' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/cg13gkix</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading dataset: jbarat/plant_species\n",
            "Dataset prepared with 640 training, 128 validation, and 32 test examples\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting training for SGD_cosine...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='40' max='40' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [40/40 01:23, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>2.038900</td>\n",
              "      <td>1.864676</td>\n",
              "      <td>0.539062</td>\n",
              "      <td>0.508032</td>\n",
              "      <td>0.529822</td>\n",
              "      <td>0.539062</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>1.683700</td>\n",
              "      <td>1.481734</td>\n",
              "      <td>0.710938</td>\n",
              "      <td>0.695309</td>\n",
              "      <td>0.723851</td>\n",
              "      <td>0.710938</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>1.427400</td>\n",
              "      <td>1.293991</td>\n",
              "      <td>0.734375</td>\n",
              "      <td>0.721809</td>\n",
              "      <td>0.763800</td>\n",
              "      <td>0.734375</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>1.324700</td>\n",
              "      <td>1.264845</td>\n",
              "      <td>0.742188</td>\n",
              "      <td>0.732071</td>\n",
              "      <td>0.771488</td>\n",
              "      <td>0.742188</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating SGD_cosine...\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "Running experiment: SGD_polynomial\n",
            "==================================================\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▇██▄</td></tr><tr><td>eval/f1</td><td>▁▇██▃</td></tr><tr><td>eval/loss</td><td>█▄▂▁▁</td></tr><tr><td>eval/precision</td><td>▁▇██▂</td></tr><tr><td>eval/recall</td><td>▁▇██▄</td></tr><tr><td>eval/runtime</td><td>▇█▇▇▁</td></tr><tr><td>eval/samples_per_second</td><td>▇▁██▃</td></tr><tr><td>eval/steps_per_second</td><td>▇▁██▃</td></tr><tr><td>final_accuracy</td><td>▁</td></tr><tr><td>final_f1</td><td>▁</td></tr><tr><td>final_precision</td><td>▁</td></tr><tr><td>final_recall</td><td>▁</td></tr><tr><td>test/accuracy</td><td>▁</td></tr><tr><td>test/f1</td><td>▁</td></tr><tr><td>test/loss</td><td>▁</td></tr><tr><td>test/precision</td><td>▁</td></tr><tr><td>test/recall</td><td>▁</td></tr><tr><td>test/runtime</td><td>▁</td></tr><tr><td>test/samples_per_second</td><td>▁</td></tr><tr><td>test/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▃▃▆▆████</td></tr><tr><td>train/global_step</td><td>▁▁▃▃▆▆███████</td></tr><tr><td>train/grad_norm</td><td>▁▂▇█</td></tr><tr><td>train/learning_rate</td><td>█▆▃▁</td></tr><tr><td>train/loss</td><td>█▅▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.625</td></tr><tr><td>eval/f1</td><td>0.56942</td></tr><tr><td>eval/loss</td><td>1.24508</td></tr><tr><td>eval/precision</td><td>0.56027</td></tr><tr><td>eval/recall</td><td>0.625</td></tr><tr><td>eval/runtime</td><td>1.843</td></tr><tr><td>eval/samples_per_second</td><td>17.363</td></tr><tr><td>eval/steps_per_second</td><td>1.085</td></tr><tr><td>final_accuracy</td><td>0.625</td></tr><tr><td>final_f1</td><td>0.56942</td></tr><tr><td>final_precision</td><td>0.56027</td></tr><tr><td>final_recall</td><td>0.625</td></tr><tr><td>test/accuracy</td><td>0.625</td></tr><tr><td>test/f1</td><td>0.56942</td></tr><tr><td>test/loss</td><td>1.24508</td></tr><tr><td>test/precision</td><td>0.56027</td></tr><tr><td>test/recall</td><td>0.625</td></tr><tr><td>test/runtime</td><td>1.7845</td></tr><tr><td>test/samples_per_second</td><td>17.932</td></tr><tr><td>test/steps_per_second</td><td>1.121</td></tr><tr><td>total_flos</td><td>4.959754037231616e+16</td></tr><tr><td>train/epoch</td><td>1</td></tr><tr><td>train/global_step</td><td>40</td></tr><tr><td>train/grad_norm</td><td>2.36969</td></tr><tr><td>train/learning_rate</td><td>4e-05</td></tr><tr><td>train/loss</td><td>1.3247</td></tr><tr><td>train_loss</td><td>1.61868</td></tr><tr><td>train_runtime</td><td>85.3046</td></tr><tr><td>train_samples_per_second</td><td>7.503</td></tr><tr><td>train_steps_per_second</td><td>0.469</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">SGD_cosine</strong> at: <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/cg13gkix' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/cg13gkix</a><br> View project at: <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers</a><br>Synced 5 W&B file(s), 1 media file(s), 2 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250420_025314-cg13gkix/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/Users/egoh02/Github/CS7643-Project-SP25/wandb/run-20250420_025453-m83emkob</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/m83emkob' target=\"_blank\">SGD_polynomial</a></strong> to <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/m83emkob' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/m83emkob</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading dataset: jbarat/plant_species\n",
            "Dataset prepared with 640 training, 128 validation, and 32 test examples\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting training for SGD_polynomial...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='40' max='40' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [40/40 01:31, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>2.040200</td>\n",
              "      <td>1.875883</td>\n",
              "      <td>0.539062</td>\n",
              "      <td>0.506938</td>\n",
              "      <td>0.533774</td>\n",
              "      <td>0.539062</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>1.712100</td>\n",
              "      <td>1.530592</td>\n",
              "      <td>0.710938</td>\n",
              "      <td>0.694397</td>\n",
              "      <td>0.718191</td>\n",
              "      <td>0.710938</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>1.466500</td>\n",
              "      <td>1.316684</td>\n",
              "      <td>0.742188</td>\n",
              "      <td>0.731327</td>\n",
              "      <td>0.769627</td>\n",
              "      <td>0.742188</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>1.326600</td>\n",
              "      <td>1.251603</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.740272</td>\n",
              "      <td>0.788163</td>\n",
              "      <td>0.750000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating SGD_polynomial...\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "Running experiment: SGD_cyclic\n",
            "==================================================\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▇██▄</td></tr><tr><td>eval/f1</td><td>▁▇██▃</td></tr><tr><td>eval/loss</td><td>█▄▂▁▁</td></tr><tr><td>eval/precision</td><td>▁▆▇█▂</td></tr><tr><td>eval/recall</td><td>▁▇██▄</td></tr><tr><td>eval/runtime</td><td>▆▅█▅▁</td></tr><tr><td>eval/samples_per_second</td><td>▆█▄█▁</td></tr><tr><td>eval/steps_per_second</td><td>▆█▄█▁</td></tr><tr><td>final_accuracy</td><td>▁</td></tr><tr><td>final_f1</td><td>▁</td></tr><tr><td>final_precision</td><td>▁</td></tr><tr><td>final_recall</td><td>▁</td></tr><tr><td>test/accuracy</td><td>▁</td></tr><tr><td>test/f1</td><td>▁</td></tr><tr><td>test/loss</td><td>▁</td></tr><tr><td>test/precision</td><td>▁</td></tr><tr><td>test/recall</td><td>▁</td></tr><tr><td>test/runtime</td><td>▁</td></tr><tr><td>test/samples_per_second</td><td>▁</td></tr><tr><td>test/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▃▃▆▆████</td></tr><tr><td>train/global_step</td><td>▁▁▃▃▆▆███████</td></tr><tr><td>train/grad_norm</td><td>▁▁█▄</td></tr><tr><td>train/learning_rate</td><td>█▆▃▁</td></tr><tr><td>train/loss</td><td>█▅▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.625</td></tr><tr><td>eval/f1</td><td>0.57439</td></tr><tr><td>eval/loss</td><td>1.22946</td></tr><tr><td>eval/precision</td><td>0.57019</td></tr><tr><td>eval/recall</td><td>0.625</td></tr><tr><td>eval/runtime</td><td>3.1253</td></tr><tr><td>eval/samples_per_second</td><td>10.239</td></tr><tr><td>eval/steps_per_second</td><td>0.64</td></tr><tr><td>final_accuracy</td><td>0.625</td></tr><tr><td>final_f1</td><td>0.57439</td></tr><tr><td>final_precision</td><td>0.57019</td></tr><tr><td>final_recall</td><td>0.625</td></tr><tr><td>test/accuracy</td><td>0.625</td></tr><tr><td>test/f1</td><td>0.57439</td></tr><tr><td>test/loss</td><td>1.22946</td></tr><tr><td>test/precision</td><td>0.57019</td></tr><tr><td>test/recall</td><td>0.625</td></tr><tr><td>test/runtime</td><td>1.7512</td></tr><tr><td>test/samples_per_second</td><td>18.273</td></tr><tr><td>test/steps_per_second</td><td>1.142</td></tr><tr><td>total_flos</td><td>4.959754037231616e+16</td></tr><tr><td>train/epoch</td><td>1</td></tr><tr><td>train/global_step</td><td>40</td></tr><tr><td>train/grad_norm</td><td>2.37882</td></tr><tr><td>train/learning_rate</td><td>0.00056</td></tr><tr><td>train/loss</td><td>1.3266</td></tr><tr><td>train_loss</td><td>1.63639</td></tr><tr><td>train_runtime</td><td>93.2923</td></tr><tr><td>train_samples_per_second</td><td>6.86</td></tr><tr><td>train_steps_per_second</td><td>0.429</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">SGD_polynomial</strong> at: <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/m83emkob' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/m83emkob</a><br> View project at: <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers</a><br>Synced 5 W&B file(s), 1 media file(s), 2 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250420_025453-m83emkob/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/Users/egoh02/Github/CS7643-Project-SP25/wandb/run-20250420_025644-by4mzsnd</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/by4mzsnd' target=\"_blank\">SGD_cyclic</a></strong> to <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/by4mzsnd' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/by4mzsnd</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading dataset: jbarat/plant_species\n",
            "Dataset prepared with 640 training, 128 validation, and 32 test examples\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting training for SGD_cyclic...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='40' max='40' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [40/40 01:24, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>2.069300</td>\n",
              "      <td>1.963961</td>\n",
              "      <td>0.421875</td>\n",
              "      <td>0.394648</td>\n",
              "      <td>0.422122</td>\n",
              "      <td>0.421875</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>1.761600</td>\n",
              "      <td>1.528975</td>\n",
              "      <td>0.703125</td>\n",
              "      <td>0.681888</td>\n",
              "      <td>0.714156</td>\n",
              "      <td>0.703125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>1.423000</td>\n",
              "      <td>1.250856</td>\n",
              "      <td>0.734375</td>\n",
              "      <td>0.719621</td>\n",
              "      <td>0.786035</td>\n",
              "      <td>0.734375</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>1.242000</td>\n",
              "      <td>1.158270</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.738160</td>\n",
              "      <td>0.793480</td>\n",
              "      <td>0.750000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating SGD_cyclic...\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "Running experiment: SGD_exponential\n",
            "==================================================\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▇██▅</td></tr><tr><td>eval/f1</td><td>▁▇██▅</td></tr><tr><td>eval/loss</td><td>█▄▂▁▁</td></tr><tr><td>eval/precision</td><td>▁▇██▄</td></tr><tr><td>eval/recall</td><td>▁▇██▅</td></tr><tr><td>eval/runtime</td><td>█▆▆▆▁</td></tr><tr><td>eval/samples_per_second</td><td>▃███▁</td></tr><tr><td>eval/steps_per_second</td><td>▃███▁</td></tr><tr><td>final_accuracy</td><td>▁</td></tr><tr><td>final_f1</td><td>▁</td></tr><tr><td>final_precision</td><td>▁</td></tr><tr><td>final_recall</td><td>▁</td></tr><tr><td>test/accuracy</td><td>▁</td></tr><tr><td>test/f1</td><td>▁</td></tr><tr><td>test/loss</td><td>▁</td></tr><tr><td>test/precision</td><td>▁</td></tr><tr><td>test/recall</td><td>▁</td></tr><tr><td>test/runtime</td><td>▁</td></tr><tr><td>test/samples_per_second</td><td>▁</td></tr><tr><td>test/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▃▃▆▆████</td></tr><tr><td>train/global_step</td><td>▁▁▃▃▆▆███████</td></tr><tr><td>train/grad_norm</td><td>▁▂█▄</td></tr><tr><td>train/learning_rate</td><td>▇█▅▁</td></tr><tr><td>train/loss</td><td>█▅▃▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.625</td></tr><tr><td>eval/f1</td><td>0.57264</td></tr><tr><td>eval/loss</td><td>1.12829</td></tr><tr><td>eval/precision</td><td>0.55952</td></tr><tr><td>eval/recall</td><td>0.625</td></tr><tr><td>eval/runtime</td><td>2.5684</td></tr><tr><td>eval/samples_per_second</td><td>12.459</td></tr><tr><td>eval/steps_per_second</td><td>0.779</td></tr><tr><td>final_accuracy</td><td>0.625</td></tr><tr><td>final_f1</td><td>0.57264</td></tr><tr><td>final_precision</td><td>0.55952</td></tr><tr><td>final_recall</td><td>0.625</td></tr><tr><td>test/accuracy</td><td>0.625</td></tr><tr><td>test/f1</td><td>0.57264</td></tr><tr><td>test/loss</td><td>1.12829</td></tr><tr><td>test/precision</td><td>0.55952</td></tr><tr><td>test/recall</td><td>0.625</td></tr><tr><td>test/runtime</td><td>2.0935</td></tr><tr><td>test/samples_per_second</td><td>15.286</td></tr><tr><td>test/steps_per_second</td><td>0.955</td></tr><tr><td>total_flos</td><td>4.959754037231616e+16</td></tr><tr><td>train/epoch</td><td>1</td></tr><tr><td>train/global_step</td><td>40</td></tr><tr><td>train/grad_norm</td><td>2.61131</td></tr><tr><td>train/learning_rate</td><td>0.002</td></tr><tr><td>train/loss</td><td>1.242</td></tr><tr><td>train_loss</td><td>1.62398</td></tr><tr><td>train_runtime</td><td>86.353</td></tr><tr><td>train_samples_per_second</td><td>7.411</td></tr><tr><td>train_steps_per_second</td><td>0.463</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">SGD_cyclic</strong> at: <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/by4mzsnd' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/by4mzsnd</a><br> View project at: <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers</a><br>Synced 5 W&B file(s), 1 media file(s), 2 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250420_025644-by4mzsnd/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/Users/egoh02/Github/CS7643-Project-SP25/wandb/run-20250420_025824-58sfh1w2</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/58sfh1w2' target=\"_blank\">SGD_exponential</a></strong> to <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/58sfh1w2' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/58sfh1w2</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading dataset: jbarat/plant_species\n",
            "Dataset prepared with 640 training, 128 validation, and 32 test examples\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting training for SGD_exponential...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='40' max='40' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [40/40 01:22, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>2.027000</td>\n",
              "      <td>1.889268</td>\n",
              "      <td>0.507812</td>\n",
              "      <td>0.472801</td>\n",
              "      <td>0.478262</td>\n",
              "      <td>0.507812</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>1.770100</td>\n",
              "      <td>1.647508</td>\n",
              "      <td>0.671875</td>\n",
              "      <td>0.656179</td>\n",
              "      <td>0.688578</td>\n",
              "      <td>0.671875</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>1.605100</td>\n",
              "      <td>1.486669</td>\n",
              "      <td>0.703125</td>\n",
              "      <td>0.687895</td>\n",
              "      <td>0.723122</td>\n",
              "      <td>0.703125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>1.479000</td>\n",
              "      <td>1.398493</td>\n",
              "      <td>0.710938</td>\n",
              "      <td>0.697121</td>\n",
              "      <td>0.738380</td>\n",
              "      <td>0.710938</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating SGD_exponential...\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/egoh02/Github/CS7643-Project-SP25/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/Users/egoh02/Github/CS7643-Project-SP25/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "Running experiment: SGD_constant\n",
            "==================================================\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▇██▅</td></tr><tr><td>eval/f1</td><td>▁▇██▄</td></tr><tr><td>eval/loss</td><td>█▅▂▁▁</td></tr><tr><td>eval/precision</td><td>▁▇██▃</td></tr><tr><td>eval/recall</td><td>▁▇██▅</td></tr><tr><td>eval/runtime</td><td>█▇▇▇▁</td></tr><tr><td>eval/samples_per_second</td><td>▁▇▆█▅</td></tr><tr><td>eval/steps_per_second</td><td>▁▇▆█▅</td></tr><tr><td>final_accuracy</td><td>▁</td></tr><tr><td>final_f1</td><td>▁</td></tr><tr><td>final_precision</td><td>▁</td></tr><tr><td>final_recall</td><td>▁</td></tr><tr><td>test/accuracy</td><td>▁</td></tr><tr><td>test/f1</td><td>▁</td></tr><tr><td>test/loss</td><td>▁</td></tr><tr><td>test/precision</td><td>▁</td></tr><tr><td>test/recall</td><td>▁</td></tr><tr><td>test/runtime</td><td>▁</td></tr><tr><td>test/samples_per_second</td><td>▁</td></tr><tr><td>test/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▃▃▆▆████</td></tr><tr><td>train/global_step</td><td>▁▁▃▃▆▆███████</td></tr><tr><td>train/grad_norm</td><td>▁▁█▇</td></tr><tr><td>train/learning_rate</td><td>█▄▂▁</td></tr><tr><td>train/loss</td><td>█▅▃▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.625</td></tr><tr><td>eval/f1</td><td>0.56845</td></tr><tr><td>eval/loss</td><td>1.38423</td></tr><tr><td>eval/precision</td><td>0.54601</td></tr><tr><td>eval/recall</td><td>0.625</td></tr><tr><td>eval/runtime</td><td>1.7602</td></tr><tr><td>eval/samples_per_second</td><td>18.179</td></tr><tr><td>eval/steps_per_second</td><td>1.136</td></tr><tr><td>final_accuracy</td><td>0.625</td></tr><tr><td>final_f1</td><td>0.56845</td></tr><tr><td>final_precision</td><td>0.54601</td></tr><tr><td>final_recall</td><td>0.625</td></tr><tr><td>test/accuracy</td><td>0.625</td></tr><tr><td>test/f1</td><td>0.56845</td></tr><tr><td>test/loss</td><td>1.38423</td></tr><tr><td>test/precision</td><td>0.54601</td></tr><tr><td>test/recall</td><td>0.625</td></tr><tr><td>test/runtime</td><td>1.731</td></tr><tr><td>test/samples_per_second</td><td>18.486</td></tr><tr><td>test/steps_per_second</td><td>1.155</td></tr><tr><td>total_flos</td><td>4.959754037231616e+16</td></tr><tr><td>train/epoch</td><td>1</td></tr><tr><td>train/global_step</td><td>40</td></tr><tr><td>train/grad_norm</td><td>2.19767</td></tr><tr><td>train/learning_rate</td><td>0.00271</td></tr><tr><td>train/loss</td><td>1.479</td></tr><tr><td>train_loss</td><td>1.72028</td></tr><tr><td>train_runtime</td><td>84.8693</td></tr><tr><td>train_samples_per_second</td><td>7.541</td></tr><tr><td>train_steps_per_second</td><td>0.471</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">SGD_exponential</strong> at: <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/58sfh1w2' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/58sfh1w2</a><br> View project at: <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers</a><br>Synced 5 W&B file(s), 1 media file(s), 2 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250420_025824-58sfh1w2/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/Users/egoh02/Github/CS7643-Project-SP25/wandb/run-20250420_030001-qwmlnafr</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/qwmlnafr' target=\"_blank\">SGD_constant</a></strong> to <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/qwmlnafr' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/qwmlnafr</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading dataset: jbarat/plant_species\n",
            "Dataset prepared with 640 training, 128 validation, and 32 test examples\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting training for SGD_constant...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='40' max='40' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [40/40 01:25, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>2.013200</td>\n",
              "      <td>1.823707</td>\n",
              "      <td>0.554688</td>\n",
              "      <td>0.527025</td>\n",
              "      <td>0.538492</td>\n",
              "      <td>0.554688</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>1.618000</td>\n",
              "      <td>1.358081</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.736120</td>\n",
              "      <td>0.772129</td>\n",
              "      <td>0.750000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>1.241500</td>\n",
              "      <td>1.012988</td>\n",
              "      <td>0.734375</td>\n",
              "      <td>0.717402</td>\n",
              "      <td>0.779032</td>\n",
              "      <td>0.734375</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>0.945100</td>\n",
              "      <td>0.819525</td>\n",
              "      <td>0.742188</td>\n",
              "      <td>0.728290</td>\n",
              "      <td>0.785069</td>\n",
              "      <td>0.742188</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating SGD_constant...\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "Running experiment: SGD_cosine_with_restarts\n",
            "==================================================\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁█▇█▅</td></tr><tr><td>eval/f1</td><td>▁█▇█▄</td></tr><tr><td>eval/loss</td><td>█▅▂▁▁</td></tr><tr><td>eval/precision</td><td>▁███▃</td></tr><tr><td>eval/recall</td><td>▁█▇█▅</td></tr><tr><td>eval/runtime</td><td>████▁</td></tr><tr><td>eval/samples_per_second</td><td>▁█▇▇▃</td></tr><tr><td>eval/steps_per_second</td><td>▁█▇▇▃</td></tr><tr><td>final_accuracy</td><td>▁</td></tr><tr><td>final_f1</td><td>▁</td></tr><tr><td>final_precision</td><td>▁</td></tr><tr><td>final_recall</td><td>▁</td></tr><tr><td>test/accuracy</td><td>▁</td></tr><tr><td>test/f1</td><td>▁</td></tr><tr><td>test/loss</td><td>▁</td></tr><tr><td>test/precision</td><td>▁</td></tr><tr><td>test/recall</td><td>▁</td></tr><tr><td>test/runtime</td><td>▁</td></tr><tr><td>test/samples_per_second</td><td>▁</td></tr><tr><td>test/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▃▃▆▆████</td></tr><tr><td>train/global_step</td><td>▁▁▃▃▆▆███████</td></tr><tr><td>train/grad_norm</td><td>▁▁▅█</td></tr><tr><td>train/learning_rate</td><td>▁▁▁▁</td></tr><tr><td>train/loss</td><td>█▅▃▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.65625</td></tr><tr><td>eval/f1</td><td>0.61181</td></tr><tr><td>eval/loss</td><td>0.80828</td></tr><tr><td>eval/precision</td><td>0.61632</td></tr><tr><td>eval/recall</td><td>0.65625</td></tr><tr><td>eval/runtime</td><td>1.7265</td></tr><tr><td>eval/samples_per_second</td><td>18.534</td></tr><tr><td>eval/steps_per_second</td><td>1.158</td></tr><tr><td>final_accuracy</td><td>0.65625</td></tr><tr><td>final_f1</td><td>0.61181</td></tr><tr><td>final_precision</td><td>0.61632</td></tr><tr><td>final_recall</td><td>0.65625</td></tr><tr><td>test/accuracy</td><td>0.65625</td></tr><tr><td>test/f1</td><td>0.61181</td></tr><tr><td>test/loss</td><td>0.80828</td></tr><tr><td>test/precision</td><td>0.61632</td></tr><tr><td>test/recall</td><td>0.65625</td></tr><tr><td>test/runtime</td><td>1.7191</td></tr><tr><td>test/samples_per_second</td><td>18.614</td></tr><tr><td>test/steps_per_second</td><td>1.163</td></tr><tr><td>total_flos</td><td>4.959754037231616e+16</td></tr><tr><td>train/epoch</td><td>1</td></tr><tr><td>train/global_step</td><td>40</td></tr><tr><td>train/grad_norm</td><td>3.60594</td></tr><tr><td>train/learning_rate</td><td>0.02</td></tr><tr><td>train/loss</td><td>0.9451</td></tr><tr><td>train_loss</td><td>1.45446</td></tr><tr><td>train_runtime</td><td>87.6521</td></tr><tr><td>train_samples_per_second</td><td>7.302</td></tr><tr><td>train_steps_per_second</td><td>0.456</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">SGD_constant</strong> at: <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/qwmlnafr' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/qwmlnafr</a><br> View project at: <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers</a><br>Synced 5 W&B file(s), 1 media file(s), 2 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250420_030001-qwmlnafr/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/Users/egoh02/Github/CS7643-Project-SP25/wandb/run-20250420_030143-t10bchpm</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/t10bchpm' target=\"_blank\">SGD_cosine_with_restarts</a></strong> to <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/t10bchpm' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/t10bchpm</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading dataset: jbarat/plant_species\n",
            "Dataset prepared with 640 training, 128 validation, and 32 test examples\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting training for SGD_cosine_with_restarts...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='40' max='40' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [40/40 01:21, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>2.038900</td>\n",
              "      <td>1.864676</td>\n",
              "      <td>0.539062</td>\n",
              "      <td>0.508032</td>\n",
              "      <td>0.529822</td>\n",
              "      <td>0.539062</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>1.683700</td>\n",
              "      <td>1.481734</td>\n",
              "      <td>0.710938</td>\n",
              "      <td>0.695309</td>\n",
              "      <td>0.723851</td>\n",
              "      <td>0.710938</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>1.427400</td>\n",
              "      <td>1.293991</td>\n",
              "      <td>0.734375</td>\n",
              "      <td>0.721809</td>\n",
              "      <td>0.763800</td>\n",
              "      <td>0.734375</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>1.324700</td>\n",
              "      <td>1.264845</td>\n",
              "      <td>0.742188</td>\n",
              "      <td>0.732071</td>\n",
              "      <td>0.771488</td>\n",
              "      <td>0.742188</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating SGD_cosine_with_restarts...\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "Running experiment: SGD_constant_with_warmup\n",
            "==================================================\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▇██▄</td></tr><tr><td>eval/f1</td><td>▁▇██▃</td></tr><tr><td>eval/loss</td><td>█▄▂▁▁</td></tr><tr><td>eval/precision</td><td>▁▇██▂</td></tr><tr><td>eval/recall</td><td>▁▇██▄</td></tr><tr><td>eval/runtime</td><td>████▁</td></tr><tr><td>eval/samples_per_second</td><td>▁▆█▇▁</td></tr><tr><td>eval/steps_per_second</td><td>▁▆█▇▁</td></tr><tr><td>final_accuracy</td><td>▁</td></tr><tr><td>final_f1</td><td>▁</td></tr><tr><td>final_precision</td><td>▁</td></tr><tr><td>final_recall</td><td>▁</td></tr><tr><td>test/accuracy</td><td>▁</td></tr><tr><td>test/f1</td><td>▁</td></tr><tr><td>test/loss</td><td>▁</td></tr><tr><td>test/precision</td><td>▁</td></tr><tr><td>test/recall</td><td>▁</td></tr><tr><td>test/runtime</td><td>▁</td></tr><tr><td>test/samples_per_second</td><td>▁</td></tr><tr><td>test/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▃▃▆▆████</td></tr><tr><td>train/global_step</td><td>▁▁▃▃▆▆███████</td></tr><tr><td>train/grad_norm</td><td>▁▂▇█</td></tr><tr><td>train/learning_rate</td><td>█▆▃▁</td></tr><tr><td>train/loss</td><td>█▅▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.625</td></tr><tr><td>eval/f1</td><td>0.56942</td></tr><tr><td>eval/loss</td><td>1.24508</td></tr><tr><td>eval/precision</td><td>0.56027</td></tr><tr><td>eval/recall</td><td>0.625</td></tr><tr><td>eval/runtime</td><td>1.7472</td></tr><tr><td>eval/samples_per_second</td><td>18.315</td></tr><tr><td>eval/steps_per_second</td><td>1.145</td></tr><tr><td>final_accuracy</td><td>0.625</td></tr><tr><td>final_f1</td><td>0.56942</td></tr><tr><td>final_precision</td><td>0.56027</td></tr><tr><td>final_recall</td><td>0.625</td></tr><tr><td>test/accuracy</td><td>0.625</td></tr><tr><td>test/f1</td><td>0.56942</td></tr><tr><td>test/loss</td><td>1.24508</td></tr><tr><td>test/precision</td><td>0.56027</td></tr><tr><td>test/recall</td><td>0.625</td></tr><tr><td>test/runtime</td><td>1.7024</td></tr><tr><td>test/samples_per_second</td><td>18.797</td></tr><tr><td>test/steps_per_second</td><td>1.175</td></tr><tr><td>total_flos</td><td>4.959754037231616e+16</td></tr><tr><td>train/epoch</td><td>1</td></tr><tr><td>train/global_step</td><td>40</td></tr><tr><td>train/grad_norm</td><td>2.36969</td></tr><tr><td>train/learning_rate</td><td>4e-05</td></tr><tr><td>train/loss</td><td>1.3247</td></tr><tr><td>train_loss</td><td>1.61868</td></tr><tr><td>train_runtime</td><td>83.8141</td></tr><tr><td>train_samples_per_second</td><td>7.636</td></tr><tr><td>train_steps_per_second</td><td>0.477</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">SGD_cosine_with_restarts</strong> at: <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/t10bchpm' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/t10bchpm</a><br> View project at: <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers</a><br>Synced 5 W&B file(s), 1 media file(s), 2 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250420_030143-t10bchpm/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/Users/egoh02/Github/CS7643-Project-SP25/wandb/run-20250420_030321-dvuorqn4</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/dvuorqn4' target=\"_blank\">SGD_constant_with_warmup</a></strong> to <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/dvuorqn4' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/dvuorqn4</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading dataset: jbarat/plant_species\n",
            "Dataset prepared with 640 training, 128 validation, and 32 test examples\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting training for SGD_constant_with_warmup...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='40' max='40' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [40/40 01:21, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>2.038600</td>\n",
              "      <td>1.860518</td>\n",
              "      <td>0.539062</td>\n",
              "      <td>0.508032</td>\n",
              "      <td>0.529822</td>\n",
              "      <td>0.539062</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>1.653200</td>\n",
              "      <td>1.390407</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.730923</td>\n",
              "      <td>0.777988</td>\n",
              "      <td>0.750000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>1.268400</td>\n",
              "      <td>1.036549</td>\n",
              "      <td>0.726562</td>\n",
              "      <td>0.705841</td>\n",
              "      <td>0.778798</td>\n",
              "      <td>0.726562</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>0.965500</td>\n",
              "      <td>0.835922</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.735915</td>\n",
              "      <td>0.785297</td>\n",
              "      <td>0.750000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating SGD_constant_with_warmup...\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁█▇█▅</td></tr><tr><td>eval/f1</td><td>▁█▇█▄</td></tr><tr><td>eval/loss</td><td>█▅▃▁▁</td></tr><tr><td>eval/precision</td><td>▁███▃</td></tr><tr><td>eval/recall</td><td>▁█▇█▅</td></tr><tr><td>eval/runtime</td><td>████▁</td></tr><tr><td>eval/samples_per_second</td><td>▂▇█▅▁</td></tr><tr><td>eval/steps_per_second</td><td>▂▇█▅▁</td></tr><tr><td>final_accuracy</td><td>▁</td></tr><tr><td>final_f1</td><td>▁</td></tr><tr><td>final_precision</td><td>▁</td></tr><tr><td>final_recall</td><td>▁</td></tr><tr><td>test/accuracy</td><td>▁</td></tr><tr><td>test/f1</td><td>▁</td></tr><tr><td>test/loss</td><td>▁</td></tr><tr><td>test/precision</td><td>▁</td></tr><tr><td>test/recall</td><td>▁</td></tr><tr><td>test/runtime</td><td>▁</td></tr><tr><td>test/samples_per_second</td><td>▁</td></tr><tr><td>test/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▃▃▆▆████</td></tr><tr><td>train/global_step</td><td>▁▁▃▃▆▆███████</td></tr><tr><td>train/grad_norm</td><td>▁▂▅█</td></tr><tr><td>train/learning_rate</td><td>▁▁▁▁</td></tr><tr><td>train/loss</td><td>█▅▃▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.65625</td></tr><tr><td>eval/f1</td><td>0.61181</td></tr><tr><td>eval/loss</td><td>0.79155</td></tr><tr><td>eval/precision</td><td>0.61632</td></tr><tr><td>eval/recall</td><td>0.65625</td></tr><tr><td>eval/runtime</td><td>1.7651</td></tr><tr><td>eval/samples_per_second</td><td>18.129</td></tr><tr><td>eval/steps_per_second</td><td>1.133</td></tr><tr><td>final_accuracy</td><td>0.65625</td></tr><tr><td>final_f1</td><td>0.61181</td></tr><tr><td>final_precision</td><td>0.61632</td></tr><tr><td>final_recall</td><td>0.65625</td></tr><tr><td>test/accuracy</td><td>0.65625</td></tr><tr><td>test/f1</td><td>0.61181</td></tr><tr><td>test/loss</td><td>0.79155</td></tr><tr><td>test/precision</td><td>0.61632</td></tr><tr><td>test/recall</td><td>0.65625</td></tr><tr><td>test/runtime</td><td>1.7132</td></tr><tr><td>test/samples_per_second</td><td>18.679</td></tr><tr><td>test/steps_per_second</td><td>1.167</td></tr><tr><td>total_flos</td><td>4.959754037231616e+16</td></tr><tr><td>train/epoch</td><td>1</td></tr><tr><td>train/global_step</td><td>40</td></tr><tr><td>train/grad_norm</td><td>3.21751</td></tr><tr><td>train/learning_rate</td><td>0.02</td></tr><tr><td>train/loss</td><td>0.9655</td></tr><tr><td>train_loss</td><td>1.48141</td></tr><tr><td>train_runtime</td><td>83.3368</td></tr><tr><td>train_samples_per_second</td><td>7.68</td></tr><tr><td>train_steps_per_second</td><td>0.48</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">SGD_constant_with_warmup</strong> at: <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/dvuorqn4' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers/runs/dvuorqn4</a><br> View project at: <a href='https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers' target=\"_blank\">https://wandb.ai/dl_project_sp25/ViT-LR-Schedulers</a><br>Synced 5 W&B file(s), 1 media file(s), 2 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250420_030321-dvuorqn4/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Results Summary:\n",
            "                                  Experiment  Accuracy  F1 Score  Precision  \\\n",
            "0                 schedule_free_adamw_linear   0.68750  0.669766   0.759859   \n",
            "1                 schedule_free_adamw_cosine   0.71875  0.701389   0.764881   \n",
            "2             schedule_free_adamw_polynomial   0.71875  0.701389   0.764881   \n",
            "3                 schedule_free_adamw_cyclic   0.71875  0.706818   0.747396   \n",
            "4            schedule_free_adamw_exponential   0.59375  0.587500   0.622024   \n",
            "5               schedule_free_adamw_constant   0.75000  0.739574   0.773438   \n",
            "6   schedule_free_adamw_cosine_with_restarts   0.71875  0.701389   0.764881   \n",
            "7   schedule_free_adamw_constant_with_warmup   0.81250  0.811291   0.895833   \n",
            "8                               AdamW_linear   0.68750  0.677604   0.726190   \n",
            "9                               AdamW_cosine   0.75000  0.737847   0.810268   \n",
            "10                          AdamW_polynomial   0.68750  0.677604   0.726190   \n",
            "11                              AdamW_cyclic   0.75000  0.745028   0.866146   \n",
            "12                         AdamW_exponential   0.62500  0.629687   0.703795   \n",
            "13                            AdamW_constant   0.75000  0.741004   0.848661   \n",
            "14                AdamW_cosine_with_restarts   0.75000  0.737847   0.810268   \n",
            "15                AdamW_constant_with_warmup   0.78125  0.771307   0.863542   \n",
            "16                            RMSProp_linear   0.68750  0.675050   0.761781   \n",
            "17                            RMSProp_cosine   0.62500  0.596904   0.732205   \n",
            "18                        RMSProp_polynomial   0.65625  0.628919   0.754836   \n",
            "19                            RMSProp_cyclic   0.12500  0.034722   0.020161   \n",
            "20                       RMSProp_exponential   0.15625  0.083640   0.057292   \n",
            "21                          RMSProp_constant   0.15625  0.070833   0.046875   \n",
            "22              RMSProp_cosine_with_restarts   0.62500  0.596904   0.732205   \n",
            "23              RMSProp_constant_with_warmup   0.37500  0.372965   0.560417   \n",
            "24                            AdaGrad_linear   0.62500  0.606083   0.740327   \n",
            "25                            AdaGrad_cosine   0.65625  0.654545   0.692708   \n",
            "26                        AdaGrad_polynomial   0.62500  0.611697   0.701563   \n",
            "27                            AdaGrad_cyclic   0.59375  0.580447   0.635417   \n",
            "28                       AdaGrad_exponential   0.59375  0.572998   0.661830   \n",
            "29                          AdaGrad_constant   0.68750  0.685119   0.828125   \n",
            "30              AdaGrad_cosine_with_restarts   0.65625  0.654545   0.692708   \n",
            "31              AdaGrad_constant_with_warmup   0.75000  0.735593   0.854167   \n",
            "32                                SGD_linear   0.62500  0.577606   0.569444   \n",
            "33                                SGD_cosine   0.62500  0.569418   0.560268   \n",
            "34                            SGD_polynomial   0.62500  0.574387   0.570188   \n",
            "35                                SGD_cyclic   0.62500  0.572637   0.559524   \n",
            "36                           SGD_exponential   0.62500  0.568452   0.546007   \n",
            "37                              SGD_constant   0.65625  0.611812   0.616319   \n",
            "38                  SGD_cosine_with_restarts   0.62500  0.569418   0.560268   \n",
            "39                  SGD_constant_with_warmup   0.65625  0.611812   0.616319   \n",
            "\n",
            "     Recall             Scheduler  Learning Rate            Optimizer  \\\n",
            "0   0.68750                linear         0.0002  schedule_free_adamw   \n",
            "1   0.71875                cosine         0.0002  schedule_free_adamw   \n",
            "2   0.71875            polynomial         0.0002  schedule_free_adamw   \n",
            "3   0.71875                cyclic         0.0002  schedule_free_adamw   \n",
            "4   0.59375           exponential         0.0002  schedule_free_adamw   \n",
            "5   0.75000              constant         0.0002  schedule_free_adamw   \n",
            "6   0.71875  cosine_with_restarts         0.0002  schedule_free_adamw   \n",
            "7   0.81250  constant_with_warmup         0.0002  schedule_free_adamw   \n",
            "8   0.68750                linear         0.0002                AdamW   \n",
            "9   0.75000                cosine         0.0002                AdamW   \n",
            "10  0.68750            polynomial         0.0002                AdamW   \n",
            "11  0.75000                cyclic         0.0002                AdamW   \n",
            "12  0.62500           exponential         0.0002                AdamW   \n",
            "13  0.75000              constant         0.0002                AdamW   \n",
            "14  0.75000  cosine_with_restarts         0.0002                AdamW   \n",
            "15  0.78125  constant_with_warmup         0.0002                AdamW   \n",
            "16  0.68750                linear         0.0002              RMSProp   \n",
            "17  0.62500                cosine         0.0002              RMSProp   \n",
            "18  0.65625            polynomial         0.0002              RMSProp   \n",
            "19  0.12500                cyclic         0.0002              RMSProp   \n",
            "20  0.15625           exponential         0.0002              RMSProp   \n",
            "21  0.15625              constant         0.0002              RMSProp   \n",
            "22  0.62500  cosine_with_restarts         0.0002              RMSProp   \n",
            "23  0.37500  constant_with_warmup         0.0002              RMSProp   \n",
            "24  0.62500                linear         0.0002              AdaGrad   \n",
            "25  0.65625                cosine         0.0002              AdaGrad   \n",
            "26  0.62500            polynomial         0.0002              AdaGrad   \n",
            "27  0.59375                cyclic         0.0002              AdaGrad   \n",
            "28  0.59375           exponential         0.0002              AdaGrad   \n",
            "29  0.68750              constant         0.0002              AdaGrad   \n",
            "30  0.65625  cosine_with_restarts         0.0002              AdaGrad   \n",
            "31  0.75000  constant_with_warmup         0.0002              AdaGrad   \n",
            "32  0.62500                linear         0.0200                  SGD   \n",
            "33  0.62500                cosine         0.0200                  SGD   \n",
            "34  0.62500            polynomial         0.0200                  SGD   \n",
            "35  0.62500                cyclic         0.0200                  SGD   \n",
            "36  0.62500           exponential         0.0200                  SGD   \n",
            "37  0.65625              constant         0.0200                  SGD   \n",
            "38  0.62500  cosine_with_restarts         0.0200                  SGD   \n",
            "39  0.65625  constant_with_warmup         0.0200                  SGD   \n",
            "\n",
            "                 Dataset  \n",
            "0   jbarat/plant_species  \n",
            "1   jbarat/plant_species  \n",
            "2   jbarat/plant_species  \n",
            "3   jbarat/plant_species  \n",
            "4   jbarat/plant_species  \n",
            "5   jbarat/plant_species  \n",
            "6   jbarat/plant_species  \n",
            "7   jbarat/plant_species  \n",
            "8   jbarat/plant_species  \n",
            "9   jbarat/plant_species  \n",
            "10  jbarat/plant_species  \n",
            "11  jbarat/plant_species  \n",
            "12  jbarat/plant_species  \n",
            "13  jbarat/plant_species  \n",
            "14  jbarat/plant_species  \n",
            "15  jbarat/plant_species  \n",
            "16  jbarat/plant_species  \n",
            "17  jbarat/plant_species  \n",
            "18  jbarat/plant_species  \n",
            "19  jbarat/plant_species  \n",
            "20  jbarat/plant_species  \n",
            "21  jbarat/plant_species  \n",
            "22  jbarat/plant_species  \n",
            "23  jbarat/plant_species  \n",
            "24  jbarat/plant_species  \n",
            "25  jbarat/plant_species  \n",
            "26  jbarat/plant_species  \n",
            "27  jbarat/plant_species  \n",
            "28  jbarat/plant_species  \n",
            "29  jbarat/plant_species  \n",
            "30  jbarat/plant_species  \n",
            "31  jbarat/plant_species  \n",
            "32  jbarat/plant_species  \n",
            "33  jbarat/plant_species  \n",
            "34  jbarat/plant_species  \n",
            "35  jbarat/plant_species  \n",
            "36  jbarat/plant_species  \n",
            "37  jbarat/plant_species  \n",
            "38  jbarat/plant_species  \n",
            "39  jbarat/plant_species  \n",
            "Experiments completed!\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Main execution\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"Starting ViT experiments with different learning rate schedulers...\")\n",
        "    os.environ[\"WANDB_PROJECT\"] = \"ViT-LR-Schedulers\"\n",
        "\n",
        "    # Option 1: Run all experiments (time-consuming)\n",
        "    results = run_all_experiments()\n",
        "    results_df = visualize_results(results)\n",
        "\n",
        "    # Option 2: Run a single experiment for testing\n",
        "    # run_single_experiment(0)  # Try the baseline experiment first\n",
        "\n",
        "    #option 3: Optimizer sweep:\n",
        "    # Define sweep configuration\n",
        "    # sweep_config = {\n",
        "    #     \"method\": \"grid\",  # we can use \"grid\", \"random\", or \"bayes\"\n",
        "    #     \"metric\": {\n",
        "    #         \"name\": \"val_accuracy\",  # Metric to optimize\n",
        "    #         \"goal\": \"maximize\"       # Goal: maximize or minimize\n",
        "    #     },\n",
        "    #     \"parameters\": {\n",
        "    #         \"optimizer_name\": {\n",
        "    #             \"values\": [\"schedule_free_adamw\",\"AdamW\", \"SGD\", \"RMSProp\", \"AdaGrad\"]  # Optimizers to test\n",
        "    #         },\n",
        "    #         \"learning_rate\": {\n",
        "    #             \"values\": [2e-5, 2e-4, 2e-3, 2e-2, 2e-1]  # Learning rates to test\n",
        "    #         },\n",
        "    #         \"batch_size\": {\n",
        "    #             \"values\": [16]  # Fixed batch size\n",
        "    #         },\n",
        "    #         \"num_epochs\": {\n",
        "    #             \"values\": [3]  # Fixed number of epochs\n",
        "    #         },\n",
        "    #         \"scheduler_name\": {\n",
        "    #             \"values\": [\"cosine\"]  # Fixed scheduler for simplicity\n",
        "    #         }\n",
        "    #     }\n",
        "    # }\n",
        "    \n",
        "    # # Initialize the sweep\n",
        "    # sweep_id = wandb.sweep(sweep_config, project=\"ViT-Optimizer-Sweep\")\n",
        "    # wandb.agent(sweep_id, function=run_optimizer_sweep)\n",
        "    \n",
        "\n",
        "    print(\"Experiments completed!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "dON4fJvq0Ulv"
      },
      "outputs": [],
      "source": [
        "# Identify best of learning rate sweep:\n",
        "# import pandas as pd\n",
        "\n",
        "# # Load the exported CSV file\n",
        "# df = pd.read_csv(\"wandb_export.csv\")\n",
        "\n",
        "# # Group by optimizer and find the best learning rate for each\n",
        "# best_lr_per_optimizer = (\n",
        "#     df.groupby(\"optimizer_name\")\n",
        "#     .apply(lambda group: group.loc[group[\"val_accuracy\"].idxmax()])\n",
        "#     [[\"optimizer_name\", \"learning_rate\", \"val_accuracy\"]]\n",
        "# )\n",
        "\n",
        "# print(best_lr_per_optimizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OJqA_rlc0Ulv"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
